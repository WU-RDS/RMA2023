<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Hypothesis testing | Marketing Analytics 2021</title>
  <meta name="description" content="An Introduction to Data Analytics Using R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Hypothesis testing | Marketing Analytics 2021" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An Introduction to Data Analytics Using R" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Hypothesis testing | Marketing Analytics 2021" />
  
  <meta name="twitter:description" content="An Introduction to Data Analytics Using R" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="statistical-inference.html"/>
<link rel="next" href="regression.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">MA 2021</a></strong></li>

<li class="divider"></li>
<li class="part"><span><b>I Course outline</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#course-structure"><i class="fa fa-check"></i>Course structure</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#schedule"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#grading"><i class="fa fa-check"></i>Grading</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#course-materials"><i class="fa fa-check"></i>Course materials</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#main-reference"><i class="fa fa-check"></i>Main reference</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#further-readings"><i class="fa fa-check"></i>Further readings</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#discussion-forum"><i class="fa fa-check"></i>Discussion forum</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#datacamp"><i class="fa fa-check"></i>DataCamp</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#other-web-resources"><i class="fa fa-check"></i>Other web-resources</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#contact"><i class="fa fa-check"></i>Contact</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Lecture notes</b></span></li>
<li class="chapter" data-level="1" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>1</b> Preliminaries</a>
<ul>
<li class="chapter" data-level="1.1" data-path="preliminaries.html"><a href="preliminaries.html#marketing-foundations-recap"><i class="fa fa-check"></i><b>1.1</b> Marketing foundations (recap)</a></li>
<li class="chapter" data-level="1.2" data-path="preliminaries.html"><a href="preliminaries.html#the-research-process"><i class="fa fa-check"></i><b>1.2</b> The research process</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="preliminaries.html"><a href="preliminaries.html#research-question-and-hypothesis"><i class="fa fa-check"></i><b>1.2.1</b> Research question and hypothesis</a></li>
<li class="chapter" data-level="1.2.2" data-path="preliminaries.html"><a href="preliminaries.html#choosing-a-research-design"><i class="fa fa-check"></i><b>1.2.2</b> Choosing a research design</a></li>
<li class="chapter" data-level="1.2.3" data-path="preliminaries.html"><a href="preliminaries.html#collecting-data"><i class="fa fa-check"></i><b>1.2.3</b> Collecting data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#learning-check"><i class="fa fa-check"></i>Learning check</a></li>
<li class="chapter" data-level="" data-path="preliminaries.html"><a href="preliminaries.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html"><i class="fa fa-check"></i><b>2</b> Getting started with R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#how-to-download-and-install-r-and-rstudio"><i class="fa fa-check"></i><b>2.1</b> How to download and install R and RStudio</a></li>
<li class="chapter" data-level="2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#the-r-studio-interface"><i class="fa fa-check"></i><b>2.2</b> The R Studio interface</a></li>
<li class="chapter" data-level="2.3" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#functions"><i class="fa fa-check"></i><b>2.3</b> Functions</a></li>
<li class="chapter" data-level="2.4" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#packages"><i class="fa fa-check"></i><b>2.4</b> Packages</a></li>
<li class="chapter" data-level="2.5" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#a-typical-r-session"><i class="fa fa-check"></i><b>2.5</b> A typical R session</a></li>
<li class="chapter" data-level="2.6" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#getting-help"><i class="fa fa-check"></i><b>2.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-handling.html"><a href="data-handling.html"><i class="fa fa-check"></i><b>3</b> Data handling</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-handling.html"><a href="data-handling.html#basic-data-handling"><i class="fa fa-check"></i><b>3.1</b> Basic data handling</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="data-handling.html"><a href="data-handling.html#creating-objects"><i class="fa fa-check"></i><b>3.1.1</b> Creating objects</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-handling.html"><a href="data-handling.html#data-types"><i class="fa fa-check"></i><b>3.1.2</b> Data types</a></li>
<li class="chapter" data-level="3.1.3" data-path="data-handling.html"><a href="data-handling.html#data-structures"><i class="fa fa-check"></i><b>3.1.3</b> Data structures</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-handling.html"><a href="data-handling.html#data-import-and-export"><i class="fa fa-check"></i><b>3.2</b> Data import and export</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="data-handling.html"><a href="data-handling.html#getting-data-for-this-course"><i class="fa fa-check"></i><b>3.2.1</b> Getting data for this course</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-handling.html"><a href="data-handling.html#import-data-created-by-other-software-packages"><i class="fa fa-check"></i><b>3.2.2</b> Import data created by other software packages</a></li>
<li class="chapter" data-level="3.2.3" data-path="data-handling.html"><a href="data-handling.html#import-data-from-qualtrics"><i class="fa fa-check"></i><b>3.2.3</b> Import data from Qualtrics</a></li>
<li class="chapter" data-level="3.2.4" data-path="data-handling.html"><a href="data-handling.html#export-data"><i class="fa fa-check"></i><b>3.2.4</b> Export data</a></li>
<li class="chapter" data-level="3.2.5" data-path="data-handling.html"><a href="data-handling.html#import-data-from-the-web"><i class="fa fa-check"></i><b>3.2.5</b> Import data from the Web</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-handling.html"><a href="data-handling.html#learning-check-1"><i class="fa fa-check"></i>Learning check</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>4</b> Summarizing data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="summarizing-data.html"><a href="summarizing-data.html#summary-statistics"><i class="fa fa-check"></i><b>4.1</b> Summary statistics</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="summarizing-data.html"><a href="summarizing-data.html#categorical-variables"><i class="fa fa-check"></i><b>4.1.1</b> Categorical variables</a></li>
<li class="chapter" data-level="4.1.2" data-path="summarizing-data.html"><a href="summarizing-data.html#continuous-variables"><i class="fa fa-check"></i><b>4.1.2</b> Continuous variables</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="summarizing-data.html"><a href="summarizing-data.html#data-visualization"><i class="fa fa-check"></i><b>4.2</b> Data visualization</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#categorical-variables-1"><i class="fa fa-check"></i><b>4.2.1</b> Categorical variables</a></li>
<li class="chapter" data-level="4.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#continuous-variables-1"><i class="fa fa-check"></i><b>4.2.2</b> Continuous variables</a></li>
<li class="chapter" data-level="4.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#saving-plots"><i class="fa fa-check"></i><b>4.2.3</b> Saving plots</a></li>
<li class="chapter" data-level="4.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#ggplot-extensions"><i class="fa fa-check"></i><b>4.2.4</b> ggplot extensions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#learning-check-2"><i class="fa fa-check"></i>Learning check</a></li>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#references-1"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>5</b> Statistical inference</a>
<ul>
<li class="chapter" data-level="5.1" data-path="statistical-inference.html"><a href="statistical-inference.html#if-we-knew-it-all"><i class="fa fa-check"></i><b>5.1</b> If we knew it all</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="statistical-inference.html"><a href="statistical-inference.html#sampling-from-a-known-population"><i class="fa fa-check"></i><b>5.1.1</b> Sampling from a known population</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistical-inference.html"><a href="statistical-inference.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>5.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistical-inference.html"><a href="statistical-inference.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>5.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="5.3" data-path="statistical-inference.html"><a href="statistical-inference.html#using-what-we-actually-know"><i class="fa fa-check"></i><b>5.3</b> Using what we actually know</a></li>
<li class="chapter" data-level="5.4" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals-for-the-sample-mean"><i class="fa fa-check"></i><b>5.4</b> Confidence Intervals for the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#learning-check-3"><i class="fa fa-check"></i>Learning check</a></li>
<li class="chapter" data-level="" data-path="statistical-inference.html"><a href="statistical-inference.html#references-2"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#introduction-1"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-null-hypothesis"><i class="fa fa-check"></i><b>6.1.1</b> The null hypothesis</a></li>
<li class="chapter" data-level="6.1.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#statistical-inference-on-a-sample"><i class="fa fa-check"></i><b>6.1.2</b> Statistical inference on a sample</a></li>
<li class="chapter" data-level="6.1.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#choosing-the-right-test"><i class="fa fa-check"></i><b>6.1.3</b> Choosing the right test</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-sample-t-test"><i class="fa fa-check"></i><b>6.2</b> One sample t-test</a></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#comparing-two-means"><i class="fa fa-check"></i><b>6.3</b> Comparing two means</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#independent-means-t-test"><i class="fa fa-check"></i><b>6.3.1</b> Independent-means t-test</a></li>
<li class="chapter" data-level="6.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#dependent-means-t-test"><i class="fa fa-check"></i><b>6.3.2</b> Dependent-means t-test</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#nhst-considerations"><i class="fa fa-check"></i><b>6.4</b> NHST considerations</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>6.4.1</b> Type I and Type II Errors</a></li>
<li class="chapter" data-level="6.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#significance-level-sample-size-power-and-effect-size"><i class="fa fa-check"></i><b>6.4.2</b> Significance level, sample size, power, and effect size</a></li>
<li class="chapter" data-level="6.4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#p-values-stopping-rules-and-p-hacking"><i class="fa fa-check"></i><b>6.4.3</b> P-values, stopping rules and p-hacking</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#comparing-several-means"><i class="fa fa-check"></i><b>6.5</b> Comparing several means</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#introduction-2"><i class="fa fa-check"></i><b>6.5.1</b> Introduction</a></li>
<li class="chapter" data-level="6.5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#decomposing-variance"><i class="fa fa-check"></i><b>6.5.2</b> Decomposing variance</a></li>
<li class="chapter" data-level="6.5.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-way-anova"><i class="fa fa-check"></i><b>6.5.3</b> One-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>6.6</b> Non-parametric tests</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mann-whitney-u-test-a.k.a.-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>6.6.1</b> Mann-Whitney U Test (a.k.a. Wilcoxon rank-sum test)</a></li>
<li class="chapter" data-level="6.6.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>6.6.2</b> Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="6.6.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>6.6.3</b> Kruskal-Wallis test</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#categorical-data"><i class="fa fa-check"></i><b>6.7</b> Categorical data</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#confidence-intervals-for-proportions"><i class="fa fa-check"></i><b>6.7.1</b> Confidence intervals for proportions</a></li>
<li class="chapter" data-level="6.7.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi-square-test"><i class="fa fa-check"></i><b>6.7.2</b> Chi-square test</a></li>
<li class="chapter" data-level="6.7.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-size-1"><i class="fa fa-check"></i><b>6.7.3</b> Sample size</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-check-4"><i class="fa fa-check"></i>Learning check</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#references-3"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>7</b> Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regression.html"><a href="regression.html#correlation"><i class="fa fa-check"></i><b>7.1</b> Correlation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="regression.html"><a href="regression.html#correlation-coefficient"><i class="fa fa-check"></i><b>7.1.1</b> Correlation coefficient</a></li>
<li class="chapter" data-level="7.1.2" data-path="regression.html"><a href="regression.html#significance-testing"><i class="fa fa-check"></i><b>7.1.2</b> Significance testing</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="regression.html"><a href="regression.html#regression-1"><i class="fa fa-check"></i><b>7.2</b> Regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="regression.html"><a href="regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>7.2.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="7.2.2" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>7.2.2</b> Multiple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="regression.html"><a href="regression.html#potential-problems"><i class="fa fa-check"></i><b>7.3</b> Potential problems</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="regression.html"><a href="regression.html#outliers"><i class="fa fa-check"></i><b>7.3.1</b> Outliers</a></li>
<li class="chapter" data-level="7.3.2" data-path="regression.html"><a href="regression.html#influential-observations"><i class="fa fa-check"></i><b>7.3.2</b> Influential observations</a></li>
<li class="chapter" data-level="7.3.3" data-path="regression.html"><a href="regression.html#non-linearity"><i class="fa fa-check"></i><b>7.3.3</b> Non-linearity</a></li>
<li class="chapter" data-level="7.3.4" data-path="regression.html"><a href="regression.html#non-constant-error-variance"><i class="fa fa-check"></i><b>7.3.4</b> Non-constant error variance</a></li>
<li class="chapter" data-level="7.3.5" data-path="regression.html"><a href="regression.html#non-normally-distributed-errors"><i class="fa fa-check"></i><b>7.3.5</b> Non-normally distributed errors</a></li>
<li class="chapter" data-level="7.3.6" data-path="regression.html"><a href="regression.html#correlation-of-errors"><i class="fa fa-check"></i><b>7.3.6</b> Correlation of errors</a></li>
<li class="chapter" data-level="7.3.7" data-path="regression.html"><a href="regression.html#collinearity"><i class="fa fa-check"></i><b>7.3.7</b> Collinearity</a></li>
<li class="chapter" data-level="7.3.8" data-path="regression.html"><a href="regression.html#omitted-variables"><i class="fa fa-check"></i><b>7.3.8</b> Omitted Variables</a></li>
<li class="chapter" data-level="7.3.9" data-path="regression.html"><a href="regression.html#overfitting"><i class="fa fa-check"></i><b>7.3.9</b> Overfitting</a></li>
<li class="chapter" data-level="7.3.10" data-path="regression.html"><a href="regression.html#variable-selection"><i class="fa fa-check"></i><b>7.3.10</b> Variable selection</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="regression.html"><a href="regression.html#categorical-predictors"><i class="fa fa-check"></i><b>7.4</b> Categorical predictors</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="regression.html"><a href="regression.html#two-categories"><i class="fa fa-check"></i><b>7.4.1</b> Two categories</a></li>
<li class="chapter" data-level="7.4.2" data-path="regression.html"><a href="regression.html#more-than-two-categories"><i class="fa fa-check"></i><b>7.4.2</b> More than two categories</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regression.html"><a href="regression.html#extensions-of-the-linear-model"><i class="fa fa-check"></i><b>7.5</b> Extensions of the linear model</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="regression.html"><a href="regression.html#interaction-effects"><i class="fa fa-check"></i><b>7.5.1</b> Interaction effects</a></li>
<li class="chapter" data-level="7.5.2" data-path="regression.html"><a href="regression.html#non-linear-relationships"><i class="fa fa-check"></i><b>7.5.2</b> Non-linear relationships</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="regression.html"><a href="regression.html#logistic-regression"><i class="fa fa-check"></i><b>7.6</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="regression.html"><a href="regression.html#motivation-and-intuition"><i class="fa fa-check"></i><b>7.6.1</b> Motivation and intuition</a></li>
<li class="chapter" data-level="7.6.2" data-path="regression.html"><a href="regression.html#technical-details-of-the-model"><i class="fa fa-check"></i><b>7.6.2</b> Technical details of the model</a></li>
<li class="chapter" data-level="7.6.3" data-path="regression.html"><a href="regression.html#estimation-in-r"><i class="fa fa-check"></i><b>7.6.3</b> Estimation in R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="regression.html"><a href="regression.html#learning-check-5"><i class="fa fa-check"></i>Learning check</a></li>
<li class="chapter" data-level="" data-path="regression.html"><a href="regression.html#references-4"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html"><i class="fa fa-check"></i><b>8</b> Exploratory factor analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#introduction-3"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#steps-in-factor-analysis"><i class="fa fa-check"></i><b>8.2</b> Steps in factor analysis</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#are-the-assumptions-satisfied"><i class="fa fa-check"></i><b>8.2.1</b> Are the assumptions satisfied?</a></li>
<li class="chapter" data-level="8.2.2" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#deriving-factors"><i class="fa fa-check"></i><b>8.2.2</b> Deriving factors</a></li>
<li class="chapter" data-level="8.2.3" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#factor-interpretation"><i class="fa fa-check"></i><b>8.2.3</b> Factor interpretation</a></li>
<li class="chapter" data-level="8.2.4" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#creating-new-variables"><i class="fa fa-check"></i><b>8.2.4</b> Creating new variables</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#reliability-analysis"><i class="fa fa-check"></i><b>8.3</b> Reliability analysis</a></li>
<li class="chapter" data-level="" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#learning-check-6"><i class="fa fa-check"></i>Learning check</a></li>
<li class="chapter" data-level="" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#references-5"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>9</b> Cluster analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#k-means"><i class="fa fa-check"></i><b>9.1</b> K-Means</a></li>
<li class="chapter" data-level="9.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hierarchical-clustering"><i class="fa fa-check"></i><b>9.2</b> Hierarchical Clustering</a></li>
</ul></li>
<li class="part"><span><b>III Assignments</b></span></li>
<li class="chapter" data-level="10" data-path="r-markdown.html"><a href="r-markdown.html"><i class="fa fa-check"></i><b>10</b> R Markdown</a>
<ul>
<li class="chapter" data-level="10.1" data-path="r-markdown.html"><a href="r-markdown.html#introduction-to-r-markdown"><i class="fa fa-check"></i><b>10.1</b> Introduction to R Markdown</a>
<ul>
<li class="chapter" data-level="" data-path="r-markdown.html"><a href="r-markdown.html#creating-a-new-r-markdown-document"><i class="fa fa-check"></i>Creating a new R Markdown document</a></li>
<li class="chapter" data-level="" data-path="r-markdown.html"><a href="r-markdown.html#text-and-equations"><i class="fa fa-check"></i>Text and Equations</a></li>
<li class="chapter" data-level="" data-path="r-markdown.html"><a href="r-markdown.html#r-code"><i class="fa fa-check"></i>R-Code</a></li>
<li class="chapter" data-level="" data-path="r-markdown.html"><a href="r-markdown.html#latex-math"><i class="fa fa-check"></i>LaTeX Math</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="r-markdown.html"><a href="r-markdown.html#solution-assignment-2"><i class="fa fa-check"></i><b>10.2</b> Solution assignment 2</a></li>
</ul></li>
<li class="part"><span><b>IV Group project</b></span></li>
<li class="chapter" data-level="11" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html"><i class="fa fa-check"></i><b>11</b> Survey design &amp; analysis</a>
<ul>
<li class="chapter" data-level="11.1" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#your-tasks"><i class="fa fa-check"></i><b>11.1</b> Your tasks</a></li>
<li class="chapter" data-level="11.2" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#topics-for-the-group-project"><i class="fa fa-check"></i><b>11.2</b> Topics for the group project</a></li>
<li class="chapter" data-level="11.3" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#general-information"><i class="fa fa-check"></i><b>11.3</b> General information</a></li>
<li class="chapter" data-level="11.4" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#part-1-questionnaire-design"><i class="fa fa-check"></i><b>11.4</b> Part 1: Questionnaire design</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#guidelines-for-the-submission-and-presentation"><i class="fa fa-check"></i><b>11.4.1</b> Guidelines for the submission and presentation</a></li>
<li class="chapter" data-level="11.4.2" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#guidelines-for-the-design-of-your-questionnaire"><i class="fa fa-check"></i><b>11.4.2</b> Guidelines for the design of your questionnaire</a></li>
<li class="chapter" data-level="11.4.3" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#questionnaire-structure-and-contents"><i class="fa fa-check"></i><b>11.4.3</b> Questionnaire structure and contents</a></li>
<li class="chapter" data-level="11.4.4" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#test-your-questionnaire"><i class="fa fa-check"></i><b>11.4.4</b> Test your questionnaire</a></li>
<li class="chapter" data-level="11.4.5" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#data-collection"><i class="fa fa-check"></i><b>11.4.5</b> Data collection</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#part-2-data-analysis"><i class="fa fa-check"></i><b>11.5</b> Part 2: Data analysis</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#guidelines-for-the-submission-and-presentation-1"><i class="fa fa-check"></i><b>11.5.1</b> Guidelines for the submission and presentation</a></li>
<li class="chapter" data-level="11.5.2" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#data-export-from-qualtrics"><i class="fa fa-check"></i><b>11.5.2</b> Data export from Qualtrics</a></li>
<li class="chapter" data-level="11.5.3" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#randomized-groups"><i class="fa fa-check"></i><b>11.5.3</b> Randomized groups</a></li>
<li class="chapter" data-level="11.5.4" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#importing-qualtrics-data"><i class="fa fa-check"></i><b>11.5.4</b> Importing Qualtrics data</a></li>
<li class="chapter" data-level="11.5.5" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#data-handling-1"><i class="fa fa-check"></i><b>11.5.5</b> Data handling</a></li>
<li class="chapter" data-level="11.5.6" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#visualizations"><i class="fa fa-check"></i><b>11.5.6</b> Visualizations</a></li>
<li class="chapter" data-level="11.5.7" data-path="survey-design-analysis.html"><a href="survey-design-analysis.html#working-with-factors"><i class="fa fa-check"></i><b>11.5.7</b> Working with factors</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V FAQ</b></span></li>
<li class="chapter" data-level="12" data-path="faq.html"><a href="faq.html"><i class="fa fa-check"></i><b>12</b> FAQ</a>
<ul>
<li class="chapter" data-level="12.1" data-path="faq.html"><a href="faq.html#common-error-messages"><i class="fa fa-check"></i><b>12.1</b> Common error messages</a>
<ul>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#a-general-note-on-error-messages"><i class="fa fa-check"></i>A general note on error messages</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-in-filefile-rt-cannot-open-the-connection"><i class="fa fa-check"></i>Error in file(file, “rt”): cannot open the connection</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-unexpected-symbol-in-call"><i class="fa fa-check"></i>Error: unexpected ‘SYMBOL’ in “CALL”</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-in-call-object-of-type-closure-is-not-subsettable"><i class="fa fa-check"></i>Error in CALL : object of type ‘closure’ is not subsettable</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-in-call_with_-operator-is-invalid-for-atomic-vectors"><i class="fa fa-check"></i>Error in CALL_WITH_$: $ operator is invalid for atomic vectors</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-in-call-object-name-not-found"><i class="fa fa-check"></i>Error in CALL: object ‘NAME’ not found</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-in-call-could-not-find-function-function"><i class="fa fa-check"></i>Error in CALL: could not find function “FUNCTION”</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#error-in-call-incorrect-number-of-dimension"><i class="fa fa-check"></i>Error in CALL: incorrect number of dimension</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="faq.html"><a href="faq.html#installation-of-r-packages"><i class="fa fa-check"></i><b>12.2</b> Installation of R packages</a>
<ul>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#what-are-the-different-ways-to-install-r-packages"><i class="fa fa-check"></i>What are the different ways to install R packages?</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#i-cannot-install-packages-due-to-error-in-contrib.urlrepossource-or-warning-message-package-packagename-is-not-available-for-this-version-of-r"><i class="fa fa-check"></i>I cannot install packages due to “Error in contrib.url(repos,”source”)” or “Warning message: package ‘PACKAGENAME’ is not available for this version of R”</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#some-libraries-with-graphical-output-e.g.-summarytools-magick-fail-to-installload-properly-on-macos"><i class="fa fa-check"></i>Some libraries with graphical output (e.g., summarytools, magick) fail to install/load properly on MacOS</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#i-cannot-install-some-packages-on-macos"><i class="fa fa-check"></i>I cannot install some packages on MacOS</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="faq.html"><a href="faq.html#issues-with-statistics-and-data"><i class="fa fa-check"></i><b>12.3</b> Issues with statistics and data</a>
<ul>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#why-does-a-multi-item-scale-lead-to-increased-reliability"><i class="fa fa-check"></i>Why does a multi-item scale lead to increased reliability?</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#why-can-demeaningstandardization-lead-to-missing-values"><i class="fa fa-check"></i>Why can demeaning/standardization lead to missing values?</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#the-confidence-interval-ci-of-the-mean-seems-very-small-compared-to-the-dispersion-of-my-sample.-can-this-be-correct"><i class="fa fa-check"></i>The confidence interval (CI) of the mean seems very small compared to the dispersion of my sample. Can this be correct?</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="faq.html"><a href="faq.html#errors-related-to-specific-methods"><i class="fa fa-check"></i><b>12.4</b> Errors related to specific methods</a>
<ul>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#logistic-regression-1"><i class="fa fa-check"></i>Logistic regression</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#when-using-logistic-regression-error-in-weights-y-non-numeric-argument-to-binary-operator"><i class="fa fa-check"></i>When using logistic regression: Error in weights * y : non-numeric argument to binary operator</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="faq.html"><a href="faq.html#general-settings-and-options"><i class="fa fa-check"></i><b>12.5</b> General settings and options</a>
<ul>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#numbers-are-formatted-weirdly"><i class="fa fa-check"></i>Numbers are formatted weirdly</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="faq.html"><a href="faq.html#data-visualizationoutput-issues"><i class="fa fa-check"></i><b>12.6</b> Data visualization/output issues</a>
<ul>
<li><a href="faq.html#how-can-the-geom-colors-in-a-ggplot-be-changed">How can the <code>geom</code> colors in a <code>ggplot</code> be changed?</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#why-are-some-histograms-displayed-differently"><i class="fa fa-check"></i>Why are some histograms displayed differently?</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#some-labels-in-plots-are-cut-off.-how-can-i-extend-the-plot-margins"><i class="fa fa-check"></i>Some labels in plots are cut off. How can I extend the plot margins?</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="faq.html"><a href="faq.html#issues-with-functions-and-function-arguments"><i class="fa fa-check"></i><b>12.7</b> Issues with functions and function arguments</a>
<ul>
<li><a href="faq.html#problems-with-factor-and-as.factor">Problems with <code>factor</code> and <code>as.factor</code></a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#how-can-i-find-an-explanation-of-the-output-of-a-function"><i class="fa fa-check"></i>How can I find an explanation of the output of a function?</a></li>
<li><a href="faq.html#what-does-the-margin-argument-do">What does the <code>MARGIN</code> argument do?</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="faq.html"><a href="faq.html#issues-with-r-markdown"><i class="fa fa-check"></i><b>12.8</b> Issues with R Markdown</a>
<ul>
<li><a href="faq.html#i-get-an-error-when-knitting-to-pdf-but-it-works-for-html">I get an error when <code>knit</code>ting to PDF but it works for HTML</a></li>
<li class="chapter" data-level="" data-path="faq.html"><a href="faq.html#i-am-not-sure-where-r-code-latex-math-and-text-go"><i class="fa fa-check"></i>I am not sure where R-code, LaTeX math, and text go</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="faq.html"><a href="faq.html#new-questions"><i class="fa fa-check"></i><b>12.9</b> New questions</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Marketing Analytics 2021</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Hypothesis testing</h1>
<div id="introduction-1" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Introduction</h2>
<div class="infobox download">
<p><a href="./Code/06-hypothesis_testing.R">You can download the corresponding R-Code here</a></p>
</div>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/cJRwmWWCpZE" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>We test hypotheses because we are confined to taking samples – we rarely work with the entire population. In the previous chapter, we introduced the standard error (i.e., the standard deviation of a large number of hypothetical samples) as an estimate of how well a particular sample represents the population. We also saw how we can construct confidence intervals around the sample mean <span class="math inline">\(\bar x\)</span> by computing <span class="math inline">\(SE_{\bar x}\)</span> as an estimate of <span class="math inline">\(\sigma_{\bar x}\)</span> using <span class="math inline">\(s\)</span> as an estimate of <span class="math inline">\(\sigma\)</span> and calculating the 95% CI as <span class="math inline">\(\bar x \pm 1.96 * SE_{\bar x}\)</span>. Although we do not know the true population mean (<span class="math inline">\(\mu\)</span>), we might have an hypothesis about it and this would tell us how the corresponding sampling distribution looks like. Based on the sampling distribution of the hypothesized population mean, we could then determine the probability of a given sample <strong>assuming that the hypothesis is true</strong>.</p>
<p>Let us again begin by assuming we know the entire population using the example of music listening times among students from the previous example. As a reminder, the following plot shows the distribution of music listening times in the population of WU students.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="hypothesis-testing.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb210-2"><a href="hypothesis-testing.html#cb210-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb210-3"><a href="hypothesis-testing.html#cb210-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(latex2exp)</span>
<span id="cb210-4"><a href="hypothesis-testing.html#cb210-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb210-5"><a href="hypothesis-testing.html#cb210-5" aria-hidden="true" tabindex="-1"></a>hours <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="at">n =</span> <span class="dv">25000</span>, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">10</span>)</span>
<span id="cb210-6"><a href="hypothesis-testing.html#cb210-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(hours)) <span class="sc">+</span></span>
<span id="cb210-7"><a href="hypothesis-testing.html#cb210-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> hours), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill=</span><span class="st">&#39;white&#39;</span>, <span class="at">color=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb210-8"><a href="hypothesis-testing.html#cb210-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(hours), <span class="at">size =</span> <span class="dv">1</span>)  <span class="sc">+</span>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb210-9"><a href="hypothesis-testing.html#cb210-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Histogram of listening times&quot;</span>,</span>
<span id="cb210-10"><a href="hypothesis-testing.html#cb210-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">TeX</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Population mean ($</span><span class="sc">\\</span><span class="st">mu$) = %.2f; population standard deviation ($</span><span class="sc">\\</span><span class="st">sigma$) = %.2f&quot;</span>,<span class="fu">round</span>(<span class="fu">mean</span>(hours),<span class="dv">2</span>),<span class="fu">round</span>(<span class="fu">sd</span>(hours),<span class="dv">2</span>))),</span>
<span id="cb210-11"><a href="hypothesis-testing.html#cb210-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&#39;Number of students&#39;</span>, </span>
<span id="cb210-12"><a href="hypothesis-testing.html#cb210-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&#39;Hours&#39;</span>) </span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>In this example, the population mean (<span class="math inline">\(\mu\)</span>) is equal to 19.98, and the population standard deviation <span class="math inline">\(\sigma\)</span> is equal to 14.15.</p>
<div id="the-null-hypothesis" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> The null hypothesis</h3>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/DZOVAkWNgTg" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>Let us assume that we were planning to take a random sample of 50 students from this population and our hypothesis was that the mean listening time is equal to some specific value <span class="math inline">\(\mu_0\)</span>, say <span class="math inline">\(10\)</span>. This would be our <strong>null hypothesis</strong>. The null hypothesis refers to the statement that is being tested and is usually a statement of the status quo, one of no difference or no effect. In our example, the null hypothesis would state that there is no difference between the true population mean <span class="math inline">\(\mu\)</span> and the hypothesized value <span class="math inline">\(\mu_0\)</span> (in our example <span class="math inline">\(10\)</span>), which can be expressed as follows:</p>
<p><span class="math display">\[
H_0: \mu = \mu_0
\]</span>
When conducting research, we are usually interested in providing evidence against the null hypothesis. If we then observe sufficient evidence against it and our estimate is said to be significant. If the null hypothesis is rejected, this is taken as support for the <strong>alternative hypothesis</strong>. The alternative hypothesis assumes that some difference exists, which can be expressed as follows:</p>
<p><span class="math display">\[
H_1: \mu \neq \mu_0
\]</span>
Accepting the alternative hypothesis in turn will often lead to changes in opinions or actions. Note that while the null hypothesis may be rejected, it can never be accepted based on a single test. If we fail to reject the null hypothesis, it means that we simply haven’t collected enough evidence against the null hypothesis to disprove it. In classical hypothesis testing, there is no way to determine whether the null hypothesis is true. <strong>Hypothesis testing</strong> provides a means to quantify to what extent the data from our sample is in line with the null hypothesis.</p>
<p>In order to quantify the concept of “sufficient evidence” we look at the theoretical distribution of the sample means given our null hypothesis and the sample standard error. Using the available information we can infer the sampling distribution for our null hypothesis. Recall that the standard deviation of the sampling distribution (i.e., the standard error of the mean) is given by <span class="math inline">\(\sigma_{\bar x}={\sigma \over \sqrt{n}}\)</span>, and thus can be computed as follows:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="hypothesis-testing.html#cb211-1" aria-hidden="true" tabindex="-1"></a>mean_pop <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours)</span>
<span id="cb211-2"><a href="hypothesis-testing.html#cb211-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sd</span>(hours) <span class="co">#population standard deviation</span></span>
<span id="cb211-3"><a href="hypothesis-testing.html#cb211-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span> <span class="co">#sample size</span></span>
<span id="cb211-4"><a href="hypothesis-testing.html#cb211-4" aria-hidden="true" tabindex="-1"></a>standard_error <span class="ot">&lt;-</span> sigma<span class="sc">/</span><span class="fu">sqrt</span>(n) <span class="co">#standard error</span></span>
<span id="cb211-5"><a href="hypothesis-testing.html#cb211-5" aria-hidden="true" tabindex="-1"></a>standard_error</span></code></pre></div>
<pre><code>## [1] 2.001639</code></pre>
<p>Since we know from the central limit theorem that the sampling distribution is normal for large enough samples, we can now visualize the expected sampling distribution <strong>if our null hypothesis was in fact true</strong> (i.e., if the was no difference between the true population mean and the hypothesized mean of 10).</p>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>We also know that 95% of the probability is within 1.96 standard deviations from the mean. Values higher than that are rather unlikely, if our hypothesis about the population mean was indeed true. This is shown by the shaded area, also known as the “rejection region.” To test our hypothesis that the population mean is equal to <span class="math inline">\(10\)</span>, let us take a random sample from the population.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="hypothesis-testing.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12567</span>)</span>
<span id="cb213-2"><a href="hypothesis-testing.html#cb213-2" aria-hidden="true" tabindex="-1"></a>H_0 <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb213-3"><a href="hypothesis-testing.html#cb213-3" aria-hidden="true" tabindex="-1"></a>student_sample <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25000</span>, <span class="at">size =</span> <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb213-4"><a href="hypothesis-testing.html#cb213-4" aria-hidden="true" tabindex="-1"></a>music_listening_sample <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">hours =</span> hours[student_sample])</span>
<span id="cb213-5"><a href="hypothesis-testing.html#cb213-5" aria-hidden="true" tabindex="-1"></a>mean_sample <span class="ot">&lt;-</span> <span class="fu">mean</span>(music_listening_sample<span class="sc">$</span>hours)</span>
<span id="cb213-6"><a href="hypothesis-testing.html#cb213-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(music_listening_sample) <span class="sc">+</span> </span>
<span id="cb213-7"><a href="hypothesis-testing.html#cb213-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> hours), <span class="at">fill =</span> <span class="st">&#39;white&#39;</span>, <span class="at">color =</span> <span class="st">&#39;black&#39;</span>, <span class="at">bins =</span> <span class="dv">20</span>) <span class="sc">+</span></span>
<span id="cb213-8"><a href="hypothesis-testing.html#cb213-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_sample, <span class="at">color =</span> <span class="st">&#39;black&#39;</span>, <span class="at">size=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb213-9"><a href="hypothesis-testing.html#cb213-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">TeX</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Distribution of values in the sample ($n =$ %.0f, $</span><span class="sc">\\</span><span class="st">bar{x] = $ %.2f, s = %.2f)&quot;</span>,n,mean_sample,<span class="fu">sd</span>(music_listening_sample<span class="sc">$</span>hours))),<span class="at">x =</span> <span class="st">&quot;Hours&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>) </span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The mean listening time in the sample (black line) <span class="math inline">\(\bar x\)</span> is 18.59. We can already see from the graphic above that such a value is rather unlikely under the hypothesis that the population mean is <span class="math inline">\(10\)</span>. Intuitively, such a result would therefore provide evidence against our null hypothesis. But how could we quantify specifically how unlikely it is to obtain such a value and decide whether or not to reject the null hypothesis? Significance tests can be used to provide answers to these questions.</p>
</div>
<div id="statistical-inference-on-a-sample" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Statistical inference on a sample</h3>
<div id="test-statistic" class="section level4" number="6.1.2.1">
<h4><span class="header-section-number">6.1.2.1</span> Test statistic</h4>
<div id="z-scores" class="section level5" number="6.1.2.1.1">
<h5><span class="header-section-number">6.1.2.1.1</span> z-scores</h5>
<p>Let’s go back to the sampling distribution above. We know that 95% of all values will fall within 1.96 standard deviations from the mean. So if we could express the distance between our sample mean and the null hypothesis in terms of standard deviations, we could make statements about the probability of getting a sample mean of the observed magnitude (or more extreme values). Essentially, we would like to know how many standard deviations (<span class="math inline">\(\sigma_{\bar x}\)</span>) our sample mean (<span class="math inline">\(\bar x\)</span>) is away from the population mean if the null hypothesis was true (<span class="math inline">\(\mu_0\)</span>). This can be formally expressed as follows:</p>
<p><span class="math display">\[
\bar x-  \mu_0 = z \sigma_{\bar x}
\]</span></p>
<p>In this equation, <code>z</code> will tell us how many standard deviations the sample mean <span class="math inline">\(\bar x\)</span> is away from the null hypothesis <span class="math inline">\(\mu_0\)</span>. Solving for <code>z</code> gives us:</p>
<p><span class="math display">\[
z = {\bar x-  \mu_0 \over \sigma_{\bar x}}={\bar x-  \mu_0 \over \sigma / \sqrt{n}}
\]</span></p>
<p>This standardized value (or “z-score”) is also referred to as a <strong>test statistic</strong>. Let’s compute the test statistic for our example above:</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="hypothesis-testing.html#cb214-1" aria-hidden="true" tabindex="-1"></a>z_score <span class="ot">&lt;-</span> (mean_sample <span class="sc">-</span> H_0)<span class="sc">/</span>(sigma<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb214-2"><a href="hypothesis-testing.html#cb214-2" aria-hidden="true" tabindex="-1"></a>z_score</span></code></pre></div>
<pre><code>## [1] 4.292454</code></pre>
<p>To make a decision on whether the difference can be deemed statistically significant, we now need to compare this calculated test statistic to a meaningful threshold. In order to do so, we need to decide on a significance level <span class="math inline">\(\alpha\)</span>, which expresses the probability of finding an effect that does not actually exist (i.e., Type I Error). You can find a detailed discussion of this point at the end of this chapter. For now, we will adopt the widely accepted significance level of 5% and set <span class="math inline">\(\alpha\)</span> to 0.05. The critical value for the normal distribution and <span class="math inline">\(\alpha\)</span> = 0.05 can be computed using the <code>qnorm()</code> function as follows:</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="hypothesis-testing.html#cb216-1" aria-hidden="true" tabindex="-1"></a>z_crit <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)</span>
<span id="cb216-2"><a href="hypothesis-testing.html#cb216-2" aria-hidden="true" tabindex="-1"></a>z_crit</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<p>We use <code>0.975</code> and not <code>0.95</code> since we are running a two-sided test and need to account for the rejection region at the other end of the distribution. Recall that for the normal distribution, 95% of the total probability falls within 1.96 standard deviations of the mean, so that higher (absolute) values provide evidence against the null hypothesis. Generally, we speak of a statistically significant effect if the (absolute) calculated test statistic is larger than the (absolute) critical value. We can easily check if this is the case in our example:</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="hypothesis-testing.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(z_score) <span class="sc">&gt;</span> <span class="fu">abs</span>(z_crit)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Since the absolute value of the calculated test statistic is larger than the critical value, we would reject <span class="math inline">\(H_0\)</span> and conclude that the true population mean <span class="math inline">\(\mu\)</span> is significantly different from the hypothesized value <span class="math inline">\(\mu_0 = 10\)</span>.</p>
</div>
<div id="t-statistic" class="section level5" number="6.1.2.1.2">
<h5><span class="header-section-number">6.1.2.1.2</span> t-statistic</h5>
<p>You may have noticed that the formula for the z-score above assumes that we know the true population standard deviation (<span class="math inline">\(\sigma\)</span>) when computing the standard deviation of the sampling distribution (<span class="math inline">\(\sigma_{\bar x}\)</span>) in the denominator. However, the population standard deviation is usually not known in the real world and therefore represents another unknown population parameter which we have to estimate from the sample. We saw in the previous chapter that we usually use <span class="math inline">\(s\)</span> as an estimate of <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(SE_{\bar x}\)</span> as and estimate of <span class="math inline">\(\sigma_{\bar x}\)</span>. Intuitively, we should be more conservative regarding the critical value that we used above to assess whether we have a significant effect to reflect this uncertainty about the true population standard deviation. That is, the threshold for a “significant” effect should be higher to safeguard against falsely claiming a significant effect when there is none. If we replace <span class="math inline">\(\sigma_{\bar x}\)</span> by it’s estimate <span class="math inline">\(SE_{\bar x}\)</span> in the formula for the z-score, we get a new test statistic (i.e, the <strong>t-statistic</strong>) with its own distribution (the <strong>t-distribution</strong>):</p>
<p><span class="math display">\[
t = {\bar x-  \mu_0 \over SE_{\bar x}}={\bar x-  \mu_0 \over s / \sqrt{n}}
\]</span></p>
<p>Here, <span class="math inline">\(\bar X\)</span> denotes the sample mean and <span class="math inline">\(s\)</span> the sample standard deviation. The t-distribution has more probability in its “tails,” i.e. farther away from the mean. This reflects the higher uncertainty introduced by replacing the population standard deviation by its sample estimate. Intuitively, this is particularly relevant for small samples, since the uncertainty about the true population parameters decreases with increasing sample size. This is reflected by the fact that the exact shape of the t-distribution depends on the <strong>degrees of freedom</strong>, which is the sample size minus one (i.e., <span class="math inline">\(n-1\)</span>). To see this, the following graph shows the t-distribution with different degrees of freedom for a two-tailed test and <span class="math inline">\(\alpha = 0.05\)</span>. The grey curve shows the normal distribution.</p>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-9-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Notice that as <span class="math inline">\(n\)</span> gets larger, the t-distribution gets closer and closer to the normal distribution, reflecting the fact that the uncertainty introduced by <span class="math inline">\(s\)</span> is reduced. To summarize, we now have an estimate for the standard deviation of the distribution of the sample mean (i.e., <span class="math inline">\(SE_{\bar x}\)</span>) and an appropriate distribution that takes into account the necessary uncertainty (i.e., the t-distribution). Let us now compute the t-statistic according to the formula above:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="hypothesis-testing.html#cb220-1" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">&lt;-</span> (<span class="fu">sd</span>(music_listening_sample<span class="sc">$</span>hours)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb220-2"><a href="hypothesis-testing.html#cb220-2" aria-hidden="true" tabindex="-1"></a>t_score <span class="ot">&lt;-</span> (mean_sample <span class="sc">-</span> H_0)<span class="sc">/</span>SE</span>
<span id="cb220-3"><a href="hypothesis-testing.html#cb220-3" aria-hidden="true" tabindex="-1"></a>t_score</span></code></pre></div>
<pre><code>## [1] 4.84204</code></pre>
<p>Notice that the value of the t-statistic is higher compared to the z-score (4.29). This can be attributed to the fact that by using the <span class="math inline">\(s\)</span> as and estimate of <span class="math inline">\(\sigma\)</span>, we underestimate the true population standard deviation. Hence, the critical value would need to be larger to adjust for this. This is what the t-distribution does. Let us compute the critical value from the t-distribution with <code>n - 1</code>degrees of freedom.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="hypothesis-testing.html#cb222-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> n <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb222-2"><a href="hypothesis-testing.html#cb222-2" aria-hidden="true" tabindex="-1"></a>t_crit <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> df)</span>
<span id="cb222-3"><a href="hypothesis-testing.html#cb222-3" aria-hidden="true" tabindex="-1"></a>t_crit</span></code></pre></div>
<pre><code>## [1] 2.009575</code></pre>
<p>Again, we use <code>0.975</code> and not <code>0.95</code> since we are running a two-sided test and need to account for the rejection region at the other end of the distribution. Notice that the new critical value based on the t-distributionis larger, to reflect the uncertainty when estimating <span class="math inline">\(\sigma\)</span> from <span class="math inline">\(s\)</span>. Now we can see that the calculated test statistic is still larger than the critical value.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="hypothesis-testing.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(t_score) <span class="sc">&gt;</span> <span class="fu">abs</span>(t_crit)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>The following graphics shows that the calculated test statistic (red line) falls into the rejection region so that in our example, we would reject the null hypothesis that the true population mean is equal to <span class="math inline">\(10\)</span>.</p>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><strong>Decision:</strong> Reject <span class="math inline">\(H_0\)</span>, given that the calculated test statistic is larger than critical value.</p>
<p>Something to keep in mind here is the fact the test statistic is a function of the sample size. This, as <span class="math inline">\(n\)</span> gets large, the test statistic gets larger as well and we are more likely to find a significant effect. This reflects the decrease in uncertainty about the true population mean as our sample size increases.</p>
</div>
</div>
<div id="p-values" class="section level4" number="6.1.2.2">
<h4><span class="header-section-number">6.1.2.2</span> P-values</h4>
<p>In the previous section, we computed the test statistic, which tells us how close our sample is to the null hypothesis. The p-value corresponds to the probability that the test statistic would take a value as extreme or more extreme than the one that we actually observed, <strong>assuming that the null hypothesis is true</strong>. It is important to note that this is a <strong>conditional probability</strong>: we compute the probability of observing a sample mean (or a more extreme value) conditional on the assumption that the null hypothesis is true. The <code>pnorm()</code>function can be used to compute this probability. It is the cumulative probability distribution function of the `normal distribution. Cumulative probability means that the function returns the probability that the test statistic will take a value <strong>less than or equal to</strong> the calculated test statistic given the degrees of freedom. However, we are interested in obtaining the probability of observing a test statistic <strong>larger than or equal to</strong> the calculated test statistic under the null hypothesis (i.e., the p-value). Thus, we need to subtract the cumulative probability from 1. In addition, since we are running a two-sided test, we need to multiply the probability by 2 to account for the rejection region at the other side of the distribution.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="hypothesis-testing.html#cb226-1" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pt</span>(<span class="fu">abs</span>(t_score), <span class="at">df =</span> df))</span>
<span id="cb226-2"><a href="hypothesis-testing.html#cb226-2" aria-hidden="true" tabindex="-1"></a>p_value</span></code></pre></div>
<pre><code>## [1] 0.00001326885</code></pre>
<p>This value corresponds to the probability of observing a mean equal to or larger than the one we obtained from our sample, if the null hypothesis was true. As you can see, this probability is very low. A small p-value signals that it is unlikely to observe the calculated test statistic under the null hypothesis. To decide whether or not to reject the null hypothesis, we would now compare this value to the level of significance (<span class="math inline">\(\alpha\)</span>) that we chose for our test. For this example, we adopt the widely accepted significance level of 5%, so any test results with a p-value &lt; 0.05 would be deemed statistically significant. Note that the p-value is directly related to the value of the test statistic. The relationship is such that the higher (lower) the value of the test statistic, the lower (higher) the p-value.</p>
<p><strong>Decision:</strong> Reject <span class="math inline">\(H_0\)</span>, given that the p-value is smaller than 0.05.</p>
</div>
<div id="confidence-interval" class="section level4" number="6.1.2.3">
<h4><span class="header-section-number">6.1.2.3</span> Confidence interval</h4>
<p>For a given statistic calculated for a sample of observations (e.g., listening times), a 95% confidence interval can be constructed such that in 95% of samples, the true value of the true population mean will fall within its limits. If the parameter value specified in the null hypothesis (here <span class="math inline">\(10\)</span>) does not lie within the bounds, we reject <span class="math inline">\(H_0\)</span>. Building on what we learned about confidence intervals in the previous chapter, the 95% confidence interval based on the t-distribution can be computed as follows:</p>
<p><span class="math display">\[
CI_{lower} = {\bar x} - t_{1-{\alpha \over 2}} * SE_{\bar x} \\
CI_{upper} = {\bar x} + t_{1-{\alpha \over 2}} * SE_{\bar x}
\]</span></p>
<p>It is easy to compute this interval manually:</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="hypothesis-testing.html#cb228-1" aria-hidden="true" tabindex="-1"></a>ci_lower <span class="ot">&lt;-</span> (mean_sample)<span class="sc">-</span><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> df)<span class="sc">*</span>SE</span>
<span id="cb228-2"><a href="hypothesis-testing.html#cb228-2" aria-hidden="true" tabindex="-1"></a>ci_upper <span class="ot">&lt;-</span> (mean_sample)<span class="sc">+</span><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> df)<span class="sc">*</span>SE</span>
<span id="cb228-3"><a href="hypothesis-testing.html#cb228-3" aria-hidden="true" tabindex="-1"></a>ci_lower</span></code></pre></div>
<pre><code>## [1] 15.02606</code></pre>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="hypothesis-testing.html#cb230-1" aria-hidden="true" tabindex="-1"></a>ci_upper</span></code></pre></div>
<pre><code>## [1] 22.15783</code></pre>
<p>The interpretation of this interval is as follows: if we would (hypothetically) take 100 samples and calculated the mean and confidence interval for each of them, then the true population mean would be included in 95% of these intervals. The CI is informative when reporting the result of your test, since it provides an estimate of the uncertainty associated with the test result. From the test statistic or the p-value alone, it is not easy to judge in which range the true population parameter is located. The CI provides an estimate of this range.</p>
<p><strong>Decision:</strong> Reject <span class="math inline">\(H_0\)</span>, given that the parameter value from the null hypothesis (<span class="math inline">\(10\)</span>) is not included in the interval.</p>
<p>To summarize, you can see that we arrive at the same conclusion (i.e., reject <span class="math inline">\(H_0\)</span>), irrespective if we use the test statistic, the p-value, or the confidence interval. However, keep in mind that rejecting the null hypothesis does not prove the alternative hypothesis (we can merely provide support for it). Rather, think of the p-value as the chance of obtaining the data we’ve collected assuming that the null hypothesis is true. You should report the confidence interval to provide an estimate of the uncertainty associated with your test results.</p>
</div>
</div>
<div id="choosing-the-right-test" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Choosing the right test</h3>
<p>The test statistic, as we have seen, measures how close the sample is to the null hypothesis and often follows a well-known distribution (e.g., normal, t, or chi-square). To select the correct test, various factors need to be taken into consideration. Some examples are:</p>
<ul>
<li>On what scale are your variables measured (categorical vs. continuous)?</li>
<li>Do you want to test for relationships or differences?</li>
<li>If you test for differences, how many groups would you like to test?</li>
<li>For parametric tests, are the assumptions fulfilled?</li>
</ul>
<p>The previous discussion used a <strong>one sample t-test</strong> as an example, which requires that variable is measured on an interval or ratio scale. If you are confronted with other settings, the following flow chart provides a rough guideline on selecting the correct test:</p>
<div class="figure">
<img src="https://github.com/IMSMWU/Teaching/raw/master/MRDA2017/testselection.JPG" alt="" />
<p class="caption">Flowchart for selecting an appropriate test (source: McElreath, R. (2016): Statistical Rethinking, p. 2)</p>
</div>
<p>For a detailed overview over the different type of tests, please also refer to <a href="https://stats.idre.ucla.edu/other/mult-pkg/whatstat/" target="_blank">this overview</a> by the UCLA.</p>
<div id="parametric-vs.-non-parametric-tests" class="section level4" number="6.1.3.1">
<h4><span class="header-section-number">6.1.3.1</span> Parametric vs. non-parametric tests</h4>
<p>A basic distinction can be made between parametric and non-parametric tests. <strong>Parametric tests</strong> require that variables are measured on an interval or ratio scale and that the sampling distribution follows a known distribution. <strong>Non-Parametric tests</strong> on the other hand do not require the sampling distribution to be normally distributed (a.k.a. “assumption free tests”). These tests may be used when the variable of interest is measured on an ordinal scale or when the parametric assumptions do not hold. They often rely on ranking the data instead of analyzing the actual scores. By ranking the data, information on the magnitude of differences is lost. Thus, parametric tests are more powerful if the sampling distribution is normally distributed. In this chapter, we will first focus on parametric tests and cover non-parametric tests later.</p>
</div>
<div id="one-tailed-vs.-two-tailed-test" class="section level4" number="6.1.3.2">
<h4><span class="header-section-number">6.1.3.2</span> One-tailed vs. two-tailed test</h4>
<p>For some tests you may choose between a <strong>one-tailed test</strong> versus a <strong>two-tailed test</strong>. The choice depends on the hypothesis you specified, i.e., whether you specified a directional or a non-directional hypotheses. In the example above, we used a <strong>non-directional hypothesis</strong>. That is, we stated that the mean is different from the comparison value <span class="math inline">\(\mu_0\)</span>, but we did not state the direction of the effect. A <strong>directional hypothesis</strong> states the direction of the effect. For example, we might test whether the population mean is smaller than a comparison value:</p>
<p><span class="math display">\[
H_0: \mu \ge \mu_0 \\
H_1: \mu &lt; \mu_0
\]</span></p>
<p>Similarly, we could test whether the population mean is larger than a comparison value:</p>
<p><span class="math display">\[
H_0: \mu \le \mu_0 \\
H_1: \mu &gt; \mu_0
\]</span></p>
<p>Connected to the decision of how to phrase the hypotheses (directional vs. non-directional) is the choice of a <strong>one-tailed test</strong> versus a <strong>two-tailed test</strong>. Let’s first think about the meaning of a one-tailed test. Using a significance level of 0.05, a one-tailed test means that 5% of the total area under the probability distribution of our test statistic is located in one tail. Thus, under a one-tailed test, we test for the possibility of the relationship in one direction only, disregarding the possibility of a relationship in the other direction. In our example, a one-tailed test could test either if the mean listening time is significantly larger or smaller compared to the control condition, but not both. Depending on the direction, the mean listening time is significantly larger (smaller) if the test statistic is located in the top (bottom) 5% of its probability distribution.</p>
<p>The following graph shows the critical values that our test statistic would need to surpass so that the difference between the population mean and the comparison value would be deemed statistically significant.</p>
<p><img src="07-hypothesis_testing_files/figure-html/fig2-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>It can be seen that under a one-sided test, the rejection region is at one end of the distribution or the other. In a two-sided test, the rejection region is split between the two tails. As a consequence, the critical value of the test statistic is smaller using a one-tailed test, meaning that it has more power to detect an effect. Having said that, in most applications, we would like to be able catch effects in both directions, simply because we can often not rule out that an effect might exist that is not in the hypothesized direction. For example, if we would conduct a one-tailed test for a mean larger than some specified value but the mean turns out to be substantially smaller, then testing a one-directional hypothesis ($H_0: _0 $) would not allow us to conclude that there is a significant effect because there is not rejection at this end of the distribution.</p>
<p>As we have seen, the process of hypothesis testing consists of various steps:</p>
<ol style="list-style-type: decimal">
<li>Formulate null and alternative hypotheses</li>
<li>Select an appropriate test</li>
<li>Choose the level of significance (<span class="math inline">\(\alpha\)</span>)</li>
<li>Descriptive statistics and data visualization</li>
<li>Conduct significance test</li>
<li>Report results and draw a marketing conclusion</li>
</ol>
<p>In the following, we will go through the individual steps using examples for different tests.</p>
</div>
</div>
</div>
<div id="one-sample-t-test" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> One sample t-test</h2>
<p>The example we used in the introduction was an example of the <strong>one sample t-test</strong> and we computed all statistics by hand to explain the underlying intuition. When you conduct hypothesis tests using R, you do not need to calculate these statistics by hand, since there are build-in routines to conduct the steps for you. Let us use the same example again to see how you would conduct hypothesis tests in R.</p>
<p><strong>1. Formulate null and alternative hypotheses</strong></p>
<p>The null hypothesis states that there is no difference between the true population mean <span class="math inline">\(\mu\)</span> and the hypothesized value (i.e., <span class="math inline">\(10\)</span>), while the alternative hypothesis states the opposite:</p>
<p><span class="math display">\[
H_0: \mu = 10 \\
H_1: \mu \neq 10
\]</span></p>
<p><strong>2. Select an appropriate test</strong></p>
<p>Because we would like to test if the mean of a variable is different from a specified threshold, the one-sample t-test is appropriate. The assumptions of the test are 1) that the variable is measured using an interval or ratio scale, and 2) that the sampling distribution is normal. Both assumptions are met since 1) listening time is a ratio scale, and 2) we deem the sample size (n = 50) large enough to assume a normal sampling distribution according to the central limit theorem.</p>
<p><strong>3. Choose the level of significance</strong></p>
<p>We choose the conventional 5% significance level.</p>
<p><strong>4. Descriptive statistics and data visualization</strong></p>
<p>Provide descriptive statistics using the <code>describe()</code> function:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="hypothesis-testing.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb232-2"><a href="hypothesis-testing.html#cb232-2" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(student_sample)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["vars"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["median"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["trimmed"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["mad"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["min"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["max"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["range"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["skew"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["kurtosis"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["se"],"name":[13],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"50","3":"11457.94","4":"7943.54","5":"10494","6":"11277.4","7":"9759.215","8":"114","9":"24979","10":"24865","11":"0.179127","12":"-1.324842","13":"1123.386"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>From this, we can already see that the mean is different from the hypothesized value. The question however remains, whether this difference is significantly different, given the sample size and the variability in the data. Since we only have one continuous variable, we can visualize the distribution in a histogram.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="hypothesis-testing.html#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(music_listening_sample) <span class="sc">+</span> </span>
<span id="cb233-2"><a href="hypothesis-testing.html#cb233-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> hours), <span class="at">fill =</span> <span class="st">&#39;white&#39;</span>, <span class="at">color =</span> <span class="st">&#39;black&#39;</span>, <span class="at">bins =</span> <span class="dv">20</span>) <span class="sc">+</span></span>
<span id="cb233-3"><a href="hypothesis-testing.html#cb233-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb233-4"><a href="hypothesis-testing.html#cb233-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Distribution of values in the sample&quot;</span>,<span class="at">x =</span> <span class="st">&quot;Hours&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>) </span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><strong>5. Conduct significance test</strong></p>
<p>In the beginning of the chapter, we saw, how you could conduct significance test by hand. However, R has built-in routines that you can use to conduct the analyses. The <code>t.test()</code> function can be used to conduct the test. To test if the listening time among WU students was 10, you can use the following code:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="hypothesis-testing.html#cb234-1" aria-hidden="true" tabindex="-1"></a>H_0 <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb234-2"><a href="hypothesis-testing.html#cb234-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(music_listening_sample<span class="sc">$</span>hours, <span class="at">mu =</span> H_0, <span class="at">alternative =</span> <span class="st">&#39;two.sided&#39;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  music_listening_sample$hours
## t = 4.842, df = 49, p-value = 0.00001327
## alternative hypothesis: true mean is not equal to 10
## 95 percent confidence interval:
##  15.02606 22.15783
## sample estimates:
## mean of x 
##  18.59194</code></pre>
<p>Note that if you would have stated a directional hypothesis (i.e., the mean is either greater or smaller than 10 hours), you could easily amend the code to conduct a one sided test by changing the argument <code>alternative</code>from <code>'two.sided'</code> to either <code>'less'</code> or <code>'greater'</code>.</p>
<p>Note that you could also combine the results from the statistical test and the visualization using the <code>ggstatsplot</code> package as follows.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="hypothesis-testing.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb236-2"><a href="hypothesis-testing.html#cb236-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gghistostats</span>(</span>
<span id="cb236-3"><a href="hypothesis-testing.html#cb236-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> music_listening_sample, <span class="co"># dataframe from which variable is to be taken</span></span>
<span id="cb236-4"><a href="hypothesis-testing.html#cb236-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> hours, <span class="co"># numeric variable whose distribution is of interest</span></span>
<span id="cb236-5"><a href="hypothesis-testing.html#cb236-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Distribution of listening times&quot;</span>, <span class="co"># title for the plot</span></span>
<span id="cb236-6"><a href="hypothesis-testing.html#cb236-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">caption =</span> <span class="st">&quot;Notes: Test based on a random sample of 50 students.&quot;</span>,</span>
<span id="cb236-7"><a href="hypothesis-testing.html#cb236-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;parametric&quot;</span>, <span class="co"># one sample t-test</span></span>
<span id="cb236-8"><a href="hypothesis-testing.html#cb236-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">conf.level =</span> <span class="fl">0.95</span>, <span class="co"># changing confidence level for effect size</span></span>
<span id="cb236-9"><a href="hypothesis-testing.html#cb236-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">bar.measure =</span> <span class="st">&quot;mix&quot;</span>, <span class="co"># what does the bar length denote</span></span>
<span id="cb236-10"><a href="hypothesis-testing.html#cb236-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">test.value =</span> <span class="dv">10</span>, <span class="co"># default value is 0</span></span>
<span id="cb236-11"><a href="hypothesis-testing.html#cb236-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">test.value.line =</span> <span class="cn">TRUE</span>, <span class="co"># display a vertical line at test value</span></span>
<span id="cb236-12"><a href="hypothesis-testing.html#cb236-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">effsize.type =</span> <span class="st">&quot;d&quot;</span>, <span class="co"># display effect size (Cohen&#39;s d in output)</span></span>
<span id="cb236-13"><a href="hypothesis-testing.html#cb236-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">test.value.color =</span> <span class="st">&quot;#0072B2&quot;</span>, <span class="co"># color for the line for test value</span></span>
<span id="cb236-14"><a href="hypothesis-testing.html#cb236-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">centrality.para =</span> <span class="st">&quot;mean&quot;</span>, <span class="co"># which measure of central tendency is to be plotted</span></span>
<span id="cb236-15"><a href="hypothesis-testing.html#cb236-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">centrality.color =</span> <span class="st">&quot;darkred&quot;</span>, <span class="co"># decides color for central tendency line</span></span>
<span id="cb236-16"><a href="hypothesis-testing.html#cb236-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">binwidth =</span> <span class="dv">2</span>, <span class="co"># binwidth value (experiment)</span></span>
<span id="cb236-17"><a href="hypothesis-testing.html#cb236-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>, <span class="co"># turn off the messages</span></span>
<span id="cb236-18"><a href="hypothesis-testing.html#cb236-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span></span>
<span id="cb236-19"><a href="hypothesis-testing.html#cb236-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>You may nice some additional output in this plot related to the measure of effect size (Cohen’s d). Don’t worry about it at this stage, we will come back to this later in this chapter.</p>
<p><strong>6. Report results and draw a marketing conclusion</strong></p>
<p>Note that the results are the same as above, when we computed the test by hand. You could summarize the results as follows:</p>
<p>On average, the listening times in our sample were different form 10 hours per month (Mean = 18.59 hours, SE = 1.77). This difference was significant t(49) = 4.842, p &lt; .05 (95% CI = [15.03; 22.16]). Based on this evidence, we can conclude that the mean in our sample is significantly lower compared to the hypothesized population mean of <span class="math inline">\(10\)</span> hours, providing evidence against the null hypothesis.</p>
<p>Note that in the reporting above, the number <code>49</code> in parenthesis refers to the degrees of freedom that are available from the output.</p>
</div>
<div id="comparing-two-means" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Comparing two means</h2>
<p>In the one-sample test above, we tested the hypothesis that the population mean has some specific value <span class="math inline">\(\mu_0\)</span> using data from only one sample. In marketing (as in many other disciplines), you will often be confronted with a situation where you wish to compare the means of two groups. For example, you may conduct an experiment and randomly split your sample into two groups, one of which receives a treatment (experimental group) while the other doesn’t (control group). In this case, the units (e.g., participants, products) in each group are different (‘between-subjects design’) and the samples are said to be independent. Hence, we would use a <strong>independent-means t-test</strong>. If you run an experiment with two experimental conditions and the same units (e.g., participants, products) were observed in both experimental conditions, the sample is said to be dependent in the sense that you have the same units in each group (‘within-subjects design’). In this case, we would need to conduct an <strong>dependent-means t-test</strong>. Both tests are described in the following sections, beginning with the independent-means t-test.</p>
<div id="independent-means-t-test" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Independent-means t-test</h3>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/7APeiQ3_46A" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>Using an independent-means t-test, we can compare the means of two possibly different populations. It is, for example, quite common for online companies to test new service features by running an experiment and randomly splitting their website visitors into two groups: one is exposed to the website with the new feature (experimental group) and the other group is not exposed to the new feature (control group). This is a typical A/B-Test scenario.</p>
<p>As an example, imagine that a music streaming service would like to introduce a new playlist feature that let’s their users access playlists created by other users. The goal is to analyze how the new service feature impacts the listening time of users. The service randomly splits a representative subset of their users into two groups and collects data about their listening times over one month. Let’s create a data set to simulate such a scenario.</p>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["hours"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["group"],"name":[2],"type":["chr"],"align":["left"]}],"data":[{"1":"2","2":"A"},{"1":"27","2":"A"},{"1":"25","2":"A"},{"1":"2","2":"A"},{"1":"46","2":"A"},{"1":"13","2":"A"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="hypothesis-testing.html#cb237-1" aria-hidden="true" tabindex="-1"></a>hours_a_b <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/hours_a_b.csv&quot;</span>, </span>
<span id="cb237-2"><a href="hypothesis-testing.html#cb237-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, </span>
<span id="cb237-3"><a href="hypothesis-testing.html#cb237-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb237-4"><a href="hypothesis-testing.html#cb237-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(hours_a_b)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["hours"],"name":[1],"type":["int"],"align":["right"]},{"label":["group"],"name":[2],"type":["chr"],"align":["left"]}],"data":[{"1":"2","2":"A"},{"1":"27","2":"A"},{"1":"25","2":"A"},{"1":"2","2":"A"},{"1":"46","2":"A"},{"1":"13","2":"A"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>This data set contains two variables: the variable <code>hours</code> indicates the music listening times (in hours) and the variable <code>group</code> indicates from which group the observation comes, where ‘A’ refers to the control group (with the standard service) and ‘B’ refers to the experimental group (with the new playlist feature). Let’s first look at the descriptive statistics by group using the <code>describeBy</code> function:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="hypothesis-testing.html#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb238-2"><a href="hypothesis-testing.html#cb238-2" aria-hidden="true" tabindex="-1"></a><span class="fu">describeBy</span>(hours_a_b<span class="sc">$</span>hours, hours_a_b<span class="sc">$</span>group)</span></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: A
##    vars  n  mean   sd median trimmed   mad min max range skew kurtosis   se
## X1    1 98 18.11 12.1     15   16.88 10.38   2  65    63 1.08     1.21 1.22
## ------------------------------------------------------------ 
## group: B
##    vars   n mean    sd median trimmed   mad min max range skew kurtosis  se
## X1    1 112 28.5 17.97   24.5   26.56 15.57   1  83    82 0.96     0.82 1.7</code></pre>
<p>From this, we can already see that there is a difference in means between groups A and B. We can also see that the number of observations is different, as is the standard deviation. The question that we would like to answer is whether there is a significant difference in mean listening times between the groups. Remember that different users are contained in each group (‘between-subjects design’) and that the observations in one group are independent of the observations in the other group. Before we will see how you can easily conduct an independent-means t-test, let’s go over some theory first.</p>
<div id="theory" class="section level4" number="6.3.1.1">
<h4><span class="header-section-number">6.3.1.1</span> Theory</h4>
<p>As a starting point, let us label the unknown population mean of group A (control group) in our experiment <span class="math inline">\(\mu_1\)</span>, and that of group B (experimental group) <span class="math inline">\(\mu_2\)</span>. In this setting, the null hypothesis would state that the mean in group A is equal to the mean in group B:</p>
<p><span class="math display">\[
H_0: \mu_1=\mu_2
\]</span></p>
<p>This is equivalent to stating that the difference between the two groups (<span class="math inline">\(\delta\)</span>) is zero:</p>
<p><span class="math display">\[
H_0: \mu_1 - \mu_2=0=\delta
\]</span></p>
<p>That is, <span class="math inline">\(\delta\)</span> is the new unknown population parameter, so that the null and alternative hypothesis become:</p>
<p><span class="math display">\[
H_0: \delta = 0 \\
H_1: \delta \ne 0
\]</span></p>
<p>Remember that we usually don’t have access to the entire population so that we can not observe <span class="math inline">\(\delta\)</span> and have to estimate is from a sample statistic, which we define as <span class="math inline">\(d = \bar x_1-\bar x_2\)</span>, i.e., the difference between the sample means from group a (<span class="math inline">\(\bar x_1\)</span>) and group b (<span class="math inline">\(\bar x_2\)</span>). But can we really estimate <span class="math inline">\(d\)</span> from <span class="math inline">\(\delta\)</span>? Remember from the previous chapter, that we could estimate <span class="math inline">\(\mu\)</span> from <span class="math inline">\(\bar x\)</span>, because if we (hypothetically) take a larger number of samples, the distribution of the means of these samples (the sampling distribution) will be normally distributed and its mean will be (in the limit) equal to the population mean. It turns out that we can use the same underlying logic here. The above samples were drawn from two different populations with <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span>. Let us compute the difference in means between these two populations:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="hypothesis-testing.html#cb240-1" aria-hidden="true" tabindex="-1"></a>delta_pop <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_population_1)<span class="sc">-</span><span class="fu">mean</span>(hours_population_2)</span>
<span id="cb240-2"><a href="hypothesis-testing.html#cb240-2" aria-hidden="true" tabindex="-1"></a>delta_pop</span></code></pre></div>
<pre><code>## [1] -7.422855</code></pre>
<p>This means that the true difference between the mean listening times of groups a and b is -7.42. Let us now repeat the exercise from the previous chapter: let us repeatedly draw a large number of <span class="math inline">\(20,000\)</span> random samples of 100 users from each of these populations, compute the difference (i.e., <span class="math inline">\(d\)</span>, our estimate of <span class="math inline">\(\delta\)</span>), store the difference for each draw and create a histogram of <span class="math inline">\(d\)</span>.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="hypothesis-testing.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb242-2"><a href="hypothesis-testing.html#cb242-2" aria-hidden="true" tabindex="-1"></a>hours_population_1 <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">25000</span>, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">10</span>)</span>
<span id="cb242-3"><a href="hypothesis-testing.html#cb242-3" aria-hidden="true" tabindex="-1"></a>hours_population_2 <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">25000</span>, <span class="at">shape =</span> <span class="fl">2.5</span>, <span class="at">scale =</span> <span class="dv">11</span>)</span>
<span id="cb242-4"><a href="hypothesis-testing.html#cb242-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb242-5"><a href="hypothesis-testing.html#cb242-5" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="dv">20000</span></span>
<span id="cb242-6"><a href="hypothesis-testing.html#cb242-6" aria-hidden="true" tabindex="-1"></a>mean_delta <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> samples)</span>
<span id="cb242-7"><a href="hypothesis-testing.html#cb242-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>samples){</span>
<span id="cb242-8"><a href="hypothesis-testing.html#cb242-8" aria-hidden="true" tabindex="-1"></a>  student_sample <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25000</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb242-9"><a href="hypothesis-testing.html#cb242-9" aria-hidden="true" tabindex="-1"></a>  mean_delta[i,] <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_population_1[student_sample])<span class="sc">-</span><span class="fu">mean</span>(hours_population_2[student_sample])</span>
<span id="cb242-10"><a href="hypothesis-testing.html#cb242-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb242-11"><a href="hypothesis-testing.html#cb242-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb242-12"><a href="hypothesis-testing.html#cb242-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(mean_delta)) <span class="sc">+</span></span>
<span id="cb242-13"><a href="hypothesis-testing.html#cb242-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> mean_delta), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill=</span><span class="st">&#39;white&#39;</span>, <span class="at">color=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb242-14"><a href="hypothesis-testing.html#cb242-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb242-15"><a href="hypothesis-testing.html#cb242-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb242-16"><a href="hypothesis-testing.html#cb242-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(mean_delta)), <span class="at">size=</span><span class="dv">1</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;d&quot;</span>) <span class="sc">+</span></span>
<span id="cb242-17"><a href="hypothesis-testing.html#cb242-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">TeX</span>(<span class="fu">sprintf</span>(<span class="st">&quot;%d samples; $d_{</span><span class="sc">\\</span><span class="st">bar{x}}$ = %.2f&quot;</span>,samples, <span class="fu">round</span>(<span class="fu">mean</span>(mean_delta),<span class="dv">2</span>))))</span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>This gives us the sampling distribution of the mean differences between the samples. You will notice that this distribution follows a normal distribution and is centered around the true difference between the populations. This means that, on average, the difference between two sample means <span class="math inline">\(d\)</span> is a good estimate of <span class="math inline">\(\delta\)</span>. In our example, the difference between <span class="math inline">\(\bar x_1\)</span> and <span class="math inline">\(\bar x_2\)</span> is:</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="hypothesis-testing.html#cb243-1" aria-hidden="true" tabindex="-1"></a>mean_x1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_a_b[hours_a_b<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;A&quot;</span>,<span class="st">&quot;hours&quot;</span>])</span>
<span id="cb243-2"><a href="hypothesis-testing.html#cb243-2" aria-hidden="true" tabindex="-1"></a>mean_x1</span></code></pre></div>
<pre><code>## [1] 18.11224</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="hypothesis-testing.html#cb245-1" aria-hidden="true" tabindex="-1"></a>mean_x2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_a_b[hours_a_b<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;B&quot;</span>,<span class="st">&quot;hours&quot;</span>])</span>
<span id="cb245-2"><a href="hypothesis-testing.html#cb245-2" aria-hidden="true" tabindex="-1"></a>mean_x2</span></code></pre></div>
<pre><code>## [1] 28.5</code></pre>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="hypothesis-testing.html#cb247-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> mean_x1<span class="sc">-</span>mean_x2</span>
<span id="cb247-2"><a href="hypothesis-testing.html#cb247-2" aria-hidden="true" tabindex="-1"></a>d </span></code></pre></div>
<pre><code>## [1] -10.38776</code></pre>
<p>Now that we have <span class="math inline">\(d\)</span> as an estimate of <span class="math inline">\(\delta\)</span>, how can we find out if the observed difference is significantly different from the null hypothesis (i.e., <span class="math inline">\(\delta = 0\)</span>)?</p>
<p>Recall from the previous section, that the standard deviation of the sampling distribution <span class="math inline">\(\sigma_{\bar x}\)</span> (i.e., the standard error) gives us indication about the precision of our estimate. Further recall that the standard error can be calculated as <span class="math inline">\(\sigma_{\bar x}={\sigma \over \sqrt{n}}\)</span>. So how can we calculate the standard error of the difference between two population means? According to the <strong>variance sum law</strong>, to find the variance of the sampling distribution of differences, we merely need to add together the variances of the sampling distributions of the two populations that we are comparing. To find the standard error, we only need to take the square root of the variance (because the standard error is the standard deviation of the sampling distribution and the standard deviation is the square root of the variance), so that we get:</p>
<p><span class="math display">\[
\sigma_{\bar x_1-\bar x_2} = \sqrt{{\sigma_1^2 \over n_1}+{\sigma_2^2 \over n_2}}
\]</span></p>
<p>But recall that we don’t actually know the true population standard deviation, so we use <span class="math inline">\(SE_{\bar x_1-\bar x_2}\)</span> as an estimate of <span class="math inline">\(\sigma_{\bar x_1-\bar x_2}\)</span>:</p>
<p><span class="math display">\[
SE_{\bar x_1-\bar x_2} = \sqrt{{s_1^2 \over n_1}+{s_2^2 \over n_2}}
\]</span></p>
<p>Hence, for our example, we can calculate the standard error as follows:</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="hypothesis-testing.html#cb249-1" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">98</span></span>
<span id="cb249-2"><a href="hypothesis-testing.html#cb249-2" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">112</span></span>
<span id="cb249-3"><a href="hypothesis-testing.html#cb249-3" aria-hidden="true" tabindex="-1"></a>s1 <span class="ot">&lt;-</span> <span class="fu">var</span>(hours_a_b[hours_a_b<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;A&quot;</span>,<span class="st">&quot;hours&quot;</span>])</span>
<span id="cb249-4"><a href="hypothesis-testing.html#cb249-4" aria-hidden="true" tabindex="-1"></a>s1</span></code></pre></div>
<pre><code>## [1] 146.4924</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="hypothesis-testing.html#cb251-1" aria-hidden="true" tabindex="-1"></a>s2 <span class="ot">&lt;-</span> <span class="fu">var</span>(hours_a_b[hours_a_b<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;B&quot;</span>,<span class="st">&quot;hours&quot;</span>])</span>
<span id="cb251-2"><a href="hypothesis-testing.html#cb251-2" aria-hidden="true" tabindex="-1"></a>s2</span></code></pre></div>
<pre><code>## [1] 322.9189</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="hypothesis-testing.html#cb253-1" aria-hidden="true" tabindex="-1"></a>SE_x1_x2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(s1<span class="sc">/</span>n1<span class="sc">+</span>s2<span class="sc">/</span>n2)</span>
<span id="cb253-2"><a href="hypothesis-testing.html#cb253-2" aria-hidden="true" tabindex="-1"></a>SE_x1_x2</span></code></pre></div>
<pre><code>## [1] 2.092373</code></pre>
<p>Recall from above that we can calculate the t-statistic as:</p>
<p><span class="math display">\[
t= {\bar x - \mu_0 \over {s \over \sqrt{n}}} 
\]</span></p>
<p>Exchanging <span class="math inline">\(\bar x\)</span> for <span class="math inline">\(d\)</span>, we get</p>
<p><span class="math display">\[
t= {(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2) \over {\sqrt{{s_1^2 \over n_1}+{s_2^2 \over n_2}}}} 
\]</span></p>
<p>Note that according to our hypothesis <span class="math inline">\(\mu_1-\mu_2=0\)</span>, so that we can calculate the t-statistic as:</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="hypothesis-testing.html#cb255-1" aria-hidden="true" tabindex="-1"></a>t_score <span class="ot">&lt;-</span> d<span class="sc">/</span>SE_x1_x2</span>
<span id="cb255-2"><a href="hypothesis-testing.html#cb255-2" aria-hidden="true" tabindex="-1"></a>t_score</span></code></pre></div>
<pre><code>## [1] -4.964581</code></pre>
<p>Following the example of our one sample t-test above, we would now need to compare this calculated test statistic to a critical value in order to assess if <span class="math inline">\(d\)</span> is sufficiently far away from the null hypothesis to be statistically significant. To do this, we would need to know the exact t-distribution, which depends on the degrees of freedom. The problem is that deriving the degrees of freedom in this case is not that obvious. If we were willing to assume that <span class="math inline">\(\sigma_1=\sigma_2\)</span>, the correct t-distribution has <span class="math inline">\(n_1 -1 + n_2-1\)</span> degrees of freedom (i.e., the sum of the degrees of freedom of the two samples). However, because in real life we don not know if <span class="math inline">\(\sigma_1=\sigma_2\)</span>, we need to account for this additional uncertainty. We will not go into detail here, but R automatically uses a sophisticated approach to correct the degrees of freedom called the Welch’s correction, as we will see in the subsequent application.</p>
</div>
<div id="application" class="section level4" number="6.3.1.2">
<h4><span class="header-section-number">6.3.1.2</span> Application</h4>
<p>The section above explained the theory behind the independent-means t-test and showed how to compute the statistics manually. Obviously you don’t have to compute these statistics by hand in this section shows you how to conduct an independent-means t-test in R using the example from above.</p>
<p><strong>1. Formulate null and alternative hypotheses</strong></p>
<p>We wish to analyze whether there is a significant difference in music listening times between groups A and B. So our null hypothesis is that the means from the two populations are the same (i.e., there is no difference), while the alternative hypothesis states the opposite:</p>
<p><span class="math display">\[
H_0: \mu_1=\mu_2\\
H_1: \mu_1 \ne \mu_2
\]</span></p>
<p><strong>2. Select an appropriate test</strong></p>
<p>Since we have a ratio scaled variable (i.e., listening times) and two independent groups, where the mean of one sample is independent of the group of the second sample (i.e., the groups contain different units), the independent-means t-test is appropriate.</p>
<p><strong>3. Choose the level of significance</strong></p>
<p>We choose the conventional 5% significance level.</p>
<p><strong>4. Descriptive statistics and data visualization</strong></p>
<p>We can compute the descriptive statistics for each group separately, using the <code>describeBy()</code> function:</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="hypothesis-testing.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb257-2"><a href="hypothesis-testing.html#cb257-2" aria-hidden="true" tabindex="-1"></a><span class="fu">describeBy</span>(hours_a_b<span class="sc">$</span>hours, hours_a_b<span class="sc">$</span>group)</span></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: A
##    vars  n  mean   sd median trimmed   mad min max range skew kurtosis   se
## X1    1 98 18.11 12.1     15   16.88 10.38   2  65    63 1.08     1.21 1.22
## ------------------------------------------------------------ 
## group: B
##    vars   n mean    sd median trimmed   mad min max range skew kurtosis  se
## X1    1 112 28.5 17.97   24.5   26.56 15.57   1  83    82 0.96     0.82 1.7</code></pre>
<p>This already shows us that the mean between groups A and B are different. We can visualize the data using a boxplot and a histogram.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="hypothesis-testing.html#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hours_a_b, <span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> hours)) <span class="sc">+</span> </span>
<span id="cb259-2"><a href="hypothesis-testing.html#cb259-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span> </span>
<span id="cb259-3"><a href="hypothesis-testing.html#cb259-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb259-4"><a href="hypothesis-testing.html#cb259-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Listening time (hours)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb259-5"><a href="hypothesis-testing.html#cb259-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Boxplot of listening times&quot;</span>) <span class="sc">+</span></span>
<span id="cb259-6"><a href="hypothesis-testing.html#cb259-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="hypothesis-testing.html#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hours_a_b,<span class="fu">aes</span>(hours)) <span class="sc">+</span> </span>
<span id="cb260-2"><a href="hypothesis-testing.html#cb260-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb260-3"><a href="hypothesis-testing.html#cb260-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Listening time (hours)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>) <span class="sc">+</span> </span>
<span id="cb260-4"><a href="hypothesis-testing.html#cb260-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of listening times&quot;</span>) <span class="sc">+</span></span>
<span id="cb260-5"><a href="hypothesis-testing.html#cb260-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>group) <span class="sc">+</span></span>
<span id="cb260-6"><a href="hypothesis-testing.html#cb260-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-29-2.png" width="672" /></p>
<p><strong>5. Conduct significance test</strong></p>
<p>To conduct the independent means t-test, we can use the <code>t.test()</code> function:</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="hypothesis-testing.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(hours <span class="sc">~</span> group, <span class="at">data =</span> hours_a_b, <span class="at">mu =</span> <span class="dv">0</span>, <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>, <span class="at">conf.level =</span> <span class="fl">0.95</span>, <span class="at">var.equal =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  hours by group
## t = -4.9646, df = 195.73, p-value = 0.000001494
## alternative hypothesis: true difference in means between group A and group B is not equal to 0
## 95 percent confidence interval:
##  -14.514246  -6.261264
## sample estimates:
## mean in group A mean in group B 
##        18.11224        28.50000</code></pre>
<p>Again, we could combine the results of the statistical test and the visualization using the <code>ggstatsplot</code> package.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="hypothesis-testing.html#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb263-2"><a href="hypothesis-testing.html#cb263-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggbetweenstats</span>(</span>
<span id="cb263-3"><a href="hypothesis-testing.html#cb263-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> hours_a_b,</span>
<span id="cb263-4"><a href="hypothesis-testing.html#cb263-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot.type =</span> <span class="st">&quot;box&quot;</span>,</span>
<span id="cb263-5"><a href="hypothesis-testing.html#cb263-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> group, <span class="co"># 2 groups</span></span>
<span id="cb263-6"><a href="hypothesis-testing.html#cb263-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> hours ,</span>
<span id="cb263-7"><a href="hypothesis-testing.html#cb263-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;p&quot;</span>, <span class="co"># default</span></span>
<span id="cb263-8"><a href="hypothesis-testing.html#cb263-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">effsize.type =</span> <span class="st">&quot;d&quot;</span>, <span class="co"># display effect size (Cohen&#39;s d in output)</span></span>
<span id="cb263-9"><a href="hypothesis-testing.html#cb263-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb263-10"><a href="hypothesis-testing.html#cb263-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span>,</span>
<span id="cb263-11"><a href="hypothesis-testing.html#cb263-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.ci =</span> <span class="cn">TRUE</span>,</span>
<span id="cb263-12"><a href="hypothesis-testing.html#cb263-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Mean listening times for different groups&quot;</span></span>
<span id="cb263-13"><a href="hypothesis-testing.html#cb263-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-31-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>6. Report results and draw a marketing conclusion</strong></p>
<p>The results showed that listening times were higher in the experimental group (Mean = 28.50, SE = 1.70) compared to the control group (Mean = 18.11, SE = 1.22). This means that the listening times were 10.39 hours higher on average in the experimental group, compared to the control group. An independent-means t-test showed that this difference is significant t(195.73) = 4.96, p &lt; .05 (95% CI = [6.26, 14.51]).</p>
</div>
</div>
<div id="dependent-means-t-test" class="section level3" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Dependent-means t-test</h3>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/vIcrWJ6sJu8" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>While the independent-means t-test is used when different units (e.g., participants, products) were assigned to the different condition, the <strong>dependent-means t-test</strong> is used when there are two experimental conditions and the same units (e.g., participants, products) were observed in both experimental conditions.</p>
<p>Imagine, for example, a slightly different experimental setup for the above experiment. Imagine that we do not assign different users to the groups, but that a sample of 100 users gets to use the music streaming service with the new feature for one month and we compare the music listening times of these users during the month of the experiment with the listening time in the previous month. Let us generate data for this example:</p>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["hours_a"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["hours_b"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"2","2":"24"},{"1":"27","2":"21"},{"1":"25","2":"51"},{"1":"2","2":"12"},{"1":"46","2":"54"},{"1":"13","2":"18"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="hypothesis-testing.html#cb264-1" aria-hidden="true" tabindex="-1"></a>hours_a_b_paired <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/hours_a_b_paired.csv&quot;</span>, </span>
<span id="cb264-2"><a href="hypothesis-testing.html#cb264-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>, </span>
<span id="cb264-3"><a href="hypothesis-testing.html#cb264-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb264-4"><a href="hypothesis-testing.html#cb264-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(hours_a_b_paired)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["hours_a"],"name":[1],"type":["int"],"align":["right"]},{"label":["hours_b"],"name":[2],"type":["int"],"align":["right"]}],"data":[{"1":"2","2":"24"},{"1":"27","2":"21"},{"1":"25","2":"51"},{"1":"2","2":"12"},{"1":"46","2":"54"},{"1":"13","2":"18"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Note that the data set has almost the same structure as before only that we know have two variables representing the listening times of each user in the month before the experiment and during the month of the experiment when the new feature was tested.</p>
<div id="theory-1" class="section level4" number="6.3.2.1">
<h4><span class="header-section-number">6.3.2.1</span> Theory</h4>
<p>In this case, we want to test the hypothesis that there is no difference in mean the mean listening times between the two months. This can be expressed as follows:</p>
<p><span class="math display">\[
H_0: \mu_D = 0 \\
\]</span>
Note that the hypothesis only refers to one population, since both observations come from the same units (i.e., users). To use consistent notation, we replace <span class="math inline">\(\mu_D\)</span> with <span class="math inline">\(\delta\)</span> and get:</p>
<p><span class="math display">\[
H_0: \delta = 0 \\
H_1: \delta \neq 0
\]</span></p>
<p>where <span class="math inline">\(\delta\)</span> denotes the difference between the observed listening times from the two consecutive months <strong>of the same users</strong>. As is the previous example, since we do not observe the entire population, we estimate <span class="math inline">\(\delta\)</span> based on the sample using <span class="math inline">\(d\)</span>, which is the difference in mean listening time between the two months for our sample. Note that we assume that everything else (e.g., number of new releases) remained constant over the two month to keep it simple. We can show as above that the sampling distribution follows a normal distribution with a mean that is (in the limit) the same as the population mean. This means, again, that the difference in sample means is a good estimate for the difference in population means. Let’s compute a new variable <span class="math inline">\(d\)</span>, which is the difference between two month.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="hypothesis-testing.html#cb265-1" aria-hidden="true" tabindex="-1"></a>hours_a_b_paired<span class="sc">$</span>d <span class="ot">&lt;-</span> hours_a_b_paired<span class="sc">$</span>hours_a <span class="sc">-</span> hours_a_b_paired<span class="sc">$</span>hours_b</span>
<span id="cb265-2"><a href="hypothesis-testing.html#cb265-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(hours_a_b_paired)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["hours_a"],"name":[1],"type":["int"],"align":["right"]},{"label":["hours_b"],"name":[2],"type":["int"],"align":["right"]},{"label":["d"],"name":[3],"type":["int"],"align":["right"]}],"data":[{"1":"2","2":"24","3":"-22"},{"1":"27","2":"21","3":"6"},{"1":"25","2":"51","3":"-26"},{"1":"2","2":"12","3":"-10"},{"1":"46","2":"54","3":"-8"},{"1":"13","2":"18","3":"-5"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Note that we now have a new variable, which is the difference in listening times (in hours) between the two months. The mean of this difference is:</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="hypothesis-testing.html#cb266-1" aria-hidden="true" tabindex="-1"></a>mean_d <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_a_b_paired<span class="sc">$</span>d)</span>
<span id="cb266-2"><a href="hypothesis-testing.html#cb266-2" aria-hidden="true" tabindex="-1"></a>mean_d</span></code></pre></div>
<pre><code>## [1] -11.65</code></pre>
<p>Again, we use <span class="math inline">\(SE_{\bar x}\)</span> as an estimate of <span class="math inline">\(\sigma_{\bar x}\)</span>:</p>
<p><span class="math display">\[
SE_{\bar d}={s \over \sqrt{n}}
\]</span>
Hence, we can compute the standard error as:</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="hypothesis-testing.html#cb268-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(hours_a_b_paired)</span>
<span id="cb268-2"><a href="hypothesis-testing.html#cb268-2" aria-hidden="true" tabindex="-1"></a>SE_d <span class="ot">&lt;-</span> <span class="fu">sd</span>(hours_a_b_paired<span class="sc">$</span>d)<span class="sc">/</span><span class="fu">sqrt</span>(n)</span>
<span id="cb268-3"><a href="hypothesis-testing.html#cb268-3" aria-hidden="true" tabindex="-1"></a>SE_d</span></code></pre></div>
<pre><code>## [1] 2.151503</code></pre>
<p>The test statistic is therefore:</p>
<p><span class="math display">\[
t = {\bar d-  \mu_0 \over SE_{\bar d}}
\]</span>
on 99 (i.e., n-1) degrees of freedom. Now we can compute the t-statistic as follows:</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="hypothesis-testing.html#cb270-1" aria-hidden="true" tabindex="-1"></a>t_score <span class="ot">&lt;-</span> mean_d<span class="sc">/</span>SE_d</span>
<span id="cb270-2"><a href="hypothesis-testing.html#cb270-2" aria-hidden="true" tabindex="-1"></a>t_score</span></code></pre></div>
<pre><code>## [1] -5.41482</code></pre>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="hypothesis-testing.html#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>,<span class="at">df=</span><span class="dv">99</span>)</span></code></pre></div>
<pre><code>## [1] 1.984217</code></pre>
<p>Note that in the case of the dependent-means t-test, we only base our hypothesis on one population and hence there is only one population variance. This is because in the dependent sample test, the observations come from the same observational units (i.e., users). Hence, there is no unsystematic variation due to potential differences between users that were assigned to the experimental groups. This means that the influence of unobserved factors (unsystematic variation) relative to the variation due to the experimental manipulation (systematic variation) is not as strong in the dependent-means test compared to the independent-means test and we don’t need to correct for differences in the population variances.</p>
</div>
<div id="application-1" class="section level4" number="6.3.2.2">
<h4><span class="header-section-number">6.3.2.2</span> Application</h4>
<p>Again, we don’t have to compute all this by hand since the <code>t.test(...)</code> function can be used to do it for us. Now we have to use the argument <code>paired=TRUE</code> to let R know that we are working with dependent observations.</p>
<p><strong>1. Formulate null and alternative hypotheses</strong></p>
<p>We would like to the test if there is a difference in music listening times between the two consecutive months, so our null hypothesis is that there is no difference, while the alternative hypothesis states the opposite:</p>
<p><span class="math display">\[
H_0: \mu_D = 0 \\
H_0: \mu_D \ne 0
\]</span></p>
<p><strong>2. Select an appropriate test</strong></p>
<p>Since we have a ratio scaled variable (i.e., listening times) and two observations of the same group of users (i.e., the groups contain the same units), the dependent-means t-test is appropriate.</p>
<p><strong>3. Choose the level of significance</strong></p>
<p>We choose the conventional 5% significance level.</p>
<p><strong>4. Descriptive statistics and data visualization</strong></p>
<p>We can compute the descriptive statistics for each month separately, using the <code>describe()</code> function:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="hypothesis-testing.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb274-2"><a href="hypothesis-testing.html#cb274-2" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(hours_a_b_paired)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["vars"],"name":[1],"type":["int"],"align":["right"]},{"label":["n"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["median"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["trimmed"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["mad"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["min"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["max"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["range"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["skew"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["kurtosis"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["se"],"name":[13],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"100","3":"17.93","4":"12.06988","5":"15","6":"16.5875","7":"10.3782","8":"2","9":"65","10":"63","11":"1.0913320","12":"1.2549609","13":"1.206988"},{"1":"2","2":"100","3":"29.58","4":"18.41562","5":"25","6":"27.6250","7":"17.0499","8":"3","9":"83","10":"80","11":"0.8966967","12":"0.5662360","13":"1.841562"},{"1":"3","2":"100","3":"-11.65","4":"21.51503","5":"-9","6":"-10.6000","7":"19.2738","8":"-76","9":"51","10":"127","11":"-0.3750444","12":"0.7209769","13":"2.151503"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>This already shows us that the mean between the two months are different. We can visiualize the data using a plot of means, boxplot, and a histogram.</p>
<p>To plot the data, we need to do some restructuring first, since the variables are now stored in two different columns (“hours_a” and “hours_b”). This is also known as the “wide” format. To plot the data we need all observations to be stored in one variable. This is also known as the “long” format. We can use the <code>melt(...)</code> function from the <code>reshape2</code>package to “melt” the two variable into one column to plot the data.</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="hypothesis-testing.html#cb275-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reshape2)</span>
<span id="cb275-2"><a href="hypothesis-testing.html#cb275-2" aria-hidden="true" tabindex="-1"></a>hours_a_b_paired_long <span class="ot">&lt;-</span> <span class="fu">melt</span>(hours_a_b_paired[, <span class="fu">c</span>(<span class="st">&quot;hours_a&quot;</span>, <span class="st">&quot;hours_b&quot;</span>)]) </span>
<span id="cb275-3"><a href="hypothesis-testing.html#cb275-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(hours_a_b_paired_long) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;group&quot;</span>,<span class="st">&quot;hours&quot;</span>)</span>
<span id="cb275-4"><a href="hypothesis-testing.html#cb275-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(hours_a_b_paired_long)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["group"],"name":[1],"type":["fct"],"align":["left"]},{"label":["hours"],"name":[2],"type":["int"],"align":["right"]}],"data":[{"1":"hours_a","2":"2"},{"1":"hours_a","2":"27"},{"1":"hours_a","2":"25"},{"1":"hours_a","2":"2"},{"1":"hours_a","2":"46"},{"1":"hours_a","2":"13"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Now we are ready to plot the data:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="hypothesis-testing.html#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hours_a_b_paired_long, <span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> hours)) <span class="sc">+</span> </span>
<span id="cb276-2"><a href="hypothesis-testing.html#cb276-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span> </span>
<span id="cb276-3"><a href="hypothesis-testing.html#cb276-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb276-4"><a href="hypothesis-testing.html#cb276-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Listening time (hours)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb276-5"><a href="hypothesis-testing.html#cb276-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Boxplot of listening times&quot;</span>) <span class="sc">+</span></span>
<span id="cb276-6"><a href="hypothesis-testing.html#cb276-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="hypothesis-testing.html#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hours_a_b_paired_long,<span class="fu">aes</span>(hours)) <span class="sc">+</span> </span>
<span id="cb277-2"><a href="hypothesis-testing.html#cb277-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb277-3"><a href="hypothesis-testing.html#cb277-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Listening time (hours)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>) <span class="sc">+</span> </span>
<span id="cb277-4"><a href="hypothesis-testing.html#cb277-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of listening times&quot;</span>) <span class="sc">+</span></span>
<span id="cb277-5"><a href="hypothesis-testing.html#cb277-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>group) <span class="sc">+</span></span>
<span id="cb277-6"><a href="hypothesis-testing.html#cb277-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-40-2.png" width="672" /></p>
<p><strong>5. Conduct significance test</strong></p>
<p>To conduct the independent means t-test, we can use the <code>t.test()</code> function with the argument <code>paired = TRUE</code>:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="hypothesis-testing.html#cb278-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(hours_a_b_paired<span class="sc">$</span>hours_a, hours_a_b_paired<span class="sc">$</span>hours_b, <span class="at">mu =</span> <span class="dv">0</span>, <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>, <span class="at">conf.level =</span> <span class="fl">0.95</span>, <span class="at">paired=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  hours_a_b_paired$hours_a and hours_a_b_paired$hours_b
## t = -5.4148, df = 99, p-value = 0.00000043
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -15.919048  -7.380952
## sample estimates:
## mean of the differences 
##                  -11.65</code></pre>
<p>Again, we could combine the results of the statistical test and the visualization using the <code>ggstatsplot</code> package.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="hypothesis-testing.html#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb280-2"><a href="hypothesis-testing.html#cb280-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggwithinstats</span>(</span>
<span id="cb280-3"><a href="hypothesis-testing.html#cb280-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> hours_a_b_paired_long,</span>
<span id="cb280-4"><a href="hypothesis-testing.html#cb280-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> group,</span>
<span id="cb280-5"><a href="hypothesis-testing.html#cb280-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> hours,</span>
<span id="cb280-6"><a href="hypothesis-testing.html#cb280-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">path.point =</span> <span class="cn">FALSE</span>,</span>
<span id="cb280-7"><a href="hypothesis-testing.html#cb280-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">path.mean =</span> <span class="cn">TRUE</span>,</span>
<span id="cb280-8"><a href="hypothesis-testing.html#cb280-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sort =</span> <span class="st">&quot;descending&quot;</span>, <span class="co"># ordering groups along the x-axis based on</span></span>
<span id="cb280-9"><a href="hypothesis-testing.html#cb280-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">sort.fun =</span> median, <span class="co"># values of `y` variable</span></span>
<span id="cb280-10"><a href="hypothesis-testing.html#cb280-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Mean listening times for different treatments&quot;</span>,</span>
<span id="cb280-11"><a href="hypothesis-testing.html#cb280-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb280-12"><a href="hypothesis-testing.html#cb280-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span>,</span>
<span id="cb280-13"><a href="hypothesis-testing.html#cb280-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.ci =</span> <span class="cn">TRUE</span>,</span>
<span id="cb280-14"><a href="hypothesis-testing.html#cb280-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">effsize.type =</span> <span class="st">&quot;d&quot;</span> <span class="co"># display effect size (Cohen&#39;s d in output)</span></span>
<span id="cb280-15"><a href="hypothesis-testing.html#cb280-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-42-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>6. Report results and draw a marketing conclusion</strong></p>
<p>On average, the same users used the service more when it included the new feature (M = 29.58, SE = 1.84) compared to the service without the feature (M = 17.93, SE = 1.21). This difference was significant t(99) = 5.41, p &lt; .05 (95% CI = [7.38, 15.91]).</p>
</div>
</div>
</div>
<div id="nhst-considerations" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> NHST considerations</h2>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/ctwQn6YYUBM" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<div id="type-i-and-type-ii-errors" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Type I and Type II Errors</h3>
<p>When choosing the level of significance (<span class="math inline">\(\alpha\)</span>). It is important to note that the choice of the significance level affects the type 1 and type 2 error:</p>
<ul>
<li>Type I error: When we believe there is a genuine effect in our population, when in fact there isn’t. Probability of type I error (<span class="math inline">\(\alpha\)</span>) = level of significance.</li>
<li>Type II error: When we believe that there is no effect in the population, when in fact there is.</li>
</ul>
<p>This following table shows the possible outcomes of a test (retain vs. reject <span class="math inline">\(H_0\)</span>), depending on whether <span class="math inline">\(H_0\)</span> is true or false in reality.</p>
<table>
<colgroup>
<col width="16%" />
<col width="41%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th> </th>
<th>Retain <b>H<sub>0</sub></b></th>
<th>Reject <b>H<sub>0</sub></b></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><b>H<sub>0</sub> is true</b></td>
<td>Correct decision:<br>1-α (probability of correct retention);</td>
<td>Type 1 error:<br> α (level of significance)</td>
</tr>
<tr class="even">
<td><b>H<sub>0</sub> is false</b></td>
<td>Type 2 error:<br>β (type 2 error rate)</td>
<td>Correct decision:<br>1-β (power of the test)</td>
</tr>
</tbody>
</table>
</div>
<div id="significance-level-sample-size-power-and-effect-size" class="section level3" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Significance level, sample size, power, and effect size</h3>
<p>When you plan to conduct an experiment, there are some factors that are under direct control of the researcher:</p>
<ul>
<li><strong>Significance level (<span class="math inline">\(\alpha\)</span>)</strong>: The probability of finding an effect that does not genuinely exist.</li>
<li><strong>Sample size (n)</strong>: The number of observations in each group of the experimental design.</li>
</ul>
<p>Unlike α and n, which are specified by the researcher, the magnitude of β depends on the actual value of the population parameter. In addition, β is influenced by the effect size (e.g., Cohen’s d), which can be used to determine a standardized measure of the magnitude of an observed effect. The following parameters are affected more indirectly:</p>
<ul>
<li><strong>Power (1-β)</strong>: The probability of finding an effect that does genuinely exists.</li>
<li><strong>Effect size (d)</strong>: Standardized measure of the effect size under the alternate hypothesis.</li>
</ul>
<p>Although β is unknown, it is related to α. For example, if we would like to be absolutely sure that we do not falsely identify an effect which does not exist (i.e., make a type I error), this means that the probability of identifying an effect that does exist (i.e., 1-β) decreases and vice versa. Thus, an extremely low value of α (e.g., α = 0.0001) will result in intolerably high β errors. A common approach is to set α=0.05 and β=0.80.</p>
<p>Unlike the t-value of our test, the effect size (d) is unaffected by the sample size and can be categorized as follows (see Cohen, J. 1988):</p>
<ul>
<li>0.2 (small effect)</li>
<li>0.5 (medium effect)</li>
<li>0.8 (large effect)</li>
</ul>
<p>In order to test more subtle effects (smaller effect sizes), you need a larger sample size compared to the test of more obvious effects. In <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2205186" target="_blank">this paper</a>, you can find a list of examples for different effect sizes and the number of observations you need to reliably find an effect of that magnitude. Although the exact effect size is unknown before the experiment, you might be able to make a guess about the effect size (e.g., based on previous studies).</p>
<p>If you wish to obtain a standardized measure of the effect, you may compute the effect size (Cohen’s d) using the <code>cohensD()</code> function from the <code>lsr</code> package. Using the examples from the independent-means t-test above, we would use:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="hypothesis-testing.html#cb281-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lsr)</span>
<span id="cb281-2"><a href="hypothesis-testing.html#cb281-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cohensD</span>(hours <span class="sc">~</span> group, <span class="at">data =</span> hours_a_b)</span></code></pre></div>
<pre><code>## [1] 0.6696301</code></pre>
<p>According to the thresholds defined above, this effect would be judged to be a small-medium effect.</p>
<p>For the dependent-means t-test, we would use:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="hypothesis-testing.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cohensD</span>(hours_a_b_paired<span class="sc">$</span>hours_a, hours_a_b_paired<span class="sc">$</span>hours_b, <span class="at">method=</span><span class="st">&quot;paired&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 0.541482</code></pre>
<p>According to the thresholds defined above, this effect would also be judged to be a small-medium effect.</p>
<p>When constructing an experimental design, your goal should be to maximize the power of the test while maintaining an acceptable significance level and keeping the sample as small as possible. To achieve this goal, you may use the <code>pwr</code> package, which let’s you compute <code>n</code>, <code>d</code>, <code>alpha</code>, and <code>power</code>. You only need to specify three of the four input variables to get the fourth.</p>
<p>For example, what sample size do we need (per group) to identify an effect with d = 0.6, α = 0.05, and power = 0.8:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="hypothesis-testing.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pwr)</span>
<span id="cb285-2"><a href="hypothesis-testing.html#cb285-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.t.test</span>(<span class="at">d =</span> <span class="fl">0.6</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>, <span class="at">power =</span> <span class="fl">0.8</span>, <span class="at">type =</span> <span class="fu">c</span>(<span class="st">&quot;two.sample&quot;</span>), <span class="at">alternative =</span> <span class="fu">c</span>(<span class="st">&quot;two.sided&quot;</span>))</span></code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 44.58577
##               d = 0.6
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Or we could ask, what is the power of our test with 51 observations in each group, d = 0.6, and α = 0.05:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="hypothesis-testing.html#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.t.test</span>(<span class="at">n =</span> <span class="dv">51</span>, <span class="at">d =</span> <span class="fl">0.6</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>, <span class="at">type =</span> <span class="fu">c</span>(<span class="st">&quot;two.sample&quot;</span>), <span class="at">alternative =</span> <span class="fu">c</span>(<span class="st">&quot;two.sided&quot;</span>))</span></code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 51
##               d = 0.6
##       sig.level = 0.05
##           power = 0.850985
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
</div>
<div id="p-values-stopping-rules-and-p-hacking" class="section level3" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> P-values, stopping rules and p-hacking</h3>
<p>From my experience, students tend to place a lot of weight on p-values when interpreting their research findings. It is therefore important to note some points that hopefully help to put the meaning of a “significant” vs. “insignificant” test result into perspective. So what does a significant test result actually tell us?</p>
<ul>
<li>The importance of an effect? → No, significance depends on sample size.</li>
<li>That the null hypothesis is false? → No, it is always false.</li>
<li>That the null hypothesis is true? → No, it is never true.</li>
</ul>
<p>It is important to understand what the p-value actually tells you.</p>
<div class="infobox_orange hint">
<p>A p-value of &lt; 0.05 means that the probability of finding a difference of at least the observed magnitude is less than 5% if the null hypothesis was true. In other words, if there really wouldn’t be a difference between the groups, it tells you the probability of observing the difference that you found in your data (or more extreme differences).</p>
</div>
<p>The following points provide some guidance on how to interpret significant and insignificant test results.</p>
<p><strong>Significant result</strong></p>
<ul>
<li>Even if the probability of the effect being a chance result is small (e.g., less than .05) it doesn’t necessarily mean that the effect is important.</li>
<li>Very small and unimportant effects can turn out to be statistically significant if the sample size is large enough.</li>
</ul>
<p><strong>Insignificant result</strong></p>
<ul>
<li>If the probability of the effect occurring by chance is large (greater than .05), the alternative hypothesis is rejected. However, this does not mean that the null hypothesis is true.</li>
<li>Although an effect might not be large enough to be anything other than a chance finding, it doesn’t mean that the effect is zero.</li>
<li>In fact, two random samples will always have slightly different means that would deemed to be statistically significant if the samples were large enough.</li>
</ul>
<p>Thus, you should not base your research conclusion on p-values alone!</p>
<p>It is also crucial to <strong>determine the sample size before you run the experiment</strong> or before you start your analysis. Why? Consider the following example:</p>
<ul>
<li>You run an experiment</li>
<li>After each respondent you analyze the data and look at the mean difference between the two groups with a t-test</li>
<li>You stop when you have a significant effect</li>
</ul>
<p>This is called p-hacking and should be avoided at all costs. Assuming that both groups come from the same population (i.e., there is <strong>no difference</strong> in the means): What is the likelihood that the result will be significant at some point? In other words, what is the likelihood that you will draw the wrong conclusion from your data that there is an effect, while there is none? This is shown in the following graph using simulated data - the color red indicates significant test results that arise although there is no effect (i.e., false positives).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-47"></span>
<img src="07-hypothesis_testing_files/figure-html/unnamed-chunk-47-1.png" alt="p-hacking (red indicates false positives)" width="672" />
<p class="caption">
Figure 6.1: p-hacking (red indicates false positives)
</p>
</div>

</div>
</div>
<div id="comparing-several-means" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Comparing several means</h2>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/9cGZcALfU5k" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<div class="infobox download">
<p><a href="./Code/07-anova.R">You can download the corresponding R-Code here</a></p>
</div>
<div id="introduction-2" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Introduction</h3>
<p>In the previous section we learned how to compare two means using a t-test. The t-test has some limitations since it only lets you compare two means and you can only use it with one independent variable. However, often we would like to compare means from 3 or more groups. In addition, there may be instances in which you manipulate more than one independent variable. For these applications, ANOVA (<u>AN</u>alysis <u>O</u>f <u>VA</u>riance) can be used. Hence, to conduct ANOVA you need:</p>
<ul>
<li>A metric dependent variable (i.e., measured using an interval or ratio scale)</li>
<li>One or more non-metric (categorical) independent variables (also called factors)</li>
</ul>
<p>A <strong>treatment</strong> is a particular combination of factor levels, or categories. So-called <strong>one-way ANOVA</strong> is used when there is only one categorical variable (factor). In this case, a treatment is the same as a factor level. <strong>N-way ANOVA</strong> is used with two or more factors. Note that we are only going to talk about a single independent variable in the context of ANOVA on this website. If you have multiple independent variables please refer to the chapter on <strong>Regression</strong>.</p>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/cG0HAWqObJs" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>Let’s use an example to see how ANOVA works. Similar to the previous example, imagine that the music streaming service experiments with a recommender system and manipulates the intensity of personalized recommendations using three levels: ‘low,’ ‘medium,’ and ‘high.’ The service randomly assigns 100 users to each condition and records the listening times in hours in the following week. As always, we load and inspect the data first:</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="hypothesis-testing.html#cb289-1" aria-hidden="true" tabindex="-1"></a>hours_abc <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/MRDA2018/master/data/hours_abc.dat&quot;</span>, </span>
<span id="cb289-2"><a href="hypothesis-testing.html#cb289-2" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">sep =</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>, </span>
<span id="cb289-3"><a href="hypothesis-testing.html#cb289-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">header =</span> <span class="cn">TRUE</span>) <span class="co">#read in data</span></span>
<span id="cb289-4"><a href="hypothesis-testing.html#cb289-4" aria-hidden="true" tabindex="-1"></a>hours_abc<span class="sc">$</span>group <span class="ot">&lt;-</span> <span class="fu">factor</span>(hours_abc<span class="sc">$</span>group, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;B&quot;</span>,<span class="st">&quot;C&quot;</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;low&quot;</span>, <span class="st">&quot;medium&quot;</span>,<span class="st">&quot;high&quot;</span>)) <span class="co">#convert grouping variable to factor</span></span>
<span id="cb289-5"><a href="hypothesis-testing.html#cb289-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(hours_abc) <span class="co">#inspect data</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    300 obs. of  3 variables:
##  $ hours: int  18 13 3 13 20 18 18 10 11 20 ...
##  $ group: Factor w/ 3 levels &quot;low&quot;,&quot;medium&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ index: int  1 2 3 4 5 6 7 8 9 10 ...</code></pre>
<p>The null hypothesis, typically, is that all means are equal (non-directional hypothesis). Hence, in our case:</p>
<p><span class="math display">\[H_0: \mu_1 = \mu_2 = \mu_3\]</span></p>
<p>The alternative hypothesis is simply that the means are not all equal, i.e.,</p>
<p><span class="math display">\[H_1: \textrm{Means are not all equal}\]</span></p>
<p>If you wanted to put this in mathematical notation, you could also write:</p>
<p><span class="math display">\[H_1: \exists {i,j}: {\mu_i \ne \mu_j} \]</span></p>
<p>To get a first impression if there are any differences in listening times across the experimental groups, we use the <code>describeBy(...)</code> function from the <code>psych</code> package:</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="hypothesis-testing.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb291-2"><a href="hypothesis-testing.html#cb291-2" aria-hidden="true" tabindex="-1"></a><span class="fu">describeBy</span>(hours_abc<span class="sc">$</span>hours, hours_abc<span class="sc">$</span>group) <span class="co">#inspect data</span></span></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: low
##    vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 100 14.34 4.62     14   14.36 4.45   3  25    22 -0.03    -0.32 0.46
## ------------------------------------------------------------ 
## group: medium
##    vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 100 24.7 5.81     25   24.79 5.93  12  42    30 0.05      0.2 0.58
## ------------------------------------------------------------ 
## group: high
##    vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 100 34.99 6.42   34.5   35.02 6.67  17  50    33 -0.05    -0.23 0.64</code></pre>
<p>In addition, you should visualize the data using appropriate plots. Appropriate plots in this case would be a plot of means, including the 95% confidence interval around the mean, or a boxplot.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="hypothesis-testing.html#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot of mean</span></span>
<span id="cb293-2"><a href="hypothesis-testing.html#cb293-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Rmisc)</span>
<span id="cb293-3"><a href="hypothesis-testing.html#cb293-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb293-4"><a href="hypothesis-testing.html#cb293-4" aria-hidden="true" tabindex="-1"></a>mean_data <span class="ot">&lt;-</span> <span class="fu">summarySE</span>(hours_abc, <span class="at">measurevar=</span><span class="st">&quot;hours&quot;</span>, <span class="at">groupvars=</span><span class="fu">c</span>(<span class="st">&quot;group&quot;</span>))</span>
<span id="cb293-5"><a href="hypothesis-testing.html#cb293-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mean_data,<span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> hours)) <span class="sc">+</span> </span>
<span id="cb293-6"><a href="hypothesis-testing.html#cb293-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>), <span class="at">colour=</span><span class="st">&quot;black&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;#CCCCCC&quot;</span>, <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">width =</span> <span class="fl">0.65</span>) <span class="sc">+</span></span>
<span id="cb293-7"><a href="hypothesis-testing.html#cb293-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>), <span class="at">width=</span>.<span class="dv">15</span>, <span class="fu">aes</span>(<span class="at">ymin=</span>hours<span class="sc">-</span>ci, <span class="at">ymax=</span>hours<span class="sc">+</span>ci)) <span class="sc">+</span></span>
<span id="cb293-8"><a href="hypothesis-testing.html#cb293-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb293-9"><a href="hypothesis-testing.html#cb293-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Average number of hours&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Average number of hours by group&quot;</span>)<span class="sc">+</span></span>
<span id="cb293-10"><a href="hypothesis-testing.html#cb293-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb293-11"><a href="hypothesis-testing.html#cb293-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">&quot;#666666&quot;</span>)) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-6-1.png" alt="Plot of means" width="672" />
<p class="caption">
Figure 5.1: Plot of means
</p>
</div>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="hypothesis-testing.html#cb294-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hours_abc,<span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> hours)) <span class="sc">+</span> </span>
<span id="cb294-2"><a href="hypothesis-testing.html#cb294-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb294-3"><a href="hypothesis-testing.html#cb294-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb294-4"><a href="hypothesis-testing.html#cb294-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb294-5"><a href="hypothesis-testing.html#cb294-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Average number of hours&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Average number of hours by group&quot;</span>)<span class="sc">+</span></span>
<span id="cb294-6"><a href="hypothesis-testing.html#cb294-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb294-7"><a href="hypothesis-testing.html#cb294-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">&quot;#666666&quot;</span>)) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-7"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-7-1.png" alt="Boxplot" width="672" />
<p class="caption">
Figure 1.5: Boxplot
</p>
</div>
<p>Note that ANOVA is an omnibus test, which means that we test for an overall difference between groups. Hence, the test will only tell you if the group means are different, but it won’t tell you exactly which groups are different from another.</p>
<p>So why don’t we then just conduct a series of t-tests for all combinations of groups (i.e., “low” vs. “medium,” “low” vs. “high,” “medium” vs. “high”)? The reason is that if we assume each test to be independent, then there is a 5% probability of falsely rejecting the null hypothesis (Type I error) for each test. In our case:</p>
<ul>
<li>“low” vs. “medium” (α = 0.05)</li>
<li>“low” vs. “high” (α = 0.05)</li>
<li>“medium” vs. “high” (α = 0.05)</li>
</ul>
<p>This means that the overall probability of making a Type I error is 1-(0.95<sup>3</sup>) = 0.143, since the probability of no Type I error is 0.95 for each of the three tests. Consequently, the Type I error probability would be 14.3%, which is above the conventional standard of 5%. This is also known as the family-wise or experiment-wise error.</p>
</div>
<div id="decomposing-variance" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Decomposing variance</h3>
<p>The basic concept underlying ANOVA is the decomposition of the variance in the data. There are three variance components which we need to consider:</p>
<ul>
<li>We calculate how much variability there is overall between scores: <b>Total sum of squares (SS<sub>T</sub>)</b></li>
<li>We then calculate how much of this variability can be explained by the model we fit to the data (i.e., how much variability is due to the experimental manipulation): <b>Model sum of squares (SS<sub>M</sub>)</b></li>
<li>… and how much cannot be explained (i.e., how much variability is due to individual differences in performance): <b>Residual sum of squares (SS<sub>R</sub>)</b></li>
</ul>
<p>The following figure shows the different variance components using a generalized data matrix:</p>
<p style="text-align:center;">
<img src="https://github.com/IMSMWU/Teaching/raw/master/MRDA2017/sum_of_squares.JPG" alt="decomposing_variance"/>
</p>
<p>The total variation is determined by the variation between the categories (due to our experimental manipulation) and the within-category variation that is due to extraneous factors (e.g., unobserved factors such as the promotion of artists on a social network):</p>
<p><span class="math display">\[SS_T= SS_M+SS_R\]</span></p>
<p>To get a better feeling how this relates to our data set, we can look at the data in a slightly different way. Specifically, we can use the <code>dcast(...)</code> function from the <code>reshape2</code> package to convert the data to wide format:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="hypothesis-testing.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reshape2)</span>
<span id="cb295-2"><a href="hypothesis-testing.html#cb295-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dcast</span>(hours_abc, index <span class="sc">~</span> group, <span class="at">value.var =</span> <span class="st">&quot;hours&quot;</span>)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["index"],"name":[1],"type":["int"],"align":["right"]},{"label":["low"],"name":[2],"type":["int"],"align":["right"]},{"label":["medium"],"name":[3],"type":["int"],"align":["right"]},{"label":["high"],"name":[4],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"18","3":"26","4":"34"},{"1":"2","2":"13","3":"32","4":"34"},{"1":"3","2":"3","3":"29","4":"32"},{"1":"4","2":"13","3":"31","4":"25"},{"1":"5","2":"20","3":"13","4":"35"},{"1":"6","2":"18","3":"31","4":"20"},{"1":"7","2":"18","3":"26","4":"30"},{"1":"8","2":"10","3":"21","4":"33"},{"1":"9","2":"11","3":"31","4":"31"},{"1":"10","2":"20","3":"24","4":"42"},{"1":"11","2":"23","3":"13","4":"40"},{"1":"12","2":"14","3":"21","4":"44"},{"1":"13","2":"25","3":"31","4":"39"},{"1":"14","2":"16","3":"21","4":"33"},{"1":"15","2":"14","3":"28","4":"27"},{"1":"16","2":"14","3":"39","4":"48"},{"1":"17","2":"22","3":"22","4":"32"},{"1":"18","2":"23","3":"27","4":"35"},{"1":"19","2":"20","3":"28","4":"32"},{"1":"20","2":"15","3":"19","4":"35"},{"1":"21","2":"19","3":"20","4":"44"},{"1":"22","2":"16","3":"20","4":"32"},{"1":"23","2":"15","3":"26","4":"39"},{"1":"24","2":"15","3":"26","4":"35"},{"1":"25","2":"6","3":"12","4":"42"},{"1":"26","2":"12","3":"25","4":"29"},{"1":"27","2":"12","3":"23","4":"45"},{"1":"28","2":"15","3":"24","4":"27"},{"1":"29","2":"11","3":"24","4":"35"},{"1":"30","2":"10","3":"22","4":"38"},{"1":"31","2":"14","3":"16","4":"44"},{"1":"32","2":"5","3":"14","4":"39"},{"1":"33","2":"13","3":"29","4":"38"},{"1":"34","2":"12","3":"32","4":"44"},{"1":"35","2":"22","3":"29","4":"17"},{"1":"36","2":"16","3":"20","4":"38"},{"1":"37","2":"7","3":"32","4":"34"},{"1":"38","2":"20","3":"34","4":"31"},{"1":"39","2":"13","3":"27","4":"29"},{"1":"40","2":"21","3":"26","4":"46"},{"1":"41","2":"13","3":"20","4":"36"},{"1":"42","2":"13","3":"23","4":"32"},{"1":"43","2":"12","3":"42","4":"35"},{"1":"44","2":"5","3":"19","4":"30"},{"1":"45","2":"17","3":"26","4":"27"},{"1":"46","2":"18","3":"32","4":"44"},{"1":"47","2":"12","3":"29","4":"40"},{"1":"48","2":"8","3":"22","4":"31"},{"1":"49","2":"5","3":"25","4":"21"},{"1":"50","2":"18","3":"24","4":"29"},{"1":"51","2":"18","3":"28","4":"29"},{"1":"52","2":"19","3":"38","4":"32"},{"1":"53","2":"12","3":"26","4":"33"},{"1":"54","2":"11","3":"16","4":"28"},{"1":"55","2":"13","3":"21","4":"44"},{"1":"56","2":"16","3":"27","4":"37"},{"1":"57","2":"5","3":"24","4":"33"},{"1":"58","2":"17","3":"28","4":"45"},{"1":"59","2":"9","3":"28","4":"41"},{"1":"60","2":"8","3":"24","4":"33"},{"1":"61","2":"11","3":"32","4":"31"},{"1":"62","2":"12","3":"25","4":"42"},{"1":"63","2":"13","3":"18","4":"31"},{"1":"64","2":"10","3":"29","4":"25"},{"1":"65","2":"15","3":"25","4":"43"},{"1":"66","2":"16","3":"20","4":"38"},{"1":"67","2":"22","3":"18","4":"40"},{"1":"68","2":"10","3":"28","4":"36"},{"1":"69","2":"16","3":"27","4":"25"},{"1":"70","2":"18","3":"32","4":"30"},{"1":"71","2":"12","3":"22","4":"36"},{"1":"72","2":"22","3":"21","4":"46"},{"1":"73","2":"13","3":"28","4":"33"},{"1":"74","2":"14","3":"30","4":"39"},{"1":"75","2":"10","3":"30","4":"40"},{"1":"76","2":"9","3":"12","4":"31"},{"1":"77","2":"9","3":"21","4":"39"},{"1":"78","2":"11","3":"23","4":"43"},{"1":"79","2":"17","3":"22","4":"36"},{"1":"80","2":"17","3":"17","4":"37"},{"1":"81","2":"16","3":"29","4":"46"},{"1":"82","2":"14","3":"29","4":"28"},{"1":"83","2":"16","3":"22","4":"30"},{"1":"84","2":"14","3":"12","4":"31"},{"1":"85","2":"19","3":"23","4":"32"},{"1":"86","2":"24","3":"32","4":"31"},{"1":"87","2":"17","3":"21","4":"29"},{"1":"88","2":"12","3":"18","4":"50"},{"1":"89","2":"12","3":"27","4":"37"},{"1":"90","2":"17","3":"31","4":"32"},{"1":"91","2":"14","3":"23","4":"41"},{"1":"92","2":"20","3":"21","4":"36"},{"1":"93","2":"10","3":"27","4":"33"},{"1":"94","2":"13","3":"17","4":"40"},{"1":"95","2":"12","3":"21","4":"25"},{"1":"96","2":"20","3":"22","4":"38"},{"1":"97","2":"9","3":"25","4":"31"},{"1":"98","2":"16","3":"28","4":"28"},{"1":"99","2":"12","3":"27","4":"39"},{"1":"100","2":"17","3":"19","4":"34"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>In this example, X<sub>1</sub> from the generalized data matrix above would refer to the factor level “low,” X<sub>2</sub> to the level “medium,” and X<sub>3</sub> to the level “high.” Y<sub>11</sub> refers to the first data point in the first row (i.e., “13”), Y<sub>12</sub> to the second data point in the first row (i.e., “21”), etc.. The grand mean (<span class="math inline">\(\overline{Y}\)</span>) and the category means (<span class="math inline">\(\overline{Y}_c\)</span>) can be easily computed:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="hypothesis-testing.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(hours_abc<span class="sc">$</span>hours) <span class="co">#grand mean</span></span></code></pre></div>
<pre><code>## [1] 24.67667</code></pre>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="hypothesis-testing.html#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="fu">by</span>(hours_abc<span class="sc">$</span>hours, hours_abc<span class="sc">$</span>group, mean) <span class="co">#category mean</span></span></code></pre></div>
<pre><code>## hours_abc$group: low
## [1] 14.34
## ------------------------------------------------------------ 
## hours_abc$group: medium
## [1] 24.7
## ------------------------------------------------------------ 
## hours_abc$group: high
## [1] 34.99</code></pre>
<p>To see how each variance component can be derived, let’s look at the data again. The following graph shows the individual observations by experimental group:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-10-1.png" alt="Sum of Squares" width="672" />
<p class="caption">
Figure 1.8: Sum of Squares
</p>
</div>
<div id="total-sum-of-squares" class="section level4" number="6.5.2.1">
<h4><span class="header-section-number">6.5.2.1</span> Total sum of squares</h4>
<p>To compute the total variation in the data, we consider the difference between each observation and the grand mean. The grand mean is the mean over all observations in the data set. The vertical lines in the following plot measure how far each observation is away from the grand mean:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-11-1.png" alt="Total Sum of Squares" width="672" />
<p class="caption">
Figure 1.9: Total Sum of Squares
</p>
</div>
<p>The formal representation of the total sum of squares (SS<sub>T</sub>) is:</p>
<p><span class="math display">\[
SS_T= \sum_{i=1}^{N} (Y_i-\bar{Y})^2
\]</span></p>
<p>This means that we need to subtract the grand mean from each individual data point, square the difference, and sum up over all the squared differences. Thus, in our example, the total sum of squares can be calculated as:</p>
<p><span class="math display">\[ 
\begin{align}
SS_T =&amp;(13−24.67)^2 + (14−24.67)^2 + … + (2−24.67)^2\\
      &amp;+(21−24.67)^2 + (18-24.67)^2 + … + (17−24.67)^2\\
      &amp;+(30−24.67)^2 + (37−24.67)^2 + … + (28−24.67)^2\\ 
      &amp;=30855.64
\end{align}
\]</span></p>
<p>You could also compute this in R using:</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="hypothesis-testing.html#cb300-1" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>((hours_abc<span class="sc">$</span>hours <span class="sc">-</span> <span class="fu">mean</span>(hours_abc<span class="sc">$</span>hours))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb300-2"><a href="hypothesis-testing.html#cb300-2" aria-hidden="true" tabindex="-1"></a>SST</span></code></pre></div>
<pre><code>## [1] 30855.64</code></pre>
<p>For the subsequent analyses, it is important to understand the concept behind the <b>degrees of freedom</b> (df). Remember that in order to estimate a population value from a sample, we need to hold something in the population constant. In ANOVA, the df are generally one less than the number of values used to calculate the SS. For example, when we estimate the population mean from a sample, we assume that the sample mean is equal to the population mean. Then, in order to estimate the population mean from the sample, all but one scores are free to vary and the remaining score needs to be the value that keeps the population mean constant. Thus, the degrees of freedom of an estimate can also be thought of as the number of independent pieces of information that went into calculating the estimate. In our example, we used all 300 observations to calculate the sum of square, so the total degrees of freedom (df<sub>T</sub>) are:</p>
<p><span class="math display" id="eq:dfT">\[\begin{equation} 
\begin{split}
df_T = N-1=300-1=299
\end{split}
\tag{6.1}
\end{equation}\]</span></p>
<div class="infobox_orange hint">
<p>Why do we subtract 1 from the number of items when computing the <strong>degrees of freedom</strong>? As mentioned above, the degrees of freedom refer to the number of values that are free to vary in a data set. To understand what this means, imagine that we try to estimate the mean hours of music listening in a population and that mean is 20 hours. We could take different samples from the population and we assume that the sample mean is equal to the population mean. Imagine, we only take three small samples of 3 students each: i) 19, 20, 21, ii) 18, 20, 22, iii) 15, 20, 25. Once you have chosen the first two values in each set, the third item cannot be chosen freely (i.e., it is fixed) because it needs to be the value that gets you to the population mean. Hence, only the first two values are ‘free to vary.’ You can select 19 + 20 or 15 + 25, but once you have chosen the first two values, you must choose a particular value that will give you the population mean you are looking for (i.e., 20 hours). In this case, the degrees of freedom for each set of three numbers is two.</p>
</div>
</div>
<div id="model-sum-of-squares" class="section level4" number="6.5.2.2">
<h4><span class="header-section-number">6.5.2.2</span> Model sum of squares</h4>
<p>Now we know that there are 30855.64 units of total variation in our data. Next, we compute how much of the total variation can be explained by the differences between groups (i.e., our experimental manipulation). To compute the explained variation in the data, we consider the difference between the values predicted by our model for each observation (i.e., the group mean) and the grand mean. The group mean refers to the mean value within the experimental group. The vertical lines in the following plot measure how far the predicted value for each observation (i.e., the group mean) is away from the grand mean:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-13"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-13-1.png" alt="Model Sum of Squares" width="672" />
<p class="caption">
Figure 1.11: Model Sum of Squares
</p>
</div>
<p>The formal representation of the model sum of squares (SS<sub>M</sub>) is:</p>
<p><span class="math display">\[
SS_M= \sum_{j=1}^{c} n_j(\bar{Y}_j-\bar{Y})^2
\]</span></p>
<p>where c denotes the number of categories (experimental groups). This means that we need to subtract the grand mean from each group mean, square the difference, and sum up over all the squared differences. Thus, in our example, the model sum of squares can be calculated as:</p>
<p><span class="math display">\[ 
\begin{align}
SS_M &amp;= 100*(15.47−24.67)^2 + 100*(24.88−24.67)^2 + 100*(33.66−24.67)^2 \\
     &amp;= 21321.21
\end{align}
\]</span></p>
<p>You could also compute this manually in R using:</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="hypothesis-testing.html#cb302-1" aria-hidden="true" tabindex="-1"></a>SSM <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="dv">100</span><span class="sc">*</span>(<span class="fu">by</span>(hours_abc<span class="sc">$</span>hours, hours_abc<span class="sc">$</span>group, mean) <span class="sc">-</span> <span class="fu">mean</span>(hours_abc<span class="sc">$</span>hours))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb302-2"><a href="hypothesis-testing.html#cb302-2" aria-hidden="true" tabindex="-1"></a>SSM</span></code></pre></div>
<pre><code>## [1] 21321.21</code></pre>
<p>In this case, we used the three group means to calculate the sum of squares, so the model degrees of freedom (df<sub>M</sub>) are:</p>
<p><span class="math display">\[
df_M= c-1=3-1=2
\]</span></p>
</div>
<div id="residual-sum-of-squares" class="section level4" number="6.5.2.3">
<h4><span class="header-section-number">6.5.2.3</span> Residual sum of squares</h4>
<p>Lastly, we calculate the amount of variation that cannot be explained by our model. In ANOVA, this is the sum of squared distances between what the model predicts for each data point (i.e., the group means) and the observed values. In other words, this refers to the amount of variation that is caused by extraneous factors, such as differences between product characteristics of the products in the different experimental groups. The vertical lines in the following plot measure how far each observation is away from the group mean:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-15"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-15-1.png" alt="Residual Sum of Squares" width="672" />
<p class="caption">
Figure 1.13: Residual Sum of Squares
</p>
</div>
<p>The formal representation of the residual sum of squares (SS<sub>R</sub>) is:</p>
<p><span class="math display">\[
SS_R= \sum_{j=1}^{c} \sum_{i=1}^{n} ({Y}_{ij}-\bar{Y}_{j})^2
\]</span></p>
<p>This means that we need to subtract the group mean from each individual observation, square the difference, and sum up over all the squared differences. Thus, in our example, the model sum of squares can be calculated as:</p>
<p><span class="math display">\[ 
\begin{align}
SS_R =&amp; (13−14.34)^2 + (14−14.34)^2 + … + (2−14.34)^2 \\
     +&amp;(21−24.7)^2 + (18−24.7)^2 + … + (17−24.7)^2 \\
     +&amp; (30−34.99)^2 + (37−34.99)^2 + … + (28−34.99)^2 \\
     =&amp;  9534.43
\end{align}
\]</span></p>
<p>You could also compute this in R using:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="hypothesis-testing.html#cb304-1" aria-hidden="true" tabindex="-1"></a>SSR <span class="ot">&lt;-</span> <span class="fu">sum</span>((hours_abc<span class="sc">$</span>hours <span class="sc">-</span> <span class="fu">rep</span>(<span class="fu">by</span>(hours_abc<span class="sc">$</span>hours, hours_abc<span class="sc">$</span>group, mean), <span class="at">each =</span> <span class="dv">100</span>))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb304-2"><a href="hypothesis-testing.html#cb304-2" aria-hidden="true" tabindex="-1"></a>SSR</span></code></pre></div>
<pre><code>## [1] 9534.43</code></pre>
<p>In this case, we used the 10 values for each of the SS for each group, so the residual degrees of freedom (df<sub>R</sub>) are:</p>
<p><span class="math display">\[
\begin{align}
df_R=&amp; (n_1-1)+(n_2-1)+(n_3-1) \\
    =&amp;(100-1)+(100-1)+(100-1)=297
\end{align}
\]</span></p>
</div>
<div id="effect-strength" class="section level4" number="6.5.2.4">
<h4><span class="header-section-number">6.5.2.4</span> Effect strength</h4>
<p>Once you have computed the different sum of squares, you can investigate the effect strength. <span class="math inline">\(\eta^2\)</span> is a measure of the variation in Y that is explained by X:</p>
<p><span class="math display">\[
\eta^2= \frac{SS_M}{SS_T}=\frac{21321.21}{30855.64}=0.69
\]</span></p>
<p>To compute this in R:</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="hypothesis-testing.html#cb306-1" aria-hidden="true" tabindex="-1"></a>eta <span class="ot">&lt;-</span> SSM<span class="sc">/</span>SST</span>
<span id="cb306-2"><a href="hypothesis-testing.html#cb306-2" aria-hidden="true" tabindex="-1"></a>eta</span></code></pre></div>
<pre><code>## [1] 0.6909988</code></pre>
<p>The statistic can only take values between 0 and 1. It is equal to 0 when all the category means are equal, indicating that X has no effect on Y. In contrast, it has a value of 1 when there is no variability within each category of X but there is some variability between categories. You can think of it as the equivalent to the R-squared statistic in regression model since it also represents a measure of the share of explained variance.</p>
</div>
<div id="test-of-significance" class="section level4" number="6.5.2.5">
<h4><span class="header-section-number">6.5.2.5</span> Test of significance</h4>
<p>How can we determine whether the effect of X on Y is significant?</p>
<ul>
<li>First, we calculate the fit of the most basic model (i.e., the grand mean)</li>
<li>Then, we calculate the fit of the “best” model (i.e., the group means)</li>
<li>A good model should fit the data significantly better than the basic model</li>
<li>The F-statistic, or F-ratio, compares the amount of systematic variance in the data to the amount of unsystematic variance</li>
</ul>
<p>The F-statistic uses the ratio of mean square related to X (explained variation) and the mean square related to the error (unexplained variation):</p>
<p><span class="math display">\[\frac{SS_M}{SS_R}\]</span></p>
<p>However, since these are summed values, their magnitude is influenced by the number of scores that were summed. For example, to calculate SS<sub>M</sub> we only used the sum of 3 values (the group means), while we used 300 values to calculate SS<sub>T</sub> and SS<sub>R</sub>, respectively. Thus, we calculate the average sum of squares (“mean square”) to compare the average amount of systematic vs. unsystematic variation by dividing the SS values by the degrees of freedom associated with the respective statistic.</p>
<p>Mean square due to X:</p>
<p><span class="math display">\[
MS_M= \frac{SS_M}{df_M}=\frac{SS_M}{c-1}=\frac{21321.21}{(3-1)}
\]</span></p>
<p>Mean square due to error:</p>
<p><span class="math display">\[
MS_R= \frac{SS_R}{df_R}=\frac{SS_R}{N-c}=\frac{9534.43}{(300-3)}
\]</span></p>
<p>Now, we compare the amount of variability explained by the model (experiment), to the error in the model (variation due to extraneous variables). If the model explains more variability than it can’t explain, then the experimental manipulation has had a significant effect on the outcome (DV). The F-ratio can be derived as follows:</p>
<p><span class="math display">\[
F= \frac{MS_M}{MS_R}=\frac{\frac{SS_M}{c-1}}{\frac{SS_R}{N-c}}=\frac{\frac{21321.21}{(3-1)}}{\frac{9534.43}{(300-3)}}=332.08
\]</span></p>
<p>You can easily compute this in R:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="hypothesis-testing.html#cb308-1" aria-hidden="true" tabindex="-1"></a>f_ratio <span class="ot">&lt;-</span> (SSM<span class="sc">/</span><span class="dv">2</span>)<span class="sc">/</span>(SSR<span class="sc">/</span><span class="dv">297</span>)</span>
<span id="cb308-2"><a href="hypothesis-testing.html#cb308-2" aria-hidden="true" tabindex="-1"></a>f_ratio</span></code></pre></div>
<pre><code>## [1] 332.0806</code></pre>
<p>Similar to the t-test, the outcome of the significance test will be one of the following:</p>
<ul>
<li>If the null hypothesis of equal category means is not rejected, then the independent variable does not have a significant effect on the dependent variable</li>
<li>If the null hypothesis is rejected, then the effect of the independent variable is significant</li>
</ul>
<p>To decide which one it is, we proceed as with the t-test. That is, we calculate the test statistic and compare it to the critical value for a given level of confidence. If the calculated test statistic is larger than the critical value, we can reject the null hypothesis of equal group means and conclude that the independent variable has a significant effect on our outcome. In this case, however, the test statistic follows a F distribution (instead of the t-distribution) with (m = c – 1) and (n = N – c) degrees of freedom. This means that the shape of the F-distribution depends on the degrees of freedom. In this case, the shape depends on the degrees of freedom associated with the numerator and denominator used to compute the F-ratio. The following figure shows the shape of the F-distribution for different degrees of freedom:</p>
<div class="figure">
<img src="fdistributions.png" alt="" />
<p class="caption">The F distribution</p>
</div>
<p>For 2 and 297 degrees of freedom, the critical value of F is 3.026 for α=0.05. As usual, you can either look up these values in a table or use the appropriate function in R:</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="hypothesis-testing.html#cb310-1" aria-hidden="true" tabindex="-1"></a>f_crit <span class="ot">&lt;-</span> <span class="fu">qf</span>(.<span class="dv">95</span>, <span class="at">df1 =</span> <span class="dv">2</span>, <span class="at">df2 =</span> <span class="dv">297</span>) <span class="co">#critical value</span></span>
<span id="cb310-2"><a href="hypothesis-testing.html#cb310-2" aria-hidden="true" tabindex="-1"></a>f_crit </span></code></pre></div>
<pre><code>## [1] 3.026153</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="hypothesis-testing.html#cb312-1" aria-hidden="true" tabindex="-1"></a>f_ratio <span class="sc">&gt;</span> f_crit <span class="co">#test if calculated test statistic is larger than critical value</span></span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>The output tells us that the calculated test statistic exceeds the critical value. We can also show the test result visually:</p>
<div class="figure">
<img src="ftest.png" alt="" />
<p class="caption">Visual depiction of the test result</p>
</div>
<p>Thus, we conclude that because F<sub>CAL</sub> = 332.08 &gt; F<sub>CR</sub> = 3.03, H<sub>0</sub> is rejected!</p>
<p>Now we can interpret our findings as follows: one or more of the differences between means are statistically significant.</p>
<div class="infobox_red caution">
<p>Remember: The ANOVA tests for an overall difference in means between the groups. It doesn’t tell us where the differences between groups lie, e.g., whether group “low” is different from “medium” or “high” is different from “medium” or “high” is different from “low.” To find out which group means exactly differ, we need to use post-hoc procedures, which are described below. However, when the ANOVA tells you that the there is no differences between the means, then you also shouldn’t proceed to conduct post-hoc tests. In other words, you should only proceed to conduct post-hoc tests when you found a significant overall effect in your ANOVA.</p>
</div>
<p>Finally, you should report your findings in an appropriate way. You could do this by saying: There was a significant effect of playlists and personalized recommendations on listening times, F(2,297) = 332.08, p &lt; 0.05, <span class="math inline">\(\eta^2\)</span> = 0.69.</p>
<p>As usual, you don’t have to compute these statistics manually! Luckily, there is a function for ANOVA in R, which does the above calculations for you as we will see in the next section.</p>
</div>
</div>
<div id="one-way-anova" class="section level3" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> One-way ANOVA</h3>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/ElghkF6rwBQ" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<div id="basic-anova" class="section level4" number="6.5.3.1">
<h4><span class="header-section-number">6.5.3.1</span> Basic ANOVA</h4>
<p>As already indicated, one-way ANOVA is used when there is only one categorical variable (factor). Before conducting ANOVA, you need to check if the assumptions of the test are fulfilled. The assumptions of ANOVA are discussed in the following sections.</p>
<div id="independence-of-observations" class="section level5 unnumbered">
<h5>Independence of observations</h5>
<p>The observations in the groups should be independent. Because we randomly assigned the listeners to the experimental conditions, this assumption can be assumed to be met.</p>
</div>
<div id="distributional-assumptions" class="section level5 unnumbered">
<h5>Distributional assumptions</h5>
<p>ANOVA is relatively immune to violations to the normality assumption when sample sizes are large due to the Central Limit Theorem. However, if your sample is small (i.e., n &lt; 30 per group) you may nevertheless want to check the normality of your data, e.g., by using the Shapiro-Wilk test or QQ-Plot. In our example, we have 100 observations in each group which is plenty but let’s create another example with only 10 observations in each group. In the latter case we cannot rely on the Central Limit Theorem and we should test the normality of our data. This can be done using the Shapiro-Wilk Test, which has the Null Hypothesis that the data is normally distributed. Hence, an insignificant test results means that the data can be assumed to be approximately normally distributed:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="hypothesis-testing.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb314-2"><a href="hypothesis-testing.html#cb314-2" aria-hidden="true" tabindex="-1"></a>hours_fewobs <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">hours =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">5</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">40</span>, <span class="dv">5</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">60</span>, <span class="dv">5</span>)),</span>
<span id="cb314-3"><a href="hypothesis-testing.html#cb314-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">group =</span>  <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&#39;low&#39;</span>, <span class="dv">10</span>), <span class="fu">rep</span>(<span class="st">&#39;medium&#39;</span>, <span class="dv">10</span>), <span class="fu">rep</span>(<span class="st">&#39;high&#39;</span>, <span class="dv">10</span>)))</span>
<span id="cb314-4"><a href="hypothesis-testing.html#cb314-4" aria-hidden="true" tabindex="-1"></a><span class="fu">by</span>(hours_fewobs<span class="sc">$</span>hours, hours_fewobs<span class="sc">$</span>group, shapiro.test)</span></code></pre></div>
<pre><code>## hours_fewobs$group: high
## 
##  Shapiro-Wilk normality test
## 
## data:  dd[x, ]
## W = 0.9595, p-value = 0.7801
## 
## ------------------------------------------------------------ 
## hours_fewobs$group: low
## 
##  Shapiro-Wilk normality test
## 
## data:  dd[x, ]
## W = 0.91625, p-value = 0.3267
## 
## ------------------------------------------------------------ 
## hours_fewobs$group: medium
## 
##  Shapiro-Wilk normality test
## 
## data:  dd[x, ]
## W = 0.91486, p-value = 0.3161</code></pre>
<p>Since the test result is insignificant for all groups, we can conclude that the data approximately follow a normal distribution.</p>
<p>We could also test the distributional assumptions visually using a Q-Q plot (i.e., quantile-quantile plot). This plot can be used to assess if a set of data plausibly came from some theoretical distribution such as the Normal distribution. Since this is just a visual check, it is somewhat subjective. But it may help us to judge if our assumption is plausible, and if not, which data points contribute to the violation. A Q-Q plot is a scatterplot created by plotting two sets of quantiles against one another. If both sets of quantiles came from the same distribution, we should see the points forming a line that’s roughly straight. In other words, Q-Q plots take your sample data, sort it in ascending order, and then plot them versus quantiles calculated from a theoretical distribution. Quantiles are often referred to as “percentiles” and refer to the points in your data below which a certain proportion of your data fall. Recall, for example, the standard Normal distribution with a mean of 0 and a standard deviation of 1. Since the 50th percentile (or 0.5 quantile) is 0, half the data lie below 0. The 95th percentile (or 0.95 quantile), is about 1.64, which means that 95 percent of the data lie below 1.64. The 97.5th quantile is about 1.96, which means that 97.5% of the data lie below 1.96. In the Q-Q plot, the number of quantiles is selected to match the size of your sample data.</p>
<p>To create the Q-Q plot for the normal distribution, you may use the <code>qqnorm()</code> function, which takes the data to be tested as an argument. Using the <code>qqline()</code> function subsequently on the data creates the line on which the data points should fall based on the theoretical quantiles. If the individual data points deviate a lot from this line, it means that the data is not likely to follow a normal distribution.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="hypothesis-testing.html#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(hours_fewobs[hours_fewobs<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;low&quot;</span>,]<span class="sc">$</span>hours) </span>
<span id="cb316-2"><a href="hypothesis-testing.html#cb316-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(hours_fewobs[hours_fewobs<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;low&quot;</span>,]<span class="sc">$</span>hours)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-23-1"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-23-1.png" alt="Q-Q plot 1" width="672" />
<p class="caption">
Figure 6.2: Q-Q plot 1
</p>
</div>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="hypothesis-testing.html#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(hours_fewobs[hours_fewobs<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;medium&quot;</span>,]<span class="sc">$</span>hours) </span>
<span id="cb317-2"><a href="hypothesis-testing.html#cb317-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(hours_fewobs[hours_fewobs<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;medium&quot;</span>,]<span class="sc">$</span>hours)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-23-2"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-23-2.png" alt="Q-Q plot 2" width="672" />
<p class="caption">
Figure 6.3: Q-Q plot 2
</p>
</div>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="hypothesis-testing.html#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(hours_fewobs[hours_fewobs<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;high&quot;</span>,]<span class="sc">$</span>hours) </span>
<span id="cb318-2"><a href="hypothesis-testing.html#cb318-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(hours_fewobs[hours_fewobs<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;high&quot;</span>,]<span class="sc">$</span>hours)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-23-3"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-23-3.png" alt="Q-Q plot 3" width="672" />
<p class="caption">
Figure 6.4: Q-Q plot 3
</p>
</div>
<p>The Q-Q plots suggest an approximately Normal distribution. If the assumption had been violated, you might consider transforming your data or resort to a non-parametric test.</p>
</div>
<div id="homogeneity-of-variance" class="section level5 unnumbered">
<h5>Homogeneity of variance</h5>
<p>Let’s return to our original data set with 100 observations in each group for the rest of the analysis.</p>
<p>You can test the homogeneity of variances in R using Levene’s test:</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="hypothesis-testing.html#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb319-2"><a href="hypothesis-testing.html#cb319-2" aria-hidden="true" tabindex="-1"></a><span class="fu">leveneTest</span>(hours <span class="sc">~</span> group, <span class="at">data =</span> hours_abc, <span class="at">center =</span> mean)</span></code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = mean)
##        Df F value   Pr(&gt;F)   
## group   2  4.9678 0.007548 **
##       297                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The null hypothesis of the test is that the group variances are equal. Thus, if the test result is significant it means that the variances are not equal. If we cannot reject the null hypothesis (i.e., the group variances are not significantly different), we can proceed with the ANOVA as follows:</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="hypothesis-testing.html#cb321-1" aria-hidden="true" tabindex="-1"></a>aov <span class="ot">&lt;-</span> <span class="fu">aov</span>(hours <span class="sc">~</span> group, <span class="at">data =</span> hours_abc)</span>
<span id="cb321-2"><a href="hypothesis-testing.html#cb321-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(aov)</span></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
## group         2  21321   10661   332.1 &lt;2e-16 ***
## Residuals   297   9534      32                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>You can see that the p-value is smaller than 0.05. This means that, if there really was no difference between the population means (i.e., the Null hypothesis was true), the probability of the observed differences (or larger differences) is less than 5%.</p>
<p>To compute η<sup>2</sup> from the output, we can extract the relevant sum of squares as follows</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="hypothesis-testing.html#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(aov)[[<span class="dv">1</span>]]<span class="sc">$</span><span class="st">&#39;Sum Sq&#39;</span>[<span class="dv">1</span>]<span class="sc">/</span>(<span class="fu">summary</span>(aov)[[<span class="dv">1</span>]]<span class="sc">$</span><span class="st">&#39;Sum Sq&#39;</span>[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">summary</span>(aov)[[<span class="dv">1</span>]]<span class="sc">$</span><span class="st">&#39;Sum Sq&#39;</span>[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## [1] 0.6909988</code></pre>
<p>You can see that the results match the results from our manual computation above (<span class="math inline">\(\eta^2 =\)</span> 0.69).</p>
<p>The <code>aov()</code> function also automatically generates some plots that you can use to judge if the model assumptions are met. We will inspect two of the plots here.</p>
<p>We will use the first plot to inspect if the residual variances are equal across the experimental groups:</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="hypothesis-testing.html#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(aov,<span class="dv">1</span>)</span></code></pre></div>
<p><img src="08-Anova_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Generally, the residual variance (i.e., the range of values on the y-axis) should be the same for different levels of our independent variable. The plot shows, that there are some slight differences. Notably, the range of residuals is higher in group “medium” than in group “high.” However, the differences are not that large and since the Levene’s test could not reject the Null of equal variances, we conclude that the variances are similar enough in this case.</p>
<p>The second plot can be used to test the assumption that the residuals are approximately normally distributed. We use a Q-Q plot to test this assumption:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="hypothesis-testing.html#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(aov,<span class="dv">2</span>)</span></code></pre></div>
<p><img src="08-Anova_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>The plot suggests that, the residuals are approximately normally distributed. We could also test this by extracting the residuals from the anova output using the <code>resid()</code> function and using the Shapiro-Wilk test:</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="hypothesis-testing.html#cb327-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(aov))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(aov)
## W = 0.99723, p-value = 0.8925</code></pre>
<p>Confirming the impression from the Q-Q plot, we cannot reject the Null that the residuals are approximately normally distributed.</p>
<p>Note that if Levene’s test would have been significant (i.e., variances are not equal), we would have needed to either resort to non-parametric tests (see below), or compute the Welch’s F-ratio instead, which is correcting for unequal variances between the groups:</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="hypothesis-testing.html#cb329-1" aria-hidden="true" tabindex="-1"></a><span class="co">#oneway.test(hours ~ group, hours_abc)</span></span></code></pre></div>
<p>You can see that the results are fairly similar, since the variances turned out to be fairly equal across groups.</p>
</div>
</div>
<div id="post-hoc-tests" class="section level4" number="6.5.3.2">
<h4><span class="header-section-number">6.5.3.2</span> Post-hoc tests</h4>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/wNwKx0TZ7fQ" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>Provided that significant differences were detected by the overall ANOVA you can find out which group means are different using post-hoc procedures. Post-hoc procedures are designed to conduct pairwise comparisons of all different combinations of the treatment groups by correcting the level of significance for each test such that the overall Type I error rate (α) across all comparisons remains at 0.05.</p>
<p>In other words, we rejected H<sub>0</sub>: μ<sub>low</sub>= μ<sub>medium</sub>= μ<sub>high</sub>, and now we would like to test:</p>
<p>Test1:</p>
<p><span class="math display">\[H_0: \mu_{low} = \mu_{medium}\]</span></p>
<p>Test2:</p>
<p><span class="math display">\[H_0: \mu_{low} = \mu_{high}\]</span></p>
<p>Test3:</p>
<p><span class="math display">\[H_0: \mu_{medium} = \mu_{high}\]</span></p>
<p>There are several post-hoc procedures available to choose from. In this tutorial, we will cover Bonferroni and Tukey’s HSD (“honest significant differences”). Both tests control for family-wise error. Bonferroni tends to have more power when the number of comparisons is small, whereas Tukey’s HSDs is better when testing large numbers of means.</p>
<div id="bonferroni" class="section level5" number="6.5.3.2.1">
<h5><span class="header-section-number">6.5.3.2.1</span> Bonferroni</h5>
<p>One of the most popular (and easiest) methods to correct for the family-wise error rate is to conduct the individual t-tests and divide α by the number of comparisons („k“):</p>
<p><span class="math display">\[
p_{CR}= \frac{\alpha}{k}
\]</span></p>
<p>In our example with three groups:</p>
<p><span class="math display">\[p_{CR}= \frac{0.05}{3}=0.017\]</span></p>
<p>Thus, the “corrected” critical p-value is now 0.017 instead of 0.05 (i.e., the critical t value is higher). This means that the test is more conservative to account for the family-wise error. Remember that, to reject the null hypothesis at a 5% significance level, we usually check if the p-value in our analysis is smaller than 0.05. The corrected p-value above requires us to obtain a p-value smaller than 0.017 in order to reject the null hypothesis at the 5% significance level, which means that the critical value of the test statistic is higher. You can implement the Bonferroni procedure in R using:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="hypothesis-testing.html#cb330-1" aria-hidden="true" tabindex="-1"></a>bonferroni <span class="ot">&lt;-</span> <span class="fu">pairwise.t.test</span>(hours_abc<span class="sc">$</span>hours, hours_abc<span class="sc">$</span>group, <span class="at">data =</span> hours_abc, <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span>
<span id="cb330-2"><a href="hypothesis-testing.html#cb330-2" aria-hidden="true" tabindex="-1"></a>bonferroni</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  hours_abc$hours and hours_abc$group 
## 
##        low    medium
## medium &lt;2e-16 -     
## high   &lt;2e-16 &lt;2e-16
## 
## P value adjustment method: bonferroni</code></pre>
<p>In the output, you will get the corrected p-values for the individual tests. This mean, to reject the null hypothesis, we require the p-value to be smaller than 0.05 again, since the reported p-values are already corrected for the family-wise error. In our example, we can reject H<sub>0</sub> of equal means for all three tests, since p &lt; 0.05 for all combinations of groups.</p>
<p>Note the difference between the results from the post-hoc test compared to individual t-tests. For example, when we test the “medium” vs. “high” groups, the result from a t-test would be:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="hypothesis-testing.html#cb332-1" aria-hidden="true" tabindex="-1"></a>data_subset <span class="ot">&lt;-</span> <span class="fu">subset</span>(hours_abc, group <span class="sc">!=</span> <span class="st">&quot;low&quot;</span>)</span>
<span id="cb332-2"><a href="hypothesis-testing.html#cb332-2" aria-hidden="true" tabindex="-1"></a>ttest <span class="ot">&lt;-</span> <span class="fu">t.test</span>(hours <span class="sc">~</span> group, <span class="at">data =</span> data_subset, <span class="at">var.equal=</span> <span class="cn">TRUE</span>)</span>
<span id="cb332-3"><a href="hypothesis-testing.html#cb332-3" aria-hidden="true" tabindex="-1"></a>ttest</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  hours by group
## t = -11.884, df = 198, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means between group medium and group high is not equal to 0
## 95 percent confidence interval:
##  -11.997471  -8.582529
## sample estimates:
## mean in group medium   mean in group high 
##                24.70                34.99</code></pre>
<p>Usually the p-value is lower in the t-test, reflecting the fact that the family-wise error is not corrected (i.e., the test is less conservative). In this case the p-value is extremely small in both cases and thus indistinguishable.</p>
</div>
<div id="tukeys-hsd" class="section level5" number="6.5.3.2.2">
<h5><span class="header-section-number">6.5.3.2.2</span> Tukey’s HSD</h5>
<p>Tukey’s HSD also compares all possible pairs of means (two-by-two combinations; i.e., like a t-test, except that it corrects for family-wise error rate).</p>
<p>Test statistic:</p>
<p><span class="math display" id="eq:tukey">\[\begin{equation} 
\begin{split}
HSD= q\sqrt{\frac{MS_R}{n_c}}
\end{split}
\tag{6.2}
\end{equation}\]</span></p>
<p>where:</p>
<ul>
<li>q = value from studentized range table (see e.g., <a href="http://www.real-statistics.com/statistics-tables/studentized-range-q-table/" target="_blank">here</a>)</li>
<li>MS<sub>R</sub> = Mean Square Error from ANOVA</li>
<li>n<sub>c</sub> = number of observations per group</li>
<li>Decision: Reject H<sub>0</sub> if</li>
</ul>
<p><span class="math display">\[|\bar{Y}_i-\bar{Y}_j | &gt; HSD\]</span></p>
<p>The value from the studentized range table can be obtained using the <code>qtukey()</code> function.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="hypothesis-testing.html#cb334-1" aria-hidden="true" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="fu">qtukey</span>(<span class="fl">0.95</span>, <span class="at">nm =</span> <span class="dv">3</span>, <span class="at">df =</span> <span class="dv">297</span>)</span>
<span id="cb334-2"><a href="hypothesis-testing.html#cb334-2" aria-hidden="true" tabindex="-1"></a>q</span></code></pre></div>
<pre><code>## [1] 3.331215</code></pre>
<p>Hence:</p>
<p><span class="math display">\[HSD= 3.33\sqrt{\frac{33.99}{100}}=1.94\]</span></p>
<p>Or, in R:</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="hypothesis-testing.html#cb336-1" aria-hidden="true" tabindex="-1"></a>hsd <span class="ot">&lt;-</span> q <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="fu">summary</span>(aov)[[<span class="dv">1</span>]]<span class="sc">$</span><span class="st">&#39;Mean Sq&#39;</span>[<span class="dv">2</span>]<span class="sc">/</span><span class="dv">100</span>)</span>
<span id="cb336-2"><a href="hypothesis-testing.html#cb336-2" aria-hidden="true" tabindex="-1"></a>hsd</span></code></pre></div>
<pre><code>## [1] 1.887434</code></pre>
<p>Since all mean differences between groups are larger than 1.906, we can reject the null hypothesis for all individual tests, confirming the results from the Bonferroni test. To compute Tukey’s HSD, we can use the appropriate function from the <code>multcomp</code> package.</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="hypothesis-testing.html#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(multcomp)</span>
<span id="cb338-2"><a href="hypothesis-testing.html#cb338-2" aria-hidden="true" tabindex="-1"></a>aov<span class="sc">$</span>model<span class="sc">$</span>group <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(aov<span class="sc">$</span>model<span class="sc">$</span>group)</span>
<span id="cb338-3"><a href="hypothesis-testing.html#cb338-3" aria-hidden="true" tabindex="-1"></a>tukeys <span class="ot">&lt;-</span> <span class="fu">glht</span>(aov, <span class="at">linfct =</span> <span class="fu">mcp</span>(<span class="at">group =</span> <span class="st">&quot;Tukey&quot;</span>))</span>
<span id="cb338-4"><a href="hypothesis-testing.html#cb338-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tukeys)</span></code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = hours ~ group, data = hours_abc)
## 
## Linear Hypotheses:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## medium - low == 0   10.3600     0.8013   12.93   &lt;2e-16 ***
## high - low == 0     20.6500     0.8013   25.77   &lt;2e-16 ***
## high - medium == 0  10.2900     0.8013   12.84   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="hypothesis-testing.html#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(tukeys)</span></code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = hours ~ group, data = hours_abc)
## 
## Quantile = 2.3558
## 95% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                    Estimate lwr     upr    
## medium - low == 0  10.3600   8.4723 12.2477
## high - low == 0    20.6500  18.7623 22.5377
## high - medium == 0 10.2900   8.4023 12.1777</code></pre>
<p>We may also plot the result for the mean differences incl. their confidence intervals:</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="hypothesis-testing.html#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tukeys)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-36"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-36-1.png" alt="Tukey's HSD" width="672" />
<p class="caption">
Figure 4.6: Tukey’s HSD
</p>
</div>
<p>You can see that the CIs do not cross zero, which means that the true difference between group means is unlikely zero. It is sufficient to report the results in the way described above. However, you could also manually compute the differences between the groups and their confidence interval as follows:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="hypothesis-testing.html#cb343-1" aria-hidden="true" tabindex="-1"></a>mean1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_abc[hours_abc<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;low&quot;</span>,<span class="st">&quot;hours&quot;</span>]) <span class="co">#mean group &quot;low&quot;</span></span>
<span id="cb343-2"><a href="hypothesis-testing.html#cb343-2" aria-hidden="true" tabindex="-1"></a>mean1</span></code></pre></div>
<pre><code>## [1] 14.34</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="hypothesis-testing.html#cb345-1" aria-hidden="true" tabindex="-1"></a>mean2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_abc[hours_abc<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;medium&quot;</span>,<span class="st">&quot;hours&quot;</span>]) <span class="co">#mean group &quot;medium&quot;</span></span>
<span id="cb345-2"><a href="hypothesis-testing.html#cb345-2" aria-hidden="true" tabindex="-1"></a>mean2</span></code></pre></div>
<pre><code>## [1] 24.7</code></pre>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="hypothesis-testing.html#cb347-1" aria-hidden="true" tabindex="-1"></a>mean3 <span class="ot">&lt;-</span> <span class="fu">mean</span>(hours_abc[hours_abc<span class="sc">$</span>group<span class="sc">==</span><span class="st">&quot;high&quot;</span>,<span class="st">&quot;hours&quot;</span>]) <span class="co">#mean group &quot;high&quot;</span></span>
<span id="cb347-2"><a href="hypothesis-testing.html#cb347-2" aria-hidden="true" tabindex="-1"></a>mean3</span></code></pre></div>
<pre><code>## [1] 34.99</code></pre>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="hypothesis-testing.html#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="co">#CI high vs. medium</span></span>
<span id="cb349-2"><a href="hypothesis-testing.html#cb349-2" aria-hidden="true" tabindex="-1"></a>mean_diff_high_med <span class="ot">&lt;-</span> mean2<span class="sc">-</span>mean1</span>
<span id="cb349-3"><a href="hypothesis-testing.html#cb349-3" aria-hidden="true" tabindex="-1"></a>mean_diff_high_med</span></code></pre></div>
<pre><code>## [1] 10.36</code></pre>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="hypothesis-testing.html#cb351-1" aria-hidden="true" tabindex="-1"></a>ci_med_high_lower <span class="ot">&lt;-</span> mean_diff_high_med<span class="sc">-</span>hsd</span>
<span id="cb351-2"><a href="hypothesis-testing.html#cb351-2" aria-hidden="true" tabindex="-1"></a>ci_med_high_upper <span class="ot">&lt;-</span> mean_diff_high_med<span class="sc">+</span>hsd</span>
<span id="cb351-3"><a href="hypothesis-testing.html#cb351-3" aria-hidden="true" tabindex="-1"></a>ci_med_high_lower</span></code></pre></div>
<pre><code>## [1] 8.472566</code></pre>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="hypothesis-testing.html#cb353-1" aria-hidden="true" tabindex="-1"></a>ci_med_high_upper</span></code></pre></div>
<pre><code>## [1] 12.24743</code></pre>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="hypothesis-testing.html#cb355-1" aria-hidden="true" tabindex="-1"></a><span class="co">#CI high vs.low</span></span>
<span id="cb355-2"><a href="hypothesis-testing.html#cb355-2" aria-hidden="true" tabindex="-1"></a>mean_diff_high_low <span class="ot">&lt;-</span> mean3<span class="sc">-</span>mean1</span>
<span id="cb355-3"><a href="hypothesis-testing.html#cb355-3" aria-hidden="true" tabindex="-1"></a>mean_diff_high_low</span></code></pre></div>
<pre><code>## [1] 20.65</code></pre>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="hypothesis-testing.html#cb357-1" aria-hidden="true" tabindex="-1"></a>ci_low_high_lower <span class="ot">&lt;-</span> mean_diff_high_low<span class="sc">-</span>hsd</span>
<span id="cb357-2"><a href="hypothesis-testing.html#cb357-2" aria-hidden="true" tabindex="-1"></a>ci_low_high_upper <span class="ot">&lt;-</span> mean_diff_high_low<span class="sc">+</span>hsd</span>
<span id="cb357-3"><a href="hypothesis-testing.html#cb357-3" aria-hidden="true" tabindex="-1"></a>ci_low_high_lower</span></code></pre></div>
<pre><code>## [1] 18.76257</code></pre>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="hypothesis-testing.html#cb359-1" aria-hidden="true" tabindex="-1"></a>ci_low_high_upper</span></code></pre></div>
<pre><code>## [1] 22.53743</code></pre>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="hypothesis-testing.html#cb361-1" aria-hidden="true" tabindex="-1"></a><span class="co">#CI medium vs.low</span></span>
<span id="cb361-2"><a href="hypothesis-testing.html#cb361-2" aria-hidden="true" tabindex="-1"></a>mean_diff_med_low <span class="ot">&lt;-</span> mean3<span class="sc">-</span>mean2</span>
<span id="cb361-3"><a href="hypothesis-testing.html#cb361-3" aria-hidden="true" tabindex="-1"></a>mean_diff_med_low</span></code></pre></div>
<pre><code>## [1] 10.29</code></pre>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="hypothesis-testing.html#cb363-1" aria-hidden="true" tabindex="-1"></a>ci_low_med_lower <span class="ot">&lt;-</span> mean_diff_med_low<span class="sc">-</span>hsd</span>
<span id="cb363-2"><a href="hypothesis-testing.html#cb363-2" aria-hidden="true" tabindex="-1"></a>ci_low_med_upper <span class="ot">&lt;-</span> mean_diff_med_low<span class="sc">+</span>hsd</span>
<span id="cb363-3"><a href="hypothesis-testing.html#cb363-3" aria-hidden="true" tabindex="-1"></a>ci_low_med_lower</span></code></pre></div>
<pre><code>## [1] 8.402566</code></pre>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="hypothesis-testing.html#cb365-1" aria-hidden="true" tabindex="-1"></a>ci_low_med_upper</span></code></pre></div>
<pre><code>## [1] 12.17743</code></pre>
<p>The results of a post-hoc test can be reported as follows:</p>
<p>The post-hoc tests based on Bonferroni and Tukey’s HSD revealed that users listened to music significantly more when the intensity of personalized recommendations was increased. This is true for “low” vs. “medium” intensity, as well as for “low” vs. “high” and “medium” vs. “high” intensity.</p>
<p>As with the t-test, you could also use the functions contained in the <code>ggstatsplot</code> package to combine a visual depiction of the data with the results of statistical tests. In the case of an ANOVA, the output would also include the pairwise comparisons.</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="hypothesis-testing.html#cb367-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb367-2"><a href="hypothesis-testing.html#cb367-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggbetweenstats</span>(</span>
<span id="cb367-3"><a href="hypothesis-testing.html#cb367-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> hours_abc,</span>
<span id="cb367-4"><a href="hypothesis-testing.html#cb367-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> group,</span>
<span id="cb367-5"><a href="hypothesis-testing.html#cb367-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> hours,</span>
<span id="cb367-6"><a href="hypothesis-testing.html#cb367-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot.type =</span> <span class="st">&quot;box&quot;</span>,</span>
<span id="cb367-7"><a href="hypothesis-testing.html#cb367-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">pairwise.comparisons =</span> <span class="cn">TRUE</span>,</span>
<span id="cb367-8"><a href="hypothesis-testing.html#cb367-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">pairwise.annotation =</span> <span class="st">&quot;p.value&quot;</span>,</span>
<span id="cb367-9"><a href="hypothesis-testing.html#cb367-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>,</span>
<span id="cb367-10"><a href="hypothesis-testing.html#cb367-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">effsize.type =</span> <span class="st">&quot;eta&quot;</span>,</span>
<span id="cb367-11"><a href="hypothesis-testing.html#cb367-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">var.equal =</span> <span class="cn">FALSE</span>,</span>
<span id="cb367-12"><a href="hypothesis-testing.html#cb367-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.plotting =</span> <span class="cn">TRUE</span>, <span class="co"># whether mean for each group is to be displayed</span></span>
<span id="cb367-13"><a href="hypothesis-testing.html#cb367-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.ci =</span> <span class="cn">TRUE</span>, <span class="co"># whether to display confidence interval for means</span></span>
<span id="cb367-14"><a href="hypothesis-testing.html#cb367-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.label.size =</span> <span class="fl">2.5</span>, <span class="co"># size of the label for mean</span></span>
<span id="cb367-15"><a href="hypothesis-testing.html#cb367-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;parametric&quot;</span>, <span class="co"># which type of test is to be run</span></span>
<span id="cb367-16"><a href="hypothesis-testing.html#cb367-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">3</span>, <span class="co"># number of decimal places for statistical results</span></span>
<span id="cb367-17"><a href="hypothesis-testing.html#cb367-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">outlier.label.color =</span> <span class="st">&quot;darkgreen&quot;</span>, <span class="co"># changing the color for the text label</span></span>
<span id="cb367-18"><a href="hypothesis-testing.html#cb367-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Comparison of listening times between groups&quot;</span>,</span>
<span id="cb367-19"><a href="hypothesis-testing.html#cb367-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Experimental group&quot;</span>, <span class="co"># label for the x-axis variable</span></span>
<span id="cb367-20"><a href="hypothesis-testing.html#cb367-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Listening time&quot;</span>, <span class="co"># label for the y-axis variable</span></span>
<span id="cb367-21"><a href="hypothesis-testing.html#cb367-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb367-22"><a href="hypothesis-testing.html#cb367-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span></span>
<span id="cb367-23"><a href="hypothesis-testing.html#cb367-23" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-38"></span>
<img src="08-Anova_files/figure-html/unnamed-chunk-38-1.png" alt="ANOVA using ggstatsplot" width="672" />
<p class="caption">
Figure 4.8: ANOVA using ggstatsplot
</p>
</div>

<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre><code>## 
## Attaching package: &#39;ggplot2&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:psych&#39;:
## 
##     %+%, alpha</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: survival</code></pre>
<pre><code>## Loading required package: Formula</code></pre>
<pre><code>## 
## Attaching package: &#39;Hmisc&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:psych&#39;:
## 
##     describe</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     src, summarize</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     format.pval, units</code></pre>
</div>
</div>
</div>
</div>
<div id="non-parametric-tests" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Non-parametric tests</h2>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/O1Xpedqwr3o" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<div class="infobox download">
<p><a href="./Code/08-non_parametric.R">You can download the corresponding R-Code here</a></p>
</div>
<p><strong>Non-Parametric tests</strong> do not require the sampling distribution to be normally distributed (a.k.a. “assumption free tests”). These tests may be used when the variable of interest is measured on an ordinal scale or when the parametric assumptions do not hold. They often rely on ranking the data instead of analyzing the actual scores. By ranking the data, information on the magnitude of differences is lost. Thus, parametric tests are more powerful if the sampling distribution is normally distributed and you have a continuous variable.</p>
<p>When should you use non-parametric tests?</p>
<ul>
<li>When your DV is measured on an ordinal scale</li>
<li>When your data is better represented by the median (e.g., there are outliers that you can’t remove)</li>
<li>When the assumptions of parametric tests are not met (e.g., normally distributed sampling distribution)</li>
<li>You have a very small sample size (i.e., the central limit theorem does not apply)</li>
</ul>
<p>In these cases, you should resort to the non-parametric equivalent of the tests we have discussed so far, as summarized in the following table.</p>
<table>
<thead>
<tr class="header">
<th>Parametric test</th>
<th>Non-parametric equivalent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Independent-means t-test</td>
<td>Mann-Whitney U Test</td>
</tr>
<tr class="even">
<td>Dependent-means t-test</td>
<td>Wilcoxon signed-rank test</td>
</tr>
<tr class="odd">
<td>ANOVA</td>
<td>Kruskal-Wallis test</td>
</tr>
</tbody>
</table>
<p>These non-parametric tests will be briefly discussed in the following sections.</p>
<div id="mann-whitney-u-test-a.k.a.-wilcoxon-rank-sum-test" class="section level3" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> Mann-Whitney U Test (a.k.a. Wilcoxon rank-sum test)</h3>
<p>The Mann-Whitney U test is a non-parametric test of differences between groups (i.e., it is the non-parametric equivalent of the independent-means t-test). In contrast to the independent-means t-test it only requires ordinally scaled data and relies on weaker assumptions. Thus it is often useful if the assumptions of the t-test are violated, especially if the data is not on a continuous scale. The following assumptions must be fulfilled for the test to be applicable:</p>
<ul>
<li>The dependent variable is at least ordinally scaled (i.e. a ranking between values can be established)</li>
<li>The independent variable has only two levels</li>
<li>A between-subjects design is used (i.e., the subjects are not matched across conditions)</li>
</ul>
<p>Intuitively, the test compares the frequency of low and high ranks between groups. Under the null hypothesis, the amount of high and low ranks should be roughly equal in the two groups. This is achieved through comparing the expected sum of ranks to the actual sum of ranks.</p>
<p>As an example, we will be using data obtained from a field experiment with random assignment. In a music download store, new releases were randomly assigned to an experimental group and sold at a reduced price (i.e., 7.95€), or a control group and sold at the standard price (9.95€). A representative sample of 102 new releases were sampled and these albums were randomly assigned to the experimental groups (i.e., 51 albums per group). The sales were tracked over one day.</p>
<p>Let’s load and investigate the data first:</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="hypothesis-testing.html#cb380-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb380-2"><a href="hypothesis-testing.html#cb380-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb380-3"><a href="hypothesis-testing.html#cb380-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(music_sales)</span>
<span id="cb380-4"><a href="hypothesis-testing.html#cb380-4" aria-hidden="true" tabindex="-1"></a>music_sales <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/music_experiment.dat&quot;</span>, </span>
<span id="cb380-5"><a href="hypothesis-testing.html#cb380-5" aria-hidden="true" tabindex="-1"></a>                          <span class="at">sep =</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>, </span>
<span id="cb380-6"><a href="hypothesis-testing.html#cb380-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">header =</span> <span class="cn">TRUE</span>) <span class="co">#read in data</span></span>
<span id="cb380-7"><a href="hypothesis-testing.html#cb380-7" aria-hidden="true" tabindex="-1"></a>music_sales<span class="sc">$</span>group <span class="ot">&lt;-</span> <span class="fu">factor</span>(music_sales<span class="sc">$</span>group, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;low_price&quot;</span>, <span class="st">&quot;high_price&quot;</span>)) <span class="co">#convert grouping variable to factor</span></span>
<span id="cb380-8"><a href="hypothesis-testing.html#cb380-8" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(music_sales) <span class="co">#inspect data</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    102 obs. of  3 variables:
##  $ product_id: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ unit_sales: int  6 27 30 24 21 11 18 15 18 13 ...
##  $ group     : Factor w/ 2 levels &quot;low_price&quot;,&quot;high_price&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="hypothesis-testing.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(music_sales) <span class="co">#inspect data</span></span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["product_id"],"name":[1],"type":["int"],"align":["right"]},{"label":["unit_sales"],"name":[2],"type":["int"],"align":["right"]},{"label":["group"],"name":[3],"type":["fct"],"align":["left"]}],"data":[{"1":"1","2":"6","3":"low_price"},{"1":"2","2":"27","3":"low_price"},{"1":"3","2":"30","3":"low_price"},{"1":"4","2":"24","3":"low_price"},{"1":"5","2":"21","3":"low_price"},{"1":"6","2":"11","3":"low_price"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Inspect descriptives (overall and by group).</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="hypothesis-testing.html#cb383-1" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(music_sales<span class="sc">$</span>unit_sales) <span class="co">#overall descriptives</span></span></code></pre></div>
<pre><code>##    vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 102 7.12 6.26      6     6.1 4.45   0  30    30 1.71     3.02 0.62</code></pre>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="hypothesis-testing.html#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describeBy</span>(music_sales<span class="sc">$</span>unit_sales, music_sales<span class="sc">$</span>group) <span class="co">#descriptives by group</span></span></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: low_price
##    vars  n mean   sd median trimmed  mad min max range skew kurtosis  se
## X1    1 51 8.37 6.44      6    7.17 4.45   2  30    28 1.66     2.22 0.9
## ------------------------------------------------------------ 
## group: high_price
##    vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 51 5.86 5.87      3     4.9 4.45   0  30    30 1.84      4.1 0.82</code></pre>
<p>In the case of non-parametric tests, the data is better represented by the median (compared to the mean). Thus, we will visualize the data using a boxplot.</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="hypothesis-testing.html#cb387-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(music_sales,<span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> unit_sales)) <span class="sc">+</span> </span>
<span id="cb387-2"><a href="hypothesis-testing.html#cb387-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb387-3"><a href="hypothesis-testing.html#cb387-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb387-4"><a href="hypothesis-testing.html#cb387-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb387-5"><a href="hypothesis-testing.html#cb387-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Sales&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Sales by group&quot;</span>)<span class="sc">+</span></span>
<span id="cb387-6"><a href="hypothesis-testing.html#cb387-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb387-7"><a href="hypothesis-testing.html#cb387-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">&quot;#666666&quot;</span>)) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-4-1.png" alt="Boxplot" width="672" />
<p class="caption">
Figure 1.3: Boxplot
</p>
</div>
<p>Let’s assume that one of the parametric assumptions has been violated and we needed to conduct a non-parametric test. Then, the Mann-Whitney U test is implemented in R using the function <code>wilcox.test()</code>. Using the ranking data as an independent variable and the listening time as a dependent variable, the test could be executed as follows:</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="hypothesis-testing.html#cb388-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(unit_sales <span class="sc">~</span> group, <span class="at">data =</span> music_sales) <span class="co">#Mann-Whitney U Test</span></span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  unit_sales by group
## W = 1710, p-value = 0.005374
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>The p-value is smaller than 0.05, which leads us to reject the null hypothesis, i.e. the test yields evidence that the new service feature leads to higher music listening times.</p>
<p>Alternatively, you could also use the <code>ggstatsplot</code> package to obtain the result of the test by specifying the argument <code>type = "nonparametric"</code> as follows:</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="hypothesis-testing.html#cb390-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb390-2"><a href="hypothesis-testing.html#cb390-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggbetweenstats</span>(</span>
<span id="cb390-3"><a href="hypothesis-testing.html#cb390-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> music_sales,</span>
<span id="cb390-4"><a href="hypothesis-testing.html#cb390-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot.type =</span> <span class="st">&quot;box&quot;</span>,</span>
<span id="cb390-5"><a href="hypothesis-testing.html#cb390-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> group, <span class="co"># 2 groups</span></span>
<span id="cb390-6"><a href="hypothesis-testing.html#cb390-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> unit_sales ,</span>
<span id="cb390-7"><a href="hypothesis-testing.html#cb390-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;nonparametric&quot;</span>,</span>
<span id="cb390-8"><a href="hypothesis-testing.html#cb390-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">effsize.type =</span> <span class="st">&quot;r&quot;</span>, <span class="co"># display effect size (Cohen&#39;s d in output)</span></span>
<span id="cb390-9"><a href="hypothesis-testing.html#cb390-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb390-10"><a href="hypothesis-testing.html#cb390-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span>,</span>
<span id="cb390-11"><a href="hypothesis-testing.html#cb390-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.ci =</span> <span class="cn">TRUE</span>,</span>
<span id="cb390-12"><a href="hypothesis-testing.html#cb390-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Mean sales for different groups&quot;</span></span>
<span id="cb390-13"><a href="hypothesis-testing.html#cb390-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-6-1.png" alt="Mann-Whitney U Test using ggstatsplot" width="672" />
<p class="caption">
Figure 5.1: Mann-Whitney U Test using ggstatsplot
</p>
</div>
</div>
<div id="wilcoxon-signed-rank-test" class="section level3" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> Wilcoxon signed-rank test</h3>
<p>The Wilcoxon signed-rank test is a non-parametric test used to analyze the difference between paired observations, analogously to the dependent-means t-test. It can be used when measurements come from the same observational units but the distributional assumptions of the dependent-means t-test do not hold, because it does not require any assumptions about the distribution of the measurements. Since we subtract two values, however, the test requires that the dependent variable is at least interval scaled, meaning that intervals have the same meaning for different points on our measurement scale.</p>
<p>Under the null hypothesis <span class="math inline">\(H_0\)</span>, the differences of the measurements should follow a symmetric distribution around 0, meaning that, on average, there is no difference between the two matched samples. <span class="math inline">\(H_1\)</span> states that the distributions mean is non-zero.</p>
<p>As an example, let’s consider a slightly different experimental setup for the music download store. Imagine that new releases were either sold at a reduced price (i.e., 7.95€), or at the standard price (9.95€). Every time a customer came to the store, the prices were randomly determined for every new release. This means that the same 51 albums were either sold at the standard price or at the reduced price and this price was determined randomly. The sales were then recorded over one day. Note the difference to the previous case, where we randomly split the sample and assigned 50% of products to each condition. Now, we randomly vary prices for all albums between high and low prices.</p>
<p>Let’s load and investigate the data first:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="hypothesis-testing.html#cb391-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(music_sales_dep)</span>
<span id="cb391-2"><a href="hypothesis-testing.html#cb391-2" aria-hidden="true" tabindex="-1"></a>music_sales_dep <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/music_experiment_dependent.dat&quot;</span>, </span>
<span id="cb391-3"><a href="hypothesis-testing.html#cb391-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">sep =</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>, </span>
<span id="cb391-4"><a href="hypothesis-testing.html#cb391-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">header =</span> <span class="cn">TRUE</span>) <span class="co">#read in data</span></span>
<span id="cb391-5"><a href="hypothesis-testing.html#cb391-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(music_sales_dep) <span class="co">#inspect data</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    51 obs. of  3 variables:
##  $ product_id           : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ unit_sales_low_price : int  6 27 30 24 21 11 18 15 18 13 ...
##  $ unit_sales_high_price: int  9 12 30 18 20 15 2 3 3 9 ...</code></pre>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="hypothesis-testing.html#cb393-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(music_sales_dep) <span class="co">#inspect data</span></span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["product_id"],"name":[1],"type":["int"],"align":["right"]},{"label":["unit_sales_low_price"],"name":[2],"type":["int"],"align":["right"]},{"label":["unit_sales_high_price"],"name":[3],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"6","3":"9"},{"1":"2","2":"27","3":"12"},{"1":"3","2":"30","3":"30"},{"1":"4","2":"24","3":"18"},{"1":"5","2":"21","3":"20"},{"1":"6","2":"11","3":"15"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We can visualize the data using a boxplot as follows:</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="hypothesis-testing.html#cb394-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reshape2)</span>
<span id="cb394-2"><a href="hypothesis-testing.html#cb394-2" aria-hidden="true" tabindex="-1"></a>music_sales_dep_long <span class="ot">&lt;-</span> <span class="fu">melt</span>(music_sales_dep[, <span class="fu">c</span>(<span class="st">&quot;unit_sales_low_price&quot;</span>, <span class="st">&quot;unit_sales_high_price&quot;</span>)]) </span>
<span id="cb394-3"><a href="hypothesis-testing.html#cb394-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(music_sales_dep_long) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;group&quot;</span>,<span class="st">&quot;sales&quot;</span>)</span>
<span id="cb394-4"><a href="hypothesis-testing.html#cb394-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(music_sales_dep_long)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["group"],"name":[1],"type":["fct"],"align":["left"]},{"label":["sales"],"name":[2],"type":["int"],"align":["right"]}],"data":[{"1":"unit_sales_low_price","2":"6"},{"1":"unit_sales_low_price","2":"27"},{"1":"unit_sales_low_price","2":"30"},{"1":"unit_sales_low_price","2":"24"},{"1":"unit_sales_low_price","2":"21"},{"1":"unit_sales_low_price","2":"11"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="hypothesis-testing.html#cb395-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(music_sales_dep_long,<span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> sales)) <span class="sc">+</span> </span>
<span id="cb395-2"><a href="hypothesis-testing.html#cb395-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb395-3"><a href="hypothesis-testing.html#cb395-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb395-4"><a href="hypothesis-testing.html#cb395-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb395-5"><a href="hypothesis-testing.html#cb395-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Average number of sales&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Average number of sales by group&quot;</span>)<span class="sc">+</span></span>
<span id="cb395-6"><a href="hypothesis-testing.html#cb395-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb395-7"><a href="hypothesis-testing.html#cb395-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">&quot;#666666&quot;</span>)) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-8-1.png" alt="Boxplot" width="672" />
<p class="caption">
Figure 1.6: Boxplot
</p>
</div>
<p>Again, let’s assume that one of the parametric assumptions has been violated and we needed to conduct a non-parametric test. Then the Wilcoxon signed-rank test can be performed with the same command as the Mann-Whitney U test, provided that the argument <code>paired</code> is set to <code>TRUE</code>.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="hypothesis-testing.html#cb396-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(music_sales_dep<span class="sc">$</span>unit_sales_low_price, music_sales_dep<span class="sc">$</span>unit_sales_high_price, <span class="at">paired =</span> <span class="cn">TRUE</span>) <span class="co">#Wilcoxon signed-rank test</span></span></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  music_sales_dep$unit_sales_low_price and music_sales_dep$unit_sales_high_price
## V = 867.5, p-value = 0.004024
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>Using the 95% confidence level, the result would suggest a significant effect of price on sales (i.e., p &lt; 0.05).</p>
<p>Again, you could also use the <code>ggstatsplot</code> package to obtain the result of the test by specifying the argument <code>type = "nonparametric"</code> as follows:</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="hypothesis-testing.html#cb398-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb398-2"><a href="hypothesis-testing.html#cb398-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggwithinstats</span>(</span>
<span id="cb398-3"><a href="hypothesis-testing.html#cb398-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> music_sales_dep_long,</span>
<span id="cb398-4"><a href="hypothesis-testing.html#cb398-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> group,</span>
<span id="cb398-5"><a href="hypothesis-testing.html#cb398-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> sales,</span>
<span id="cb398-6"><a href="hypothesis-testing.html#cb398-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">path.point =</span> <span class="cn">FALSE</span>,</span>
<span id="cb398-7"><a href="hypothesis-testing.html#cb398-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type=</span><span class="st">&quot;nonparametric&quot;</span>,</span>
<span id="cb398-8"><a href="hypothesis-testing.html#cb398-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sort =</span> <span class="st">&quot;descending&quot;</span>, <span class="co"># ordering groups along the x-axis based on</span></span>
<span id="cb398-9"><a href="hypothesis-testing.html#cb398-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">sort.fun =</span> median, <span class="co"># values of `y` variable</span></span>
<span id="cb398-10"><a href="hypothesis-testing.html#cb398-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Mean sales for different treatments&quot;</span>,</span>
<span id="cb398-11"><a href="hypothesis-testing.html#cb398-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb398-12"><a href="hypothesis-testing.html#cb398-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span>,</span>
<span id="cb398-13"><a href="hypothesis-testing.html#cb398-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.ci =</span> <span class="cn">TRUE</span>,</span>
<span id="cb398-14"><a href="hypothesis-testing.html#cb398-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean.plotting =</span> F,</span>
<span id="cb398-15"><a href="hypothesis-testing.html#cb398-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">effsize.type =</span> <span class="st">&quot;r&quot;</span> <span class="co"># display effect size (Cohen&#39;s d in output)</span></span>
<span id="cb398-16"><a href="hypothesis-testing.html#cb398-16" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-10-1.png" alt="Wilcoxon signed-rank test using ggstatsplot" width="672" />
<p class="caption">
Figure 1.8: Wilcoxon signed-rank test using ggstatsplot
</p>
</div>
</div>
<div id="kruskal-wallis-test" class="section level3" number="6.6.3">
<h3><span class="header-section-number">6.6.3</span> Kruskal-Wallis test</h3>
<p>The Kruskal–Wallis test is the non-parametric counterpart of the one-way ANOVA. It is designed to test for significant differences in population medians when you have more than two groups (with two groups, you would use the Mann-Whitney U-test). The theory is very similar to that of the Mann–Whitney U-test since it is also based on ranked data.</p>
<p>As an example, let’s use a data set containing data from an experiment at an online store where products were randomly assigned to three groups with three different levels of promotion (i.e., “low,” “medium,” “high”) and the sales where recorded for these groups.</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="hypothesis-testing.html#cb399-1" aria-hidden="true" tabindex="-1"></a>online_store_promo <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/online_store_promo.dat&quot;</span>, </span>
<span id="cb399-2"><a href="hypothesis-testing.html#cb399-2" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">sep =</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>, </span>
<span id="cb399-3"><a href="hypothesis-testing.html#cb399-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">header =</span> <span class="cn">TRUE</span>) <span class="co">#read in data</span></span>
<span id="cb399-4"><a href="hypothesis-testing.html#cb399-4" aria-hidden="true" tabindex="-1"></a>online_store_promo<span class="sc">$</span>Promotion <span class="ot">&lt;-</span> <span class="fu">factor</span>(online_store_promo<span class="sc">$</span>Promotion, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>,<span class="st">&quot;low&quot;</span>)) <span class="co">#convert grouping variable to factor</span></span>
<span id="cb399-5"><a href="hypothesis-testing.html#cb399-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(online_store_promo)</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Obs"],"name":[1],"type":["int"],"align":["right"]},{"label":["Promotion"],"name":[2],"type":["fct"],"align":["left"]},{"label":["Newsletter"],"name":[3],"type":["int"],"align":["right"]},{"label":["Sales"],"name":[4],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"high","3":"1","4":"10"},{"1":"2","2":"high","3":"1","4":"9"},{"1":"3","2":"high","3":"1","4":"10"},{"1":"4","2":"high","3":"1","4":"8"},{"1":"5","2":"high","3":"1","4":"9"},{"1":"6","2":"high","3":"0","4":"8"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>To get a first impression, we can plot the data using a boxplot:</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="hypothesis-testing.html#cb400-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Boxplot</span></span>
<span id="cb400-2"><a href="hypothesis-testing.html#cb400-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(online_store_promo,<span class="fu">aes</span>(<span class="at">x =</span> Promotion, <span class="at">y =</span> Sales)) <span class="sc">+</span> </span>
<span id="cb400-3"><a href="hypothesis-testing.html#cb400-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb400-4"><a href="hypothesis-testing.html#cb400-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb400-5"><a href="hypothesis-testing.html#cb400-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb400-6"><a href="hypothesis-testing.html#cb400-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Experimental group (promotion level)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Number of sales&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Number of sales by group&quot;</span>)<span class="sc">+</span></span>
<span id="cb400-7"><a href="hypothesis-testing.html#cb400-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb400-8"><a href="hypothesis-testing.html#cb400-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">&quot;#666666&quot;</span>)) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-12"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-12-1.png" alt="Boxplot" width="672" />
<p class="caption">
Figure 1.10: Boxplot
</p>
</div>
<p>To test if there is a difference in medians between the groups, we can carry out the Kruskal-Wallis test using the <code>kruskal.test()</code> function:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="hypothesis-testing.html#cb401-1" aria-hidden="true" tabindex="-1"></a><span class="fu">kruskal.test</span>(Sales <span class="sc">~</span> Promotion, <span class="at">data =</span> online_store_promo) </span></code></pre></div>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  Sales by Promotion
## Kruskal-Wallis chi-squared = 16.529, df = 2, p-value = 0.0002575</code></pre>
<p>The test-statistic follows a chi-square distribution and since the test is significant (p &lt; 0.05), we can conclude that there are significant differences in population medians. Provided that the overall effect is significant, you may perform a post hoc test to find out which groups are different.</p>
<p>To test for differences between groups, we can, for example, apply post-hoc tests according to Nemenyi for pairwise multiple comparisons of the ranked data using the appropriate function from the <code>PMCMR</code> package.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="hypothesis-testing.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(PMCMR)</span>
<span id="cb403-2"><a href="hypothesis-testing.html#cb403-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(PMCMRplus)</span>
<span id="cb403-3"><a href="hypothesis-testing.html#cb403-3" aria-hidden="true" tabindex="-1"></a><span class="fu">kwAllPairsNemenyiTest</span>(<span class="at">x =</span> online_store_promo<span class="sc">$</span>Sales, <span class="at">g =</span> online_store_promo<span class="sc">$</span>Promotion, <span class="at">dist =</span> <span class="st">&quot;Tukey&quot;</span>)</span></code></pre></div>
<pre><code>##        high    medium 
## medium 0.09887 -      
## low    0.00016 0.11683</code></pre>
<p>The results reveal that there is a significant difference between the “low” and “high” promotion groups. Note that the results are different compared to the results from a parametric test, which we could obtain as follows:</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="hypothesis-testing.html#cb405-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairwise.t.test</span>(online_store_promo<span class="sc">$</span>Sales, online_store_promo<span class="sc">$</span>Promotion, <span class="at">data =</span> online_store_promo, <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  online_store_promo$Sales and online_store_promo$Promotion 
## 
##        high    medium
## medium 0.0329  -     
## low    6.6e-06 0.0092
## 
## P value adjustment method: bonferroni</code></pre>
<p>This difference occurs because non-parametric tests have less power to detect differences between groups since we lose information by ranking the data. Thus, you should rely on parametric tests if the assumptions are met.</p>
<p>Again, you could also use the <code>ggstatsplot</code> package to obtain the result of the test by specifying the argument <code>type = "nonparametric"</code> as follows:</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="hypothesis-testing.html#cb407-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb407-2"><a href="hypothesis-testing.html#cb407-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggbetweenstats</span>(</span>
<span id="cb407-3"><a href="hypothesis-testing.html#cb407-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> online_store_promo,</span>
<span id="cb407-4"><a href="hypothesis-testing.html#cb407-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot.type =</span> <span class="st">&quot;box&quot;</span>,</span>
<span id="cb407-5"><a href="hypothesis-testing.html#cb407-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> Promotion, <span class="co"># 2 groups</span></span>
<span id="cb407-6"><a href="hypothesis-testing.html#cb407-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> Sales ,</span>
<span id="cb407-7"><a href="hypothesis-testing.html#cb407-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;nonparametric&quot;</span>,</span>
<span id="cb407-8"><a href="hypothesis-testing.html#cb407-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb407-9"><a href="hypothesis-testing.html#cb407-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Mean sales for different groups&quot;</span></span>
<span id="cb407-10"><a href="hypothesis-testing.html#cb407-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-16"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-16-1.png" alt="Kruskal-Wallis test using ggstatsplot" width="672" />
<p class="caption">
Figure 4.1: Kruskal-Wallis test using ggstatsplot
</p>
</div>
</div>
</div>
<div id="categorical-data" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Categorical data</h2>
<br>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/4x0KYLGZXKc" frameborder="0" allowfullscreen>
</iframe>
</div>
<p><br></p>
<div class="infobox download">
<p><a href="./Code/09-categorical_data.R">You can download the corresponding R-Code here</a></p>
</div>
<p>In some instances, you will be confronted with differences between proportions, rather than differences between means. For example, you may conduct an A/B-Test and wish to compare the conversion rates between two advertising campaigns. In this case, your data is binary (0 = no conversion, 1 = conversion) and the sampling distribution for such data is binomial. While binomial probabilities are difficult to calculate, we can use a Normal approximation to the binomial when <code>n</code> is large (&gt;100) and the true likelihood of a 1 is not too close to 0 or 1.</p>
<p>Let’s use an example: assume a call center where service agents call potential customers to sell a product. We consider two call center agents:</p>
<ul>
<li>Service agent 1 talks to 300 customers and gets 200 of them to buy (conversion rate=2/3)</li>
<li>Service agent 2 talks to 300 customers and gets 100 of them to buy (conversion rate=1/3)</li>
</ul>
<p>As always, we load the data first:</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="hypothesis-testing.html#cb408-1" aria-hidden="true" tabindex="-1"></a>call_center <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/call_center.dat&quot;</span>, </span>
<span id="cb408-2"><a href="hypothesis-testing.html#cb408-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">sep =</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>, </span>
<span id="cb408-3"><a href="hypothesis-testing.html#cb408-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">header =</span> <span class="cn">TRUE</span>) <span class="co">#read in data</span></span>
<span id="cb408-4"><a href="hypothesis-testing.html#cb408-4" aria-hidden="true" tabindex="-1"></a>call_center<span class="sc">$</span>conversion <span class="ot">&lt;-</span> <span class="fu">factor</span>(call_center<span class="sc">$</span>conversion , <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>)) <span class="co">#convert to factor</span></span>
<span id="cb408-5"><a href="hypothesis-testing.html#cb408-5" aria-hidden="true" tabindex="-1"></a>call_center<span class="sc">$</span>agent <span class="ot">&lt;-</span> <span class="fu">factor</span>(call_center<span class="sc">$</span>agent , <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;agent_1&quot;</span>, <span class="st">&quot;agent_2&quot;</span>)) <span class="co">#convert to factor</span></span></code></pre></div>
<p>Next, we create a table to check the relative frequencies:</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="hypothesis-testing.html#cb409-1" aria-hidden="true" tabindex="-1"></a>rel_freq_table <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(call_center), <span class="dv">2</span>)) <span class="co">#conditional relative frequencies</span></span>
<span id="cb409-2"><a href="hypothesis-testing.html#cb409-2" aria-hidden="true" tabindex="-1"></a>rel_freq_table</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["agent"],"name":[1],"type":["fct"],"align":["left"]},{"label":["conversion"],"name":[2],"type":["fct"],"align":["left"]},{"label":["Freq"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"agent_1","2":"no","3":"0.3333333"},{"1":"agent_2","2":"no","3":"0.6666667"},{"1":"agent_1","2":"yes","3":"0.6666667"},{"1":"agent_2","2":"yes","3":"0.3333333"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We could also plot the data to visualize the frequencies using ggplot:</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="hypothesis-testing.html#cb410-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rel_freq_table, <span class="fu">aes</span>(<span class="at">x =</span> agent, <span class="at">y =</span> Freq, <span class="at">fill =</span> conversion)) <span class="sc">+</span> <span class="co">#plot data</span></span>
<span id="cb410-2"><a href="hypothesis-testing.html#cb410-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">width =</span> .<span class="dv">7</span>) <span class="sc">+</span> <span class="co">#position</span></span>
<span id="cb410-3"><a href="hypothesis-testing.html#cb410-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">paste0</span>(<span class="fu">round</span>(Freq<span class="sc">*</span><span class="dv">100</span>,<span class="dv">0</span>),<span class="st">&quot;%&quot;</span>)), <span class="at">position =</span> <span class="fu">position_stack</span>(<span class="at">vjust =</span> <span class="fl">0.5</span>), <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span> <span class="co">#add percentages</span></span>
<span id="cb410-4"><a href="hypothesis-testing.html#cb410-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Proportion of conversions&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Agent&quot;</span>) <span class="sc">+</span> <span class="co"># specify axis labels</span></span>
<span id="cb410-5"><a href="hypothesis-testing.html#cb410-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-19"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-19-1.png" alt="proportion of conversions per agent (stacked bar chart)" width="672" />
<p class="caption">
Figure 1.16: proportion of conversions per agent (stacked bar chart)
</p>
</div>
<div id="confidence-intervals-for-proportions" class="section level3" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> Confidence intervals for proportions</h3>
<p>Recall that we can use confidence intervals to determine the range of values that the true population parameter will take with a certain level of confidence based on the sample. Similar to the confidence interval for means, we can compute a confidence interval for proportions. The (1-<span class="math inline">\(\alpha\)</span>)% confidence interval for proportions is approximately</p>
<p><span class="math display">\[
CI = p\pm z_{1-\frac{\alpha}{2}}*\sqrt{\frac{p*(1-p)}{N}}
\]</span></p>
<p>where <span class="math inline">\(\sqrt{p(1-p)}\)</span> is the equivalent to the standard deviation in the formula for the confidence interval for means. Based on the equation, it is easy to compute the confidence intervals for the conversion rates of the call center agents:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="hypothesis-testing.html#cb411-1" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="fu">nrow</span>(<span class="fu">subset</span>(call_center,agent<span class="sc">==</span><span class="st">&quot;agent_1&quot;</span>)) <span class="co">#number of observations for agent 1</span></span>
<span id="cb411-2"><a href="hypothesis-testing.html#cb411-2" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="fu">nrow</span>(<span class="fu">subset</span>(call_center,agent<span class="sc">==</span><span class="st">&quot;agent_2&quot;</span>)) <span class="co">#number of observations for agent 1</span></span>
<span id="cb411-3"><a href="hypothesis-testing.html#cb411-3" aria-hidden="true" tabindex="-1"></a>n1_conv <span class="ot">&lt;-</span> <span class="fu">nrow</span>(<span class="fu">subset</span>(call_center,agent<span class="sc">==</span><span class="st">&quot;agent_1&quot;</span> <span class="sc">&amp;</span> conversion<span class="sc">==</span><span class="st">&quot;yes&quot;</span>)) <span class="co">#number of conversions for agent 1</span></span>
<span id="cb411-4"><a href="hypothesis-testing.html#cb411-4" aria-hidden="true" tabindex="-1"></a>n2_conv <span class="ot">&lt;-</span> <span class="fu">nrow</span>(<span class="fu">subset</span>(call_center,agent<span class="sc">==</span><span class="st">&quot;agent_2&quot;</span> <span class="sc">&amp;</span> conversion<span class="sc">==</span><span class="st">&quot;yes&quot;</span>)) <span class="co">#number of conversions for agent 2</span></span>
<span id="cb411-5"><a href="hypothesis-testing.html#cb411-5" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> n1_conv<span class="sc">/</span>n1  <span class="co">#proportion of conversions for agent 1</span></span>
<span id="cb411-6"><a href="hypothesis-testing.html#cb411-6" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> n2_conv<span class="sc">/</span>n2  <span class="co">#proportion of conversions for agent 2</span></span>
<span id="cb411-7"><a href="hypothesis-testing.html#cb411-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb411-8"><a href="hypothesis-testing.html#cb411-8" aria-hidden="true" tabindex="-1"></a>error1 <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)<span class="sc">*</span><span class="fu">sqrt</span>((p1<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p1))<span class="sc">/</span>n1)</span>
<span id="cb411-9"><a href="hypothesis-testing.html#cb411-9" aria-hidden="true" tabindex="-1"></a>ci_lower1 <span class="ot">&lt;-</span> p1 <span class="sc">-</span> error1</span>
<span id="cb411-10"><a href="hypothesis-testing.html#cb411-10" aria-hidden="true" tabindex="-1"></a>ci_upper1 <span class="ot">&lt;-</span> p1 <span class="sc">+</span> error1</span>
<span id="cb411-11"><a href="hypothesis-testing.html#cb411-11" aria-hidden="true" tabindex="-1"></a>ci_lower1</span></code></pre></div>
<pre><code>## [1] 0.6133232</code></pre>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="hypothesis-testing.html#cb413-1" aria-hidden="true" tabindex="-1"></a>ci_upper1</span></code></pre></div>
<pre><code>## [1] 0.7200101</code></pre>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="hypothesis-testing.html#cb415-1" aria-hidden="true" tabindex="-1"></a>error2 <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)<span class="sc">*</span><span class="fu">sqrt</span>((p2<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p2))<span class="sc">/</span>n2)</span>
<span id="cb415-2"><a href="hypothesis-testing.html#cb415-2" aria-hidden="true" tabindex="-1"></a>ci_lower2 <span class="ot">&lt;-</span> p2 <span class="sc">-</span> error2</span>
<span id="cb415-3"><a href="hypothesis-testing.html#cb415-3" aria-hidden="true" tabindex="-1"></a>ci_upper2 <span class="ot">&lt;-</span> p2 <span class="sc">+</span> error2</span>
<span id="cb415-4"><a href="hypothesis-testing.html#cb415-4" aria-hidden="true" tabindex="-1"></a>ci_lower2</span></code></pre></div>
<pre><code>## [1] 0.2799899</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="hypothesis-testing.html#cb417-1" aria-hidden="true" tabindex="-1"></a>ci_upper2</span></code></pre></div>
<pre><code>## [1] 0.3866768</code></pre>
<p>Similar to testing for differences in means, we could also ask: Is agent 1 twice as likely as agent 2 to convert a customer? Or, to state it formally:</p>
<p><span class="math display">\[H_0: \pi_1=\pi_2 \\
H_1: \pi_1\ne \pi_2\]</span></p>
<p>where <span class="math inline">\(\pi\)</span> denotes the population parameter associated with the proportion in the respective population. One approach to test this is based on confidence intervals to estimate the difference between two populations. We can compute an approximate confidence interval for the difference between the proportion of successes in group 1 and group 2, as:</p>
<p><span class="math display">\[
CI = p_1-p_2\pm z_{1-\frac{\alpha}{2}}*\sqrt{\frac{p_1*(1-p_1)}{n_1}+\frac{p_2*(1-p_2)}{n_2}}
\]</span></p>
<p>If the confidence interval includes zero, then the data does not suggest a difference between the groups. Let’s compute the confidence interval for differences in the proportions by hand first:</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="hypothesis-testing.html#cb419-1" aria-hidden="true" tabindex="-1"></a>ci_lower <span class="ot">&lt;-</span> p1 <span class="sc">-</span> p2 <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)<span class="sc">*</span><span class="fu">sqrt</span>(p1<span class="sc">*</span>(<span class="dv">1</span> <span class="sc">-</span> p1)<span class="sc">/</span>n1 <span class="sc">+</span> p2<span class="sc">*</span>(<span class="dv">1</span> <span class="sc">-</span> p2)<span class="sc">/</span>n2) <span class="co">#95% CI lower bound</span></span>
<span id="cb419-2"><a href="hypothesis-testing.html#cb419-2" aria-hidden="true" tabindex="-1"></a>ci_upper <span class="ot">&lt;-</span> p1 <span class="sc">-</span> p2 <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)<span class="sc">*</span><span class="fu">sqrt</span>(p1<span class="sc">*</span>(<span class="dv">1</span> <span class="sc">-</span> p1)<span class="sc">/</span>n1 <span class="sc">+</span> p2<span class="sc">*</span>(<span class="dv">1</span> <span class="sc">-</span> p2)<span class="sc">/</span>n2) <span class="co">#95% CI upper bound</span></span>
<span id="cb419-3"><a href="hypothesis-testing.html#cb419-3" aria-hidden="true" tabindex="-1"></a>ci_lower</span></code></pre></div>
<pre><code>## [1] 0.2578943</code></pre>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="hypothesis-testing.html#cb421-1" aria-hidden="true" tabindex="-1"></a>ci_upper</span></code></pre></div>
<pre><code>## [1] 0.4087724</code></pre>
<p>Now we can see that the 95% confidence interval estimate of the difference between the proportion of conversions for agent 1 and the proportion of conversions for agent 2 is between 26% and 41%. This interval tells us the range of plausible values for the difference between the two population proportions. According to this interval, zero is not a plausible value for the difference (i.e., interval does not cross zero), so we reject the null hypothesis that the population proportions are the same.</p>
<p>Instead of computing the intervals by hand, we could also use the <code>prop.test()</code> function:</p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="hypothesis-testing.html#cb423-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="at">x =</span> <span class="fu">c</span>(n1_conv, n2_conv), <span class="at">n =</span> <span class="fu">c</span>(n1, n2), <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  c(n1_conv, n2_conv) out of c(n1, n2)
## X-squared = 65.34, df = 1, p-value = 6.303e-16
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  0.2545610 0.4121057
## sample estimates:
##    prop 1    prop 2 
## 0.6666667 0.3333333</code></pre>
<p>Note that the <code>prop.test()</code> function uses a slightly different (more accurate) way to compute the confidence interval (Wilson’s score method is used). It is particularly a better approximation for smaller N. That’s why the confidence interval in the output slightly deviates from the manual computation above, which uses the Wald interval.</p>
<p>You can also see that the output from the <code>prop.test()</code> includes the results from a χ<sup>2</sup> test for the equality of proportions (which will be discussed below) and the associated p-value. Since the p-value is less than 0.05, we reject the null hypothesis of equal probability. Thus, the reporting would be:</p>
<p>The test showed that the conversion rate for agent 1 was higher by 33%. This difference is significant χ (1) = 70, p &lt; .05 (95% CI = [0.25,0.41]).</p>
</div>
<div id="chi-square-test" class="section level3" number="6.7.2">
<h3><span class="header-section-number">6.7.2</span> Chi-square test</h3>
<p>In the previous section, we saw how we can compute the confidence interval for the difference between proportions to decide on whether or not to reject the null hypothesis. Whenever you would like to investigate the relationship between two categorical variables, the <span class="math inline">\(\chi^2\)</span> test may be used to test whether the variables are independent of each other. It achieves this by comparing the expected number of observations in a group to the actual values. Let’s continue with the example from the previous section. Under the null hypothesis, the two variables <em>agent</em> and <em>conversion</em> in our contingency table are independent (i.e., there is no relationship). This means that the frequency in each field will be roughly proportional to the probability of an observation being in that category, calculated under the assumption that they are independent. The difference between that expected quantity and the actual quantity can be used to construct the test statistic. The test statistic is computed as follows:</p>
<p><span class="math display">\[
\chi^2=\sum_{i=1}^{J}\frac{(f_o-f_e)^2}{f_e}
\]</span></p>
<p>where <span class="math inline">\(J\)</span> is the number of cells in the contingency table, <span class="math inline">\(f_o\)</span> are the observed cell frequencies and <span class="math inline">\(f_e\)</span> are the expected cell frequencies. The larger the differences, the larger the test statistic and the smaller the p-value.</p>
<p>The observed cell frequencies can easily be seen from the contingency table:</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="hypothesis-testing.html#cb425-1" aria-hidden="true" tabindex="-1"></a>contigency_table <span class="ot">&lt;-</span> <span class="fu">table</span>(call_center)</span>
<span id="cb425-2"><a href="hypothesis-testing.html#cb425-2" aria-hidden="true" tabindex="-1"></a>obs_cell1 <span class="ot">&lt;-</span> contigency_table[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb425-3"><a href="hypothesis-testing.html#cb425-3" aria-hidden="true" tabindex="-1"></a>obs_cell2 <span class="ot">&lt;-</span> contigency_table[<span class="dv">1</span>,<span class="dv">2</span>]</span>
<span id="cb425-4"><a href="hypothesis-testing.html#cb425-4" aria-hidden="true" tabindex="-1"></a>obs_cell3 <span class="ot">&lt;-</span> contigency_table[<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb425-5"><a href="hypothesis-testing.html#cb425-5" aria-hidden="true" tabindex="-1"></a>obs_cell4 <span class="ot">&lt;-</span> contigency_table[<span class="dv">2</span>,<span class="dv">2</span>]</span></code></pre></div>
<p>The expected cell frequencies can be calculated as follows:</p>
<p><span class="math display">\[
f_e=\frac{(n_r*n_c)}{n}
\]</span></p>
<p>where <span class="math inline">\(n_r\)</span> are the total observed frequencies per row, <span class="math inline">\(n_c\)</span> are the total observed frequencies per column, and <span class="math inline">\(n\)</span> is the total number of observations. Thus, the expected cell frequencies under the assumption of independence can be calculated as:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="hypothesis-testing.html#cb426-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(call_center)</span>
<span id="cb426-2"><a href="hypothesis-testing.html#cb426-2" aria-hidden="true" tabindex="-1"></a>exp_cell1 <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>agent<span class="sc">==</span><span class="st">&quot;agent_1&quot;</span>,])<span class="sc">*</span><span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>conversion<span class="sc">==</span><span class="st">&quot;no&quot;</span>,]))<span class="sc">/</span>n</span>
<span id="cb426-3"><a href="hypothesis-testing.html#cb426-3" aria-hidden="true" tabindex="-1"></a>exp_cell2 <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>agent<span class="sc">==</span><span class="st">&quot;agent_1&quot;</span>,])<span class="sc">*</span><span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>conversion<span class="sc">==</span><span class="st">&quot;yes&quot;</span>,]))<span class="sc">/</span>n</span>
<span id="cb426-4"><a href="hypothesis-testing.html#cb426-4" aria-hidden="true" tabindex="-1"></a>exp_cell3 <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>agent<span class="sc">==</span><span class="st">&quot;agent_2&quot;</span>,])<span class="sc">*</span><span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>conversion<span class="sc">==</span><span class="st">&quot;no&quot;</span>,]))<span class="sc">/</span>n</span>
<span id="cb426-5"><a href="hypothesis-testing.html#cb426-5" aria-hidden="true" tabindex="-1"></a>exp_cell4 <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>agent<span class="sc">==</span><span class="st">&quot;agent_2&quot;</span>,])<span class="sc">*</span><span class="fu">nrow</span>(call_center[call_center<span class="sc">$</span>conversion<span class="sc">==</span><span class="st">&quot;yes&quot;</span>,]))<span class="sc">/</span>n</span></code></pre></div>
<p>To sum up, these are the expected cell frequencies</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="hypothesis-testing.html#cb427-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">conversion_no =</span> <span class="fu">rbind</span>(exp_cell1,exp_cell3),<span class="at">conversion_yes =</span> <span class="fu">rbind</span>(exp_cell2,exp_cell4), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;agent_1&quot;</span>,<span class="st">&quot;agent_2&quot;</span>)) </span></code></pre></div>
<pre><code>##         conversion_no conversion_yes
## agent_1           150            150
## agent_2           150            150</code></pre>
<p>… and these are the observed cell frequencies</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="hypothesis-testing.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">conversion_no =</span> <span class="fu">rbind</span>(obs_cell1,obs_cell2),<span class="at">conversion_yes =</span> <span class="fu">rbind</span>(obs_cell3,obs_cell4), <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">&quot;agent_1&quot;</span>,<span class="st">&quot;agent_2&quot;</span>)) </span></code></pre></div>
<pre><code>##         conversion_no conversion_yes
## agent_1           100            200
## agent_2           200            100</code></pre>
<p>To obtain the test statistic, we simply plug the values into the formula:</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="hypothesis-testing.html#cb431-1" aria-hidden="true" tabindex="-1"></a>chisq_cal <span class="ot">&lt;-</span>  <span class="fu">sum</span>(((obs_cell1 <span class="sc">-</span> exp_cell1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>exp_cell1),</span>
<span id="cb431-2"><a href="hypothesis-testing.html#cb431-2" aria-hidden="true" tabindex="-1"></a>                  ((obs_cell2 <span class="sc">-</span> exp_cell2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>exp_cell2),</span>
<span id="cb431-3"><a href="hypothesis-testing.html#cb431-3" aria-hidden="true" tabindex="-1"></a>                  ((obs_cell3 <span class="sc">-</span> exp_cell3)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>exp_cell3),</span>
<span id="cb431-4"><a href="hypothesis-testing.html#cb431-4" aria-hidden="true" tabindex="-1"></a>                  ((obs_cell4 <span class="sc">-</span> exp_cell4)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>exp_cell4))</span>
<span id="cb431-5"><a href="hypothesis-testing.html#cb431-5" aria-hidden="true" tabindex="-1"></a>chisq_cal</span></code></pre></div>
<pre><code>## [1] 66.66667</code></pre>
<p>The test statistic is <span class="math inline">\(\chi^2\)</span> distributed. The chi-square distribution is a non-symmetric distribution. Actually, there are many different chi-square distributions, one for each degree of freedom as show in the following figure.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-28"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-28-1.png" alt="The chi-square distribution" width="672" />
<p class="caption">
Figure 1.25: The chi-square distribution
</p>
</div>
<p>You can see that as the degrees of freedom increase, the chi-square curve approaches a normal distribution. To find the critical value, we need to specify the corresponding degrees of freedom, given by:</p>
<p><span class="math display">\[
df=(r-1)*(c-1)
\]</span></p>
<p>where <span class="math inline">\(r\)</span> is the number of rows and <span class="math inline">\(c\)</span> is the number of columns in the contingency table. Recall that degrees of freedom are generally the number of values that can vary freely when calculating a statistic. In a 2 by 2 table as in our case, we have 2 variables (or two samples) with 2 levels and in each one we have 1 that vary freely. Hence, in our example the degrees of freedom can be calculated as:</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="hypothesis-testing.html#cb433-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span>  (<span class="fu">nrow</span>(contigency_table) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> (<span class="fu">ncol</span>(contigency_table) <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb433-2"><a href="hypothesis-testing.html#cb433-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Now, we can derive the critical value given the degrees of freedom and the level of confidence using the <code>qchisq()</code> function and test if the calculated test statistic is larger than the critical value:</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="hypothesis-testing.html#cb435-1" aria-hidden="true" tabindex="-1"></a>chisq_crit <span class="ot">&lt;-</span> <span class="fu">qchisq</span>(<span class="fl">0.95</span>, df)</span>
<span id="cb435-2"><a href="hypothesis-testing.html#cb435-2" aria-hidden="true" tabindex="-1"></a>chisq_crit</span></code></pre></div>
<pre><code>## [1] 3.841459</code></pre>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="hypothesis-testing.html#cb437-1" aria-hidden="true" tabindex="-1"></a>chisq_cal <span class="sc">&gt;</span> chisq_crit</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-31"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-31-1.png" alt="Visual depiction of the test result" width="672" />
<p class="caption">
Figure 4.4: Visual depiction of the test result
</p>
</div>
<p>We could also compute the p-value using the <code>pchisq()</code> function, which tells us the probability of the observed cell frequencies if the null hypothesis was true (i.e., there was no association):</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="hypothesis-testing.html#cb439-1" aria-hidden="true" tabindex="-1"></a>p_val <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">pchisq</span>(chisq_cal,df)</span>
<span id="cb439-2"><a href="hypothesis-testing.html#cb439-2" aria-hidden="true" tabindex="-1"></a>p_val</span></code></pre></div>
<pre><code>## [1] 3.330669e-16</code></pre>
<p>The test statistic can also be calculated in R directly on the contingency table with the function <code>chisq.test()</code>.</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="hypothesis-testing.html#cb441-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(contigency_table, <span class="at">correct =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  contigency_table
## X-squared = 66.667, df = 1, p-value = 3.215e-16</code></pre>
<p>Since the p-value is smaller than 0.05 (i.e., the calculated test statistic is larger than the critical value), we reject H<sub>0</sub> that the two variables are independent.</p>
<p>Note that the test statistic is sensitive to the sample size. To see this, let’s assume that we have a sample of 100 observations instead of 1000 observations:</p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="hypothesis-testing.html#cb443-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(contigency_table<span class="sc">/</span><span class="dv">10</span>, <span class="at">correct =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  contigency_table/10
## X-squared = 6.6667, df = 1, p-value = 0.009823</code></pre>
<p>You can see that even though the proportions haven’t changed, the test is insignificant now. The following equation lets you compute a measure of the effect size, which is insensitive to sample size:</p>
<p><span class="math display">\[
\phi=\sqrt{\frac{\chi^2}{n}}
\]</span></p>
<p>The following guidelines are used to determine the magnitude of the effect size (Cohen, 1988):</p>
<ul>
<li>0.1 (small effect)</li>
<li>0.3 (medium effect)</li>
<li>0.5 (large effect)</li>
</ul>
<p>In our example, we can compute the effect sizes for the large and small samples as follows:</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="hypothesis-testing.html#cb445-1" aria-hidden="true" tabindex="-1"></a>test_stat <span class="ot">&lt;-</span> <span class="fu">chisq.test</span>(contigency_table, <span class="at">correct =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>statistic</span>
<span id="cb445-2"><a href="hypothesis-testing.html#cb445-2" aria-hidden="true" tabindex="-1"></a>phi1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(test_stat<span class="sc">/</span>n)</span>
<span id="cb445-3"><a href="hypothesis-testing.html#cb445-3" aria-hidden="true" tabindex="-1"></a>test_stat <span class="ot">&lt;-</span> <span class="fu">chisq.test</span>(contigency_table<span class="sc">/</span><span class="dv">10</span>, <span class="at">correct =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>statistic</span>
<span id="cb445-4"><a href="hypothesis-testing.html#cb445-4" aria-hidden="true" tabindex="-1"></a>phi2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(test_stat<span class="sc">/</span>(n<span class="sc">/</span><span class="dv">10</span>))</span>
<span id="cb445-5"><a href="hypothesis-testing.html#cb445-5" aria-hidden="true" tabindex="-1"></a>phi1</span></code></pre></div>
<pre><code>## X-squared 
## 0.3333333</code></pre>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="hypothesis-testing.html#cb447-1" aria-hidden="true" tabindex="-1"></a>phi2</span></code></pre></div>
<pre><code>## X-squared 
## 0.3333333</code></pre>
<p>You can see that the statistic is insensitive to the sample size.</p>
<p>Note that the Φ coefficient is appropriate for two dichotomous variables (resulting from a 2 x 2 table as above). If any your nominal variables has more than two categories, Cramer’s V should be used instead:</p>
<p><span class="math display">\[
V=\sqrt{\frac{\chi^2}{n*df_{min}}}
\]</span></p>
<p>where <span class="math inline">\(df_{min}\)</span> refers to the degrees of freedom associated with the variable that has fewer categories (e.g., if we have two nominal variables with 3 and 4 categories, <span class="math inline">\(df_{min}\)</span> would be 3 - 1 = 2). The degrees of freedom need to be taken into account when judging the magnitude of the effect sizes (see e.g., <a href="http://www.real-statistics.com/chi-square-and-f-distributions/effect-size-chi-square/" target="_blank">here</a>).</p>
<p>Note that the <code>correct = FALSE</code> argument above ensures that the test statistic is computed in the same way as we have done by hand above. By default, <code>chisq.test()</code> applies a correction to prevent overestimation of statistical significance for small data (called the Yates’ correction). The correction is implemented by subtracting the value 0.5 from the computed difference between the observed and expected cell counts in the numerator of the test statistic. This means that the calculated test statistic will be smaller (i.e., more conservative). Although the adjustment may go too far in some instances, you should generally rely on the adjusted results, which can be computed as follows:</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="hypothesis-testing.html#cb449-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(contigency_table)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  contigency_table
## X-squared = 65.34, df = 1, p-value = 6.303e-16</code></pre>
<p>As you can see, the results don’t change much in our example, since the differences between the observed and expected cell frequencies are fairly large relative to the correction.</p>
<p>As usual, you could also use the <code>ggstatsplot</code> package to obtain the result of the test, this time by using <code>ggbarstats</code> function:</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="hypothesis-testing.html#cb451-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggstatsplot)</span>
<span id="cb451-2"><a href="hypothesis-testing.html#cb451-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggbarstats</span>(</span>
<span id="cb451-3"><a href="hypothesis-testing.html#cb451-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> call_center,</span>
<span id="cb451-4"><a href="hypothesis-testing.html#cb451-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> conversion,</span>
<span id="cb451-5"><a href="hypothesis-testing.html#cb451-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> agent,</span>
<span id="cb451-6"><a href="hypothesis-testing.html#cb451-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Conversion by agent&quot;</span>,</span>
<span id="cb451-7"><a href="hypothesis-testing.html#cb451-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Agent&quot;</span>,</span>
<span id="cb451-8"><a href="hypothesis-testing.html#cb451-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">palette =</span> <span class="st">&quot;Blues&quot;</span>,</span>
<span id="cb451-9"><a href="hypothesis-testing.html#cb451-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">messages =</span> <span class="cn">FALSE</span>,</span>
<span id="cb451-10"><a href="hypothesis-testing.html#cb451-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">bar.proptest =</span> <span class="cn">FALSE</span>,</span>
<span id="cb451-11"><a href="hypothesis-testing.html#cb451-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">bf.message =</span> <span class="cn">FALSE</span></span>
<span id="cb451-12"><a href="hypothesis-testing.html#cb451-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-37"></span>
<img src="09-non_parametric_tests_files/figure-html/unnamed-chunk-37-1.png" alt="Kruskal-Wallis test using ggstatsplot" width="672" />
<p class="caption">
Figure 4.7: Kruskal-Wallis test using ggstatsplot
</p>
</div>
<p>Caution is warranted when the cell counts in the contingency table are small. The usual rule of thumb is that all cell counts should be at least 5 (this may be a little too stringent though). When some cell counts are too small, you can use Fisher’s exact test using the <code>fisher.test()</code> function.</p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="hypothesis-testing.html#cb452-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.test</span>(contigency_table)</span></code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  contigency_table
## p-value = 3.391e-16
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.1754685 0.3560568
## sample estimates:
## odds ratio 
##  0.2506258</code></pre>
<p>The Fisher test, while more conservative, also shows a significant difference between the proportions (p &lt; 0.05). This is not surprising since the cell counts in our example are fairly large.</p>
</div>
<div id="sample-size-1" class="section level3" number="6.7.3">
<h3><span class="header-section-number">6.7.3</span> Sample size</h3>
<p>To <strong>calculate the required sample size</strong> when comparing proportions, the <code>power.prop.test()</code> function can be used. For example, we could ask how large our sample needs to be if we would like to compare two groups with conversion rates of 2% and 2.5%, respectively using the conventional settings for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>:</p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="hypothesis-testing.html#cb454-1" aria-hidden="true" tabindex="-1"></a><span class="fu">power.prop.test</span>(<span class="at">p1=</span><span class="fl">0.02</span>,<span class="at">p2=</span><span class="fl">0.025</span>,<span class="at">sig.level=</span><span class="fl">0.05</span>,<span class="at">power=</span><span class="fl">0.8</span>)</span></code></pre></div>
<pre><code>## 
##      Two-sample comparison of proportions power calculation 
## 
##               n = 13808.92
##              p1 = 0.02
##              p2 = 0.025
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>The output tells us that we need 1.3809^{4} observations per group to detect a difference of the desired size.</p>
</div>
</div>
<div id="learning-check-4" class="section level2 unnumbered">
<h2>Learning check</h2>
<p><strong>(LC6.1) The Null Hypothesis (<span class="math inline">\(H_0\)</span>) is a statement of:</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
The status-quo/no effect</li>
<li><input type="checkbox" disabled="" />
The desired status</li>
<li><input type="checkbox" disabled="" />
The expected status</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.2) Which statements about the Null Hypothesis (<span class="math inline">\(H_0\)</span>) are TRUE?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
In scientific research, the goal is usually to confirm it</li>
<li><input type="checkbox" disabled="" />
In scientific research, the goal is usually to reject it</li>
<li><input type="checkbox" disabled="" />
It can be confirmed with one test</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.3) The t-distribution:</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Has more probability mass in its tails compared to the normal distribution and therefore corrects for small samples</li>
<li><input type="checkbox" disabled="" />
Approaches the normal distribution as n increases</li>
<li><input type="checkbox" disabled="" />
Is the distribution of the t-statistic</li>
<li><input type="checkbox" disabled="" />
Has less probability mass in its tails compared to the normal distribution and therefore corrects for small samples</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.4) Type I vs. Type II Errors: Which of the following statements is TRUE?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Type II Error: We believe there is no effect, when in fact there is</li>
<li><input type="checkbox" disabled="" />
Type I Error: We believe there is an effect, when in fact there isn’t</li>
<li><input type="checkbox" disabled="" />
Type I Error: We believe there is no effect, when in fact there is</li>
<li><input type="checkbox" disabled="" />
Type II Error: We believe there is an effect, when in fact there isn’t</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.5) When planning an experiment, which of the following information would you need to compute the required sample size?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
The p-value (p)</li>
<li><input type="checkbox" disabled="" />
The significance level (alpha)</li>
<li><input type="checkbox" disabled="" />
The effect size (d)</li>
<li><input type="checkbox" disabled="" />
The critical value of the test statistic (t)</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.6) In which setting would you reject the null hypothesis when conducting a statistical test?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
When the absolute value of the calculated test-statistic (e.g., t-value) exceeds the critical value of the test statistic at your specified significance level (e.g., 0.05)</li>
<li><input type="checkbox" disabled="" />
When the p-value is smaller than your specified significance level (e.g., 0.05)</li>
<li><input type="checkbox" disabled="" />
When the confidence interval associated with the test does not contain zero</li>
<li><input type="checkbox" disabled="" />
When the test-statistic (e.g., t-value) is lower than the critical value of the test statistic at your specified significance level (e.g., 0.05)</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.7) After conducting a statistical test, what is the relationship between the test statistic (e.g., t-value) and the p-value?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
The lower the absolute value of the test statistic, the lower the p-value</li>
<li><input type="checkbox" disabled="" />
The higher the absolute value of the test statistic, the higher the p-value</li>
<li><input type="checkbox" disabled="" />
There is no connection between the test statistic and the p-value</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.8) What does a significant test result tell you?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
The importance of an effect</li>
<li><input type="checkbox" disabled="" />
That the null hypothesis is false</li>
<li><input type="checkbox" disabled="" />
That the null hypothesis is true</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.9) In an experiment in which you compare the means between two groups, you should collect data until your test shows a significant results. True or false?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
True</li>
<li><input type="checkbox" disabled="" />
False</li>
</ul>
<p><strong>(LC6.10) If you have data from an within-subjects experimental design, you should use the independent-means t-test. True or false?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
True</li>
<li><input type="checkbox" disabled="" />
False</li>
</ul>
<table>
<tbody>
<tr class="odd">
<td align="left"><strong>Questions for chapters 6.4 and following from here</strong></td>
</tr>
</tbody>
</table>
<p><strong>(LC6.11) When should you use an ANOVA rather than a t-test?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
To compare the means for more than populations</li>
<li><input type="checkbox" disabled="" />
To compare the means of two groups</li>
<li><input type="checkbox" disabled="" />
To adjust the variance of different sets</li>
<li><input type="checkbox" disabled="" />
To test for causality</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.12) What is the correct representation of the null hypothesis for an ANOVA??</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
H0:μ1≠μ2≠μ3</li>
<li><input type="checkbox" disabled="" />
H1:μ1=μ2=μ3</li>
<li><input type="checkbox" disabled="" />
H0:μ1=μ2=μ3</li>
<li><input type="checkbox" disabled="" />
H0:μ1≠μ2=μ3</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.13) Using an experimental design with three groups, why can’t we just compare the means between the groups using multiple t-test?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Because the parametric assumptions of the t-test are not met</li>
<li><input type="checkbox" disabled="" />
Because of deflated Type III Error rates</li>
<li><input type="checkbox" disabled="" />
Due to the family-wise error rate the Type II Error is inflated</li>
<li><input type="checkbox" disabled="" />
Because the Type I Error rate (alpha) wouldn’t be 0.05</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.14) Which assumptions have to be satisfied to be able to use ANOVA on data from a between-subject design with three groups?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Same mean for all groups</li>
<li><input type="checkbox" disabled="" />
Normal distribution of data</li>
<li><input type="checkbox" disabled="" />
Homogeneity of variances</li>
<li><input type="checkbox" disabled="" />
Independence of observation</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.15) What procedures are designed to correct of family-wise error rate in ANOVA?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Bonferroni correction</li>
<li><input type="checkbox" disabled="" />
Tukey’s HSD</li>
<li><input type="checkbox" disabled="" />
t-test</li>
<li><input type="checkbox" disabled="" />
Post-hoc tests</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.16) Which of the following are examples for non-parametric tests?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Chi-Squared test</li>
<li><input type="checkbox" disabled="" />
ANOVA</li>
<li><input type="checkbox" disabled="" />
Kruskal-Wilcoxon test</li>
<li><input type="checkbox" disabled="" />
T-test</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.17) When should you use non-parametric tests?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
When the assumptions of parametric tests are not met (e.g., normally distributed sampling distribution)</li>
<li><input type="checkbox" disabled="" />
You have a very small sample size</li>
<li><input type="checkbox" disabled="" />
When your dependent variable is measured on an ordinal scale</li>
<li><input type="checkbox" disabled="" />
When your data is better represented by the median</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.18) When should you use a Wilcoxon Rank Sum Test (= Mann-Whitney U Test)?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
When the assumptions of the t-test have been violated</li>
<li><input type="checkbox" disabled="" />
The variances are not significantly different between groups</li>
<li><input type="checkbox" disabled="" />
As a non-parametric alternative to the independent-means t-test</li>
<li><input type="checkbox" disabled="" />
When the assumptions of the ANOVA have been violated</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.19) What does a Chi squared test do?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
Tests the statistical significance of the observed association in a cross-tabulation</li>
<li><input type="checkbox" disabled="" />
Tests whether group A affects group B</li>
<li><input type="checkbox" disabled="" />
Produces a test statistic that is Chi Squared distributed</li>
<li><input type="checkbox" disabled="" />
Tests for the association between two or more categorical variables</li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
<p><strong>(LC6.20) Which R-function would be suitable if you wanted to perform a test with ranked (ordinal) data in a two-group between-subject design?</strong></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
<code>kruskal.test(x, ...)</code></li>
<li><input type="checkbox" disabled="" />
<code>wilcox.test(x, ...)</code></li>
<li><input type="checkbox" disabled="" />
<code>aov(formula, data = ,...)</code></li>
<li><input type="checkbox" disabled="" />
<code>t.test(x, ...)</code></li>
<li><input type="checkbox" disabled="" />
None of the above</li>
</ul>
</div>
<div id="references-3" class="section level2 unnumbered">
<h2>References</h2>
<ul>
<li>Field, A., Miles J., &amp; Field, Z. (2012): Discovering Statistics Using R. Sage Publications, <strong>chapters 5, 9, 10, 12, 15, 18</strong>.</li>
<li>McCullough, B.D. &amp; Feit, E. (2020). Business Experiments with R.</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistical-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
